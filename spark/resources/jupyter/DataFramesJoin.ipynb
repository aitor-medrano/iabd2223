{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de5c8525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: integer (nullable = true)\n",
      " |-- delay: integer (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"s8a-dataframes-joins\").getOrCreate()\n",
    "\n",
    "df_vuelos = spark.read.option(\"sep\",\",\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"departure_delays.csv\")\n",
    "df_vuelos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4989d1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1391578"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vuelos.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a96dc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- IATA: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_aeropuertos = spark.read.option(\"sep\",\"\\t\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"airport-codes-na.tsv\")\n",
    "df_aeropuertos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6e1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b382ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77551f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vuelos.createOrReplaceTempView(\"vuelos\")\n",
    "df_aeropuertos.createOrReplaceTempView(\"aeropuertos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4bfbca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+----------+---------------+\n",
      "|   date|delay|distance|origin|destination|originCity|destinationCity|\n",
      "+-------+-----+--------+------+-----------+----------+---------------+\n",
      "|1011245|    6|     602|   ABE|        ATL| Allentown|        Atlanta|\n",
      "|1020600|   -8|     369|   ABE|        DTW| Allentown|        Detroit|\n",
      "|1021245|   -2|     602|   ABE|        ATL| Allentown|        Atlanta|\n",
      "+-------+-----+--------+------+-----------+----------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join = spark.sql(\"select v.*, a.City as originCity, b.City as destinationCity from vuelos v JOIN aeropuertos a on v.origin == a.IATA join aeropuertos b on v.destination = b.IATA\")\n",
    "df_join.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb50b1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361141"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e824fd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+----------+---------------+\n",
      "|   date|delay|distance|origin|destination|originCity|destinationCity|\n",
      "+-------+-----+--------+------+-----------+----------+---------------+\n",
      "|1011245|    6|     602|   ABE|        ATL| Allentown|        Atlanta|\n",
      "|1020600|   -8|     369|   ABE|        DTW| Allentown|        Detroit|\n",
      "|1021245|   -2|     602|   ABE|        ATL| Allentown|        Atlanta|\n",
      "+-------+-----+--------+------+-----------+----------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_left_join = spark.sql(\"select v.*, a.City as originCity, b.City as destinationCity from vuelos v LEFT JOIN aeropuertos a on v.origin == a.IATA LEFT JOIN aeropuertos b on v.destination = b.IATA\")\n",
    "df_left_join.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6aed257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1391578"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_left_join.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f3eaeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14416"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_left_anti_join = spark.sql(\"select * from vuelos v LEFT ANTI JOIN aeropuertos a ON v.origin == a.IATA \")\n",
    "df_left_anti_join.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c9f906d-6c5f-40ce-a68d-8a339307ca07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1377162"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exprJoin1 = df_vuelos.origin == df_aeropuertos.IATA\n",
    "df_joinp1 = df_vuelos.join(df_aeropuertos, exprJoin1, \"inner\")\n",
    "df_joinp1.count()    # 1361141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dafa3732-499c-4805-875f-f22612df8e8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": " Column IATA#501 are ambiguous. It's probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check.        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m exprJoin2 \u001b[38;5;241m=\u001b[39m df_vuelos\u001b[38;5;241m.\u001b[39mdestination \u001b[38;5;241m==\u001b[39m df_aeropuertos\u001b[38;5;241m.\u001b[39mIATA\n\u001b[0;32m----> 2\u001b[0m df_joinp2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf_joinp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_aeropuertos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexprJoin2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_joinp2\u001b[38;5;241m.\u001b[39mcount()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:1355\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how)\u001b[0m\n\u001b[1;32m   1353\u001b[0m         on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jseq([])\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(how, \u001b[38;5;28mstr\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow should be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1355\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m:  Column IATA#501 are ambiguous. It's probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check.        "
     ]
    }
   ],
   "source": [
    "exprJoin2 = df_vuelos.destination == df_aeropuertos.IATA\n",
    "df_joinp2 = df_joinp1.join(df_aeropuertos, exprJoin2, \"inner\")\n",
    "df_joinp2.count()    # 1361141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "108564e8-d063-4ec0-a60d-7bf058346b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361141"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# le indicamos alias a los campos para eliminar ambiguedades\n",
    "df_joinp2 = (df_joinp1.alias(\"a\")).join((df_aeropuertos.alias(\"b\")), col(\"a.destination\") == col(\"b.IATA\"), \"inner\")\n",
    "df_joinp2.count()    # 1361141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f6ec6c3-b70c-48e4-86f6-7a672e034697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14416"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exprJoin1 = df_vuelos.origin == df_aeropuertos.IATA\n",
    "df_left_anti_join = df_vuelos.join(df_aeropuertos, exprJoin1, \"left_anti\")\n",
    "df_left_anti_join.count()   # 14416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde17d5-f905-4af3-8785-84678dd0e714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 26 2022, 19:06:18) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
