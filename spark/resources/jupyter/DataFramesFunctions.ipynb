{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e9a203-35b8-4a9c-83f2-8f80c16d7508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ProductID: integer (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Zip: string (nullable = true)\n",
      " |-- Units: integer (nullable = true)\n",
      " |-- Revenue: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"s8a-dataframes-sql\").getOrCreate()\n",
    "\n",
    "# Lectura de CSV con el ; como separador de columnas y con encabezado\n",
    "df = spark.read.option(\"sep\",\";\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"pdi_sales_small.csv\")\n",
    "    \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2187aa8-a531-43d8-b694-2c4bb7d90ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, trim, to_date\n",
    "df = df.withColumn(\"Date\", to_date(df.Date, \"M/d/yyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5791d1d-b03d-45cf-9c19-7cf6c3429374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------------+-----+-------+-------+\n",
      "|ProductID|      Date|            Zip|Units|Revenue|Country|\n",
      "+---------+----------+---------------+-----+-------+-------+\n",
      "|      725|1999-01-15|H1B            |    1|  115.4|Canada |\n",
      "|     2235|1999-01-15|H1B            |    2|  131.1|Canada |\n",
      "|      713|1999-01-15|H1B            |    1|  160.1|Canada |\n",
      "|      574|2002-06-05|H1B            |    1|  869.1|Canada |\n",
      "|       94|1999-02-15|H1B            |    1|  866.2|Canada |\n",
      "|      609|1999-02-15|H1B            |    1|  778.8|Canada |\n",
      "|     2064|1999-03-15|H1B            |    2|  976.4|Canada |\n",
      "|      714|1999-01-15|H1B            |    1|  160.1|Canada |\n",
      "|      826|2002-05-31|H1B            |    1|  944.9|Canada |\n",
      "|     2149|2002-06-06|H1B            |    2|  871.4|Canada |\n",
      "|      992|1999-02-15|H1B            |    1|  288.7|Canada |\n",
      "|      726|1999-01-15|M4X            |    1|  115.4|Canada |\n",
      "|      725|1999-01-15|M4X            |    1|  115.4|Canada |\n",
      "|      910|1999-03-15|M4X            |    1|  414.7|Canada |\n",
      "|      727|1999-01-15|R3T            |    1|   62.9|Canada |\n",
      "|     1426|1999-02-15|R3T            |    1|  286.0|Canada |\n",
      "|     1182|1999-01-15|R3T            |    1|  157.4|Canada |\n",
      "|      976|2002-05-31|R3T            |    1|  314.9|Canada |\n",
      "|      758|1999-01-15|R3T            |    1|   83.9|Canada |\n",
      "|     1112|1999-02-15|R3T            |    1|  116.5|Canada |\n",
      "+---------+----------+---------------+-----+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").where(df.Country==\"Canada \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2fb960-9ebb-4ee2-a762-a5c5c3cc09d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+\n",
      "|      Date|date_format(Date, dd-MM-yyy)|next_day(Date, Sun)|last_day(Date)|dayofmonth(Date)|dayofyear(Date)|month(Date)|year(Date)|\n",
      "+----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+\n",
      "|1999-01-15|                  15-01-1999|         1999-01-17|    1999-01-31|              15|             15|          1|      1999|\n",
      "|2002-06-06|                  06-06-2002|         2002-06-09|    2002-06-30|               6|            157|          6|      2002|\n",
      "|2002-06-06|                  06-06-2002|         2002-06-09|    2002-06-30|               6|            157|          6|      2002|\n",
      "+----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.select(\"Date\", date_format(\"Date\", \"dd-MM-yyy\"), next_day(\"Date\", \"Sun\"), last_day(\"Date\"),\n",
    "              dayofmonth(\"Date\"), dayofyear(\"Date\"), month(\"Date\"), year(\"Date\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b901a5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+---+---------------+---------------+\n",
      "|            Zip|              l|  r|     lower(Zip)|     upper(Zip)|\n",
      "+---------------+---------------+---+---------------+---------------+\n",
      "|H1B            |H1B            |H1B|h1b            |H1B            |\n",
      "+---------------+---------------+---+---------------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Zip\", ltrim(\"Zip\").alias(\"l\"), rtrim(\"Zip\").alias(\"r\"), \n",
    "         lower(\"Zip\"), upper(\"Zip\")\n",
    "         ).where(trim(df.Country)==\"Canada\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cfd8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+----------------+---------------+--------------------------+\n",
      "|Country|initcap(lower(Country))|reverse(Country)|length(Country)|translate(Country, na, pe)|\n",
      "+-------+-----------------------+----------------+---------------+--------------------------+\n",
      "|Canada |                Canada |          adanaC|              7|                   Cepede |\n",
      "+-------+-----------------------+----------------+---------------+--------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Country\", initcap(lower(\"Country\")), reverse(\"Country\"),\n",
    "          length(\"Country\"), translate(\"Country\", \"na\", \"pe\")\n",
    "         ).where(trim(df.Country)==\"Canada\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa79b242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+---------------------+------------------------+\n",
      "|Country|split(Country, a, -1)|locate(a, Country, 1)|substring(Country, 3, 2)|\n",
      "+-------+---------------------+---------------------+------------------------+\n",
      "|Canada |         [C, n, d,  ]|                    2|                      na|\n",
      "+-------+---------------------+---------------------+------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Country\", split(\"Country\", \"a\"), locate(\"a\", \"Country\"),\n",
    "          substring(\"Country\",3,2)\n",
    "         ).where(trim(df.Country)==\"Canada\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2e66902-dc51-49c7-820b-280ff4a45a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----+\n",
      "|ProductID|Revenue|Units|\n",
      "+---------+-------+-----+\n",
      "|      495|43194.1|   77|\n",
      "|     2091| 6347.7|   41|\n",
      "|     2091| 6240.1|   41|\n",
      "|     2091| 3652.7|   24|\n",
      "|     2091| 3560.9|   23|\n",
      "+---------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"ProductID\", \"Revenue\", \"Units\").sort(\"Units\", ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec9bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "def bonus(unidades, ventas):\n",
    "    if unidades == 1 :\n",
    "        return 0.0\n",
    "    else:\n",
    "        return unidades * ventas / 100\n",
    "    \n",
    "udfBonus = udf(bonus, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e7dfdb6-216e-46cc-8dbc-33ed02cdce64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----+---------------------+\n",
      "|ProductID|Revenue|Units|bonus(Units, Revenue)|\n",
      "+---------+-------+-----+---------------------+\n",
      "|      495|43194.1|   77|   33259.456999999995|\n",
      "|     2091| 6347.7|   41|             2602.557|\n",
      "|     2091| 6240.1|   41|   2558.4410000000003|\n",
      "|     2091| 3652.7|   24|    876.6479999999999|\n",
      "|     2091| 3560.9|   23|              819.007|\n",
      "+---------+-------+-----+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"ProductID\", \"Revenue\", \"Units\", udfBonus(df.Units, df.Revenue)).sort(\"Units\", ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5936b68c-5831-4724-a32d-3fa338bc10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"ventas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d93e233b-30a7-46ba-9bc9-f3158be5605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----+------------------+\n",
      "|ProductID|Revenue|Units|             bonus|\n",
      "+---------+-------+-----+------------------+\n",
      "|      495|43194.1|   77|33259.456999999995|\n",
      "|     2091| 6347.7|   41|          2602.557|\n",
      "|     2091| 6240.1|   41|2558.4410000000003|\n",
      "|     2091| 3652.7|   24| 876.6479999999999|\n",
      "|     2091| 3560.9|   23|           819.007|\n",
      "+---------+-------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.udf.register(\"udfBonus\", bonus, DoubleType())\n",
    "spark.sql(\"select ProductID, Revenue, Units,  udfBonus(Units, Revenue) as bonus from ventas order by Units desc\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb903e7-1ba7-4982-96a3-062fb660f28c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
