{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Inteligencia Artificial y Big Data \u00b6 Apuntes realizados para el curso de especialista de Inteligencia Artificial y Big Data impartido en el IES Severo Ochoa de Elche. El curriculum viene fijado por el Real Decreto 279/2021 . Este curso se ha dise\u00f1ado mediante un proceso de flexibilizaci\u00f3n del curriculum, mediante el cual hemos repartido los diferentes resultados de aprendizaje a lo largo de tres unidades formativas. Cada una de las unidades formativas contiene varias unidades de trabajo centradas en un \u00e1rea de trabajo concreta. En cada unidad formativa vamos a realizar como hilo conductor un Proyecto de Innovaci\u00f3n Aplicado (PIAFP) que dirija el aprendizaje del alumnado. En este sitio web podr\u00e1s consultar los apuntes y ejercicios que he trabajado directamente con el alumnado durante el curso 22/23: Unidad Formativa I - Toma de decisiones UT2 - Sistemas de almacenamiento UT5 - Ecosistema Hadoop UT6 - Reto: cloud UT7 - PIAFP Lara Unidad Formativa II - Unidad Formativa III - Despliega el men\u00fa de la izquierda para consultar los materiales.","title":"Inicio"},{"location":"index.html#inteligencia-artificial-y-big-data","text":"Apuntes realizados para el curso de especialista de Inteligencia Artificial y Big Data impartido en el IES Severo Ochoa de Elche. El curriculum viene fijado por el Real Decreto 279/2021 . Este curso se ha dise\u00f1ado mediante un proceso de flexibilizaci\u00f3n del curriculum, mediante el cual hemos repartido los diferentes resultados de aprendizaje a lo largo de tres unidades formativas. Cada una de las unidades formativas contiene varias unidades de trabajo centradas en un \u00e1rea de trabajo concreta. En cada unidad formativa vamos a realizar como hilo conductor un Proyecto de Innovaci\u00f3n Aplicado (PIAFP) que dirija el aprendizaje del alumnado. En este sitio web podr\u00e1s consultar los apuntes y ejercicios que he trabajado directamente con el alumnado durante el curso 22/23: Unidad Formativa I - Toma de decisiones UT2 - Sistemas de almacenamiento UT5 - Ecosistema Hadoop UT6 - Reto: cloud UT7 - PIAFP Lara Unidad Formativa II - Unidad Formativa III - Despliega el men\u00fa de la izquierda para consultar los materiales.","title":"Inteligencia Artificial y Big Data"},{"location":"cloud/index.html","text":"Unidad de Trabajo 6.- Reto: Datos en el cloud \u00b6 Resultados de aprendizaje \u00b6 RA5074.1 Aplica t\u00e9cnicas de an\u00e1lisis de datos que integran, procesan y analizan la informaci\u00f3n, adaptando e implementando sistemas que las utilicen. RA5074.3 Gestiona y almacena datos facilitando la b\u00fasqueda de respuestas en grandes conjuntos de datos. RA5075.1 Gestiona soluciones a problemas propuestos, utilizando sistemas de almacenamiento y herramientas asociadas al centro de datos. RA5075.2 Gestiona sistemas de almacenamiento y el amplio ecosistema alrededor de ellos facilitando el procesamiento de grandes cantidades de datos sin fallos y de forma r\u00e1pida. RA5075.3 Genera mecanismos de integridad de los datos, comprobando su mantenimiento en los sistemas de ficheros distribuidos y valorando la sobrecarga que conlleva en el tratamiento de los datos. Planificaci\u00f3n \u00b6 Sesi\u00f3n Fecha Duraci\u00f3n (h) 18.- Ingenier\u00eda de datos / NoSQL Mi\u00e9rcoles 26 Oct 2p + 2o 24.- MongoDB Lunes 7 Nov 2p + 2o 26.- Modelado documental. Agregaciones en MongoDB Mi\u00e9rcoles 9 Nov 2p + 2o 28.- Formatos de datos Lunes 14 Nov 2p + 2o 30.- MongoDB y Python Mi\u00e9rcoles 16 Nov 2p + 2o","title":"Unidad de Trabajo 6.- Reto: *Datos en el cloud*"},{"location":"cloud/index.html#unidad-de-trabajo-6-reto-datos-en-el-cloud","text":"","title":"Unidad de Trabajo 6.- Reto: Datos en el cloud"},{"location":"cloud/index.html#resultados-de-aprendizaje","text":"RA5074.1 Aplica t\u00e9cnicas de an\u00e1lisis de datos que integran, procesan y analizan la informaci\u00f3n, adaptando e implementando sistemas que las utilicen. RA5074.3 Gestiona y almacena datos facilitando la b\u00fasqueda de respuestas en grandes conjuntos de datos. RA5075.1 Gestiona soluciones a problemas propuestos, utilizando sistemas de almacenamiento y herramientas asociadas al centro de datos. RA5075.2 Gestiona sistemas de almacenamiento y el amplio ecosistema alrededor de ellos facilitando el procesamiento de grandes cantidades de datos sin fallos y de forma r\u00e1pida. RA5075.3 Genera mecanismos de integridad de los datos, comprobando su mantenimiento en los sistemas de ficheros distribuidos y valorando la sobrecarga que conlleva en el tratamiento de los datos.","title":"Resultados de aprendizaje"},{"location":"cloud/index.html#planificacion","text":"Sesi\u00f3n Fecha Duraci\u00f3n (h) 18.- Ingenier\u00eda de datos / NoSQL Mi\u00e9rcoles 26 Oct 2p + 2o 24.- MongoDB Lunes 7 Nov 2p + 2o 26.- Modelado documental. Agregaciones en MongoDB Mi\u00e9rcoles 9 Nov 2p + 2o 28.- Formatos de datos Lunes 14 Nov 2p + 2o 30.- MongoDB y Python Mi\u00e9rcoles 16 Nov 2p + 2o","title":"Planificaci\u00f3n"},{"location":"cloud/01cloud.html","text":"","title":"S1.- Cloud"},{"location":"hadoop/index.html","text":"Unidad de Trabajo 5.- Ecosistema Hadoop \u00b6 Resultados de aprendizaje \u00b6 RA5074.1 Aplica t\u00e9cnicas de an\u00e1lisis de datos que integran, procesan y analizan la informaci\u00f3n, adaptando e implementando sistemas que las utilicen. RA5074.3 Gestiona y almacena datos facilitando la b\u00fasqueda de respuestas en grandes conjuntos de datos. RA5075.1 Gestiona soluciones a problemas propuestos, utilizando sistemas de almacenamiento y herramientas asociadas al centro de datos. RA5075.2 Gestiona sistemas de almacenamiento y el amplio ecosistema alrededor de ellos facilitando el procesamiento de grandes cantidades de datos sin fallos y de forma r\u00e1pida. RA5075.3 Genera mecanismos de integridad de los datos, comprobando su mantenimiento en los sistemas de ficheros distribuidos y valorando la sobrecarga que conlleva en el tratamiento de los datos. Planificaci\u00f3n \u00b6 Sesi\u00f3n Fecha Duraci\u00f3n (h) 34.- Hadoop Lunes 21 Nov 2p + 2o 35.- ETL/ELT Mi\u00e9rcoles 23 Nov 2p + 2o 36.- HDFS Mi\u00e9rcoles 23 Nov 2p + 2o 37.- Sqoop / Flume Lunes 28 Nov 2p + 2o 38.- Hive Lunes 28 Nov 2p + 2o","title":"Unidad de Trabajo 5.- Ecosistema Hadoop"},{"location":"hadoop/index.html#unidad-de-trabajo-5-ecosistema-hadoop","text":"","title":"Unidad de Trabajo 5.- Ecosistema Hadoop"},{"location":"hadoop/index.html#resultados-de-aprendizaje","text":"RA5074.1 Aplica t\u00e9cnicas de an\u00e1lisis de datos que integran, procesan y analizan la informaci\u00f3n, adaptando e implementando sistemas que las utilicen. RA5074.3 Gestiona y almacena datos facilitando la b\u00fasqueda de respuestas en grandes conjuntos de datos. RA5075.1 Gestiona soluciones a problemas propuestos, utilizando sistemas de almacenamiento y herramientas asociadas al centro de datos. RA5075.2 Gestiona sistemas de almacenamiento y el amplio ecosistema alrededor de ellos facilitando el procesamiento de grandes cantidades de datos sin fallos y de forma r\u00e1pida. RA5075.3 Genera mecanismos de integridad de los datos, comprobando su mantenimiento en los sistemas de ficheros distribuidos y valorando la sobrecarga que conlleva en el tratamiento de los datos.","title":"Resultados de aprendizaje"},{"location":"hadoop/index.html#planificacion","text":"Sesi\u00f3n Fecha Duraci\u00f3n (h) 34.- Hadoop Lunes 21 Nov 2p + 2o 35.- ETL/ELT Mi\u00e9rcoles 23 Nov 2p + 2o 36.- HDFS Mi\u00e9rcoles 23 Nov 2p + 2o 37.- Sqoop / Flume Lunes 28 Nov 2p + 2o 38.- Hive Lunes 28 Nov 2p + 2o","title":"Planificaci\u00f3n"},{"location":"hadoop/01hadoop.html","text":"Hadoop \u00b6","title":"S1.- Hadoop"},{"location":"hadoop/01hadoop.html#hadoop","text":"","title":"Hadoop"},{"location":"pia/index.html","text":"Unidad de Trabajo 7.- PIAFP Lara \u00b6 La unidad 7 se centra en trabajar a lo largo de la unidad formativa con el proyecto de innovaci\u00f3n Lara, trabajando todos los resultados de aprendizaje vistos en las sesiones de las anteriores unidades de trabajo. Planificaci\u00f3n \u00b6 Sesiones Fecha Duraci\u00f3n (h) 5,6.- Presentaci\u00f3n Viernes 7 Oct 4p + 4o 13,14.- Captura de requisitos Viernes 21 Oct 4p + 4o 21,22.- Etiquetado de datos Viernes 4 Nov 4p + 4o 31,32.- Almacenamiento de datos Viernes 18 Nov 4p + 4o 39,40.- Validaci\u00f3n Mi\u00e9rcoles 30 Nov 4p + 4o 41,42.- Almacenamiento de audio Viernes 2 Dic 4p + 4o","title":"Unidad de Trabajo 7.- PIAFP Lara"},{"location":"pia/index.html#unidad-de-trabajo-7-piafp-lara","text":"La unidad 7 se centra en trabajar a lo largo de la unidad formativa con el proyecto de innovaci\u00f3n Lara, trabajando todos los resultados de aprendizaje vistos en las sesiones de las anteriores unidades de trabajo.","title":"Unidad de Trabajo 7.- PIAFP Lara"},{"location":"pia/index.html#planificacion","text":"Sesiones Fecha Duraci\u00f3n (h) 5,6.- Presentaci\u00f3n Viernes 7 Oct 4p + 4o 13,14.- Captura de requisitos Viernes 21 Oct 4p + 4o 21,22.- Etiquetado de datos Viernes 4 Nov 4p + 4o 31,32.- Almacenamiento de datos Viernes 18 Nov 4p + 4o 39,40.- Validaci\u00f3n Mi\u00e9rcoles 30 Nov 4p + 4o 41,42.- Almacenamiento de audio Viernes 2 Dic 4p + 4o","title":"Planificaci\u00f3n"},{"location":"pia/01presentacion.html","text":"Presentaci\u00f3n PIA Lara \u00b6","title":"S5,6.- Presentaci\u00f3n"},{"location":"pia/01presentacion.html#presentacion-pia-lara","text":"","title":"Presentaci\u00f3n PIA Lara"},{"location":"sa/index.html","text":"Unidad de Trabajo 2.- Sistemas de almacenamiento \u00b6 Resultados de aprendizaje \u00b6 RA5074.1 Aplica t\u00e9cnicas de an\u00e1lisis de datos que integran, procesan y analizan la informaci\u00f3n, adaptando e implementando sistemas que las utilicen. RA5074.3 Gestiona y almacena datos facilitando la b\u00fasqueda de respuestas en grandes conjuntos de datos. RA5075.1 Gestiona soluciones a problemas propuestos, utilizando sistemas de almacenamiento y herramientas asociadas al centro de datos. RA5075.2 Gestiona sistemas de almacenamiento y el amplio ecosistema alrededor de ellos facilitando el procesamiento de grandes cantidades de datos sin fallos y de forma r\u00e1pida. RA5075.3 Genera mecanismos de integridad de los datos, comprobando su mantenimiento en los sistemas de ficheros distribuidos y valorando la sobrecarga que conlleva en el tratamiento de los datos. Planificaci\u00f3n \u00b6 Sesi\u00f3n Fecha Duraci\u00f3n (h) 18.- Ingenier\u00eda de datos / NoSQL Mi\u00e9rcoles 26 Oct 2p + 2o 24.- MongoDB Lunes 7 Nov 2p + 2o 26.- Modelado documental. Agregaciones en MongoDB Mi\u00e9rcoles 9 Nov 2p + 2o 28.- Formatos de datos Lunes 14 Nov 2p + 2o 30.- MongoDB y Python Mi\u00e9rcoles 16 Nov 2p + 2o","title":"Unidad de Trabajo 2.- Sistemas de almacenamiento"},{"location":"sa/index.html#unidad-de-trabajo-2-sistemas-de-almacenamiento","text":"","title":"Unidad de Trabajo 2.- Sistemas de almacenamiento"},{"location":"sa/index.html#resultados-de-aprendizaje","text":"RA5074.1 Aplica t\u00e9cnicas de an\u00e1lisis de datos que integran, procesan y analizan la informaci\u00f3n, adaptando e implementando sistemas que las utilicen. RA5074.3 Gestiona y almacena datos facilitando la b\u00fasqueda de respuestas en grandes conjuntos de datos. RA5075.1 Gestiona soluciones a problemas propuestos, utilizando sistemas de almacenamiento y herramientas asociadas al centro de datos. RA5075.2 Gestiona sistemas de almacenamiento y el amplio ecosistema alrededor de ellos facilitando el procesamiento de grandes cantidades de datos sin fallos y de forma r\u00e1pida. RA5075.3 Genera mecanismos de integridad de los datos, comprobando su mantenimiento en los sistemas de ficheros distribuidos y valorando la sobrecarga que conlleva en el tratamiento de los datos.","title":"Resultados de aprendizaje"},{"location":"sa/index.html#planificacion","text":"Sesi\u00f3n Fecha Duraci\u00f3n (h) 18.- Ingenier\u00eda de datos / NoSQL Mi\u00e9rcoles 26 Oct 2p + 2o 24.- MongoDB Lunes 7 Nov 2p + 2o 26.- Modelado documental. Agregaciones en MongoDB Mi\u00e9rcoles 9 Nov 2p + 2o 28.- Formatos de datos Lunes 14 Nov 2p + 2o 30.- MongoDB y Python Mi\u00e9rcoles 16 Nov 2p + 2o","title":"Planificaci\u00f3n"},{"location":"sa/01nosql.html","text":"Ingenier\u00eda de Datos \u00b6 No S\u00f3lo SQL \u00b6 Si definimos NoSQL formalmente, podemos decir que se trata de un conjunto de tecnolog\u00edas que permiten el procesamiento r\u00e1pido y eficiente de conjuntos de datos dando la mayor importancia al rendimiento, la fiabilidad y la agilidad. Si nos basamos en el acr\u00f3nimo, el t\u00e9rmino se refiere a cualquier almac\u00e9n de datos que no sigue un modelo relacional, los datos no son relacionales y por tanto no utilizan SQL como lenguaje de consulta. As\u00ed pues, los sistemas NoSQL se centran en sistemas complementarios a los SGBD relacionales, que fijan sus prioridades en la escalabilidad y la disponibilidad en contra de la atomicidad y consistencia de los datos. NoSQL aparece como una necesidad debida al creciente volumen de datos sobre usuarios, objetos y productos que las empresas tienen que almacenar, as\u00ed como la frecuencia con la que se accede a los datos. Los SGDB relacionales existentes no fueron dise\u00f1ados teniendo en cuenta la escalabilidad ni la flexibilidad necesaria por las frecuentes modificaciones que necesitan las aplicaciones modernas; tampoco aprovechan que el almacenamiento a d\u00eda de hoy es muy barato, ni el nivel de procesamiento que alcanzan las m\u00e1quinas actuales. Los diferentes tipos de bases de datos NoSQL existentes se pueden agrupar en cuatro categor\u00edas: Clave-Valor : Los almacenes clave-valor son las bases de datos NoSQL m\u00e1s simples. Cada elemento de la base de datos se almacena con un nombre de atributo (o clave) junto a su valor. Los almacenes m\u00e1s conocidos son Redis, Riak y Voldemort. Algunos almacenes, como es el caso de Redis, permiten que cada valor tenga un tipo (por ejemplo, integer) lo cual a\u00f1ade funcionalidad extra. Documentales : Cada clave se asocia a una estructura compleja que se conoce como documento. Este puede contener diferentes pares clave-valor, o pares de clave-array o incluso documentos anidados, como en un documento JSON. Los ejemplos m\u00e1s conocidos son MongoDB y CouchDB. Grafos : Los almacenes de grafos se usan para almacenar informaci\u00f3n sobre redes, como pueden ser conexiones sociales. Los ejemplos m\u00e1s conocidos son Neo4J, FlockDB, InfiniteGraph y HyperGraphDB. Basados en columnas : Los almacenes basados en columnas como BigTable, Hadoop, Cassandra y HBase est\u00e1n optimizados para consultas sobre grandes conjuntos de datos, y almacenan los datos como columnas, en vez de como filas, de modo que cada fila puede contener un n\u00famero diferente de columnas. Sistemas NoSQL Caracter\u00edsticas \u00b6 Si nos centramos en sus beneficios y los comparamos con las base de datos relacionales, las bases de datos NoSQL son m\u00e1s escalables, ofrecen un rendimiento mayor y sus modelos de datos resuelven varios problemas que no se plantearon al definir el modelo relacional: Grandes vol\u00famenes de datos estructurados, semi-estructurados y sin estructurar. Casi todas las implementaciones NoSQL ofrecen alg\u00fan tipo de representaci\u00f3n para datos sin esquema, lo que permite comenzar con una estructura y con el paso del tiempo, a\u00f1adir nuevos campos, ya sean sencillos o anidados a datos ya existentes. Sprints \u00e1giles, iteraciones r\u00e1pidas y frecuentes commits/pushes de c\u00f3digo, al emplear una sintaxis sencilla para la realizaci\u00f3n de consultas y la posibilidad de tener un modelo que vaya creciendo al mismo ritmo que el desarrollo. Arquitectura eficiente y escalable dise\u00f1ada para trabajar con clusters en vez de una arquitectura monol\u00edtica y costosa. Las soluciones NoSQL soportan la escalabilidad de un modo transparente para el desarrollador. Una caracter\u00edstica adicional que comparten los sistemas NoSQL es que ofrecen un mecanismo de cach\u00e9 de datos integrado (en los sistemas relacionales se pueden configurar de manera externa), de manera que se pueden configurar los sistemas para que los datos se mantengan en memoria y se persistan de manera periodica. El uso de una cach\u00e9 conlleva que la consistencia de los datos no sea completa y podamos tener una consistencia eventual. Esquema din\u00e1micos \u00b6 Las bases de datos relacionales requieren definir los esquemas antes de a\u00f1adir los datos. Una base de datos SQL necesita saber de antemano los datos que vamos a almacenar; por ejemplo, si nos centramos en los datos de un cliente, ser\u00edan el nombre, apellidos, n\u00famero de tel\u00e9fono, etc\u2026\u200b Esto casa bastante mal con los enfoques de desarrollo \u00e1gil, ya que cada vez que a\u00f1adimos nuevas funcionalidades, el esquema de la base de datos suele cambiar. De modo que si a mitad de desarrollo decidimos almacenar los productos favoritos de un cliente del cual guard\u00e1bamos su direcci\u00f3n y n\u00fameros de tel\u00e9fono, tendr\u00edamos que a\u00f1adir una nueva columna a la base de datos y migrar la base de datos entera a un nuevo esquema. Si la base de datos es grande, conlleva un proceso lento que implica parar el sistema durante un tiempo considerable. Si frecuentemente cambiamos los datos que la aplicaci\u00f3n almacena (al usar un desarrollo iterativo), tambi\u00e9n tendremos per\u00edodos frecuentes de inactividad del sistema. As\u00ed pues, no hay un modo efectivo mediante una base de datos relacional, de almacenar los datos que est\u00e1n desestructurados o que no se conocen de antemano. Las bases de datos NoSQL se construyen para permitir la inserci\u00f3n de datos sin un esquema predefinido. Esto facilita la modificaci\u00f3n de la aplicaci\u00f3n en tiempo real, sin preocuparse por interrupciones de servicio. De este modo se consigue un desarrollo m\u00e1s r\u00e1pido, integraci\u00f3n de c\u00f3digo m\u00e1s robusto y menos tiempo empleado en la administraci\u00f3n de la base de datos. Particionado \u00b6 Dado el modo en el que se estructuran las bases de datos relacionales, normalmente escalan verticalmente - un \u00fanico servidor que almacena toda la base de datos para asegurar la disponibilidad continua de los datos. Esto se traduce en costes que se incrementan r\u00e1pidamente, con un l\u00edmites definidos por el propio hardware, y en un peque\u00f1o n\u00famero de puntos cr\u00edticos de fallo dentro de la infraestructura de datos. La soluci\u00f3n es escalar horizontalmente, a\u00f1adiendo nuevos servidores en vez de concentrarse en incrementar la capacidad de un \u00fanico servidor. Este escalado horizontal se conoce como Sharding o Particionado. Particionado de los datos El particionado no es \u00fanico de las bases de datos NoSQL. Las bases de datos relacionales tambi\u00e9n lo soportan. Si en un sistema relacional queremos particionar los datos, podemos distinguir entre particionado: Horizontal : diferentes filas en diferentes particiones. Vertical : diferentes columnas en particiones distintas. En el caso de las bases de datos NoSQL, el particionado depende del modelo de la base de datos: Los almacenes clave-valor y las bases de datos documentales normalmente se particionan horizontalmente. Las bases de datos basados en columnas se pueden particionar horizontal o verticalmente. Escalar horizontalmente una base de datos relacional entre muchas instancias de servidores se puede conseguir pero normalmente conlleva el uso de SANs ( Storage Area Networks ) y otras triqui\u00f1uelas para hacer que el hardware act\u00fae como un \u00fanico servidor. Como los sistemas SQL no ofrecen esta prestaci\u00f3n de forma nativa, los equipos de desarrollo se las tienen que ingeniar para conseguir desplegar m\u00faltiples bases de datos relacionales en varias m\u00e1quinas. Para ello: Los datos se almacenan en cada instancia de base de datos de manera aut\u00f3noma El c\u00f3digo de aplicaci\u00f3n se desarrolla para distribuir los datos y las consultas y agregar los resultados de los datos a trav\u00e9s de todas las instancias de bases de datos Se debe desarrollar c\u00f3digo adicional para gestionar los fallos sobre los recursos, para realizar joins entre diferentes bases de datos, balancear los datos y/o replicarlos, etc\u2026\u200b Adem\u00e1s, muchos beneficios de las bases de datos como la integridad transaccional se ven comprometidos o incluso eliminados al emplear un escalado horizontal. Auto-sharding \u00b6 Por contra, las bases de datos NoSQL normalmente soportan auto-sharding , lo que implica que de manera nativa y autom\u00e1ticamente se dividen los datos entre un n\u00famero arbitrario de servidores, sin que la aplicaci\u00f3n sea consciente de la composici\u00f3n del pool de servidores. Los datos y las consultas se balancean entre los servidores. El particionado se realiza mediante un m\u00e9todo consistente, como puede ser: Por rangos de su id: por ejemplo \"los usuarios del 1 al mill\u00f3n est\u00e1n en la partici\u00f3n 1\" o \"los usuarios cuyo nombre va de la A a la E\" en una partici\u00f3n, en otra de la M a la Q, y de la R a la Z en la tercera. Por listas : dividiendo los datos por la categor\u00eda del dato, es decir, en el caso de datos sobre libros, las novelas en una partici\u00f3n, las recetas de cocina en otra, etc.. Mediante un funci\u00f3n hash , la cual devuelve un valor para un elemento que determine a que partici\u00f3n pertenece. Cuando particionar \u00b6 El motivo para particionar los datos se debe a: limitaciones de almacenamiento: los datos no caben en un \u00fanico servidor, tanto a nivel de disco como de memoria RAM. rendimiento: al balancear la carga entre particiones las escrituras ser\u00e1n m\u00e1s r\u00e1pidas que al centrarlas en un \u00fanico servidor. disponibilidad: si un servidor esta ocupado, otro servidor puede devolver los datos. La carga de los servidores se reduce. No particionaremos los datos cuando la cantidad sea peque\u00f1a, ya que el hecho de distribuir los datos conlleva unos costes que pueden no compensar con un volumen de datos insuficiente. Tampoco esperaremos a particionar cuando tengamos much\u00edsimos datos, ya que el proceso de particionado puede provocar sobrecarga del sistema. La nube facilita de manera considerable este escalado, mediante proveedores como Amazon Web Services el cual ofrece virtualmente una capacidad ilimitada bajo demanda, y preocup\u00e1ndose de todas las tareas necesarias para la administraci\u00f3n de la base de datos. Los desarrolladores ya no necesitamos construir plataformas complejas para nuestras aplicaciones, de modo que nos podemos centrar en escribir c\u00f3digo de aplicaci\u00f3n. Una granja de servidores puede ofrecer el mismo procesamiento y capacidad de almacenamiento que un \u00fanico servidor de alto rendimiento por mucho menos coste. Replicaci\u00f3n \u00b6 a replicaci\u00f3n mantiene copias id\u00e9nticas de los datos en m\u00faltiples servidores, lo que facilita que las aplicaciones siempre funcionen y los datos se mantengan seguros, incluso si alguno de los servidores sufre alg\u00fan problema. La mayor\u00eda de las bases de datos NoSQL tambi\u00e9n soportan la replicaci\u00f3n autom\u00e1tica, lo que implica una alta disponibilidad y recuperaci\u00f3n frente a desastres sin la necesidad de aplicaciones de terceros encargadas de ello. Desde el punto de vista del desarrollador, el entorno de almacenamiento es virtual y ajeno al c\u00f3digo de aplicaci\u00f3n. Replicaci\u00f3n de los datos La replicaci\u00f3n de los datos se utiliza para alcanzar: escalabilidad , incrementando el rendimiento al poder distribuir las consultas en diferentes nodos, y mejorar la rendundancia al permitir que cada nodo tenga una copia de los datos. disponibilidad , ofreciendo tolerancia a fallos de hardware o corrupci\u00f3n de la base de datos. Al replicar los datos vamos a poder tener una copia de la base de datos, dar soporte a un servidor de datos agregados, o tener nodos a modo de copias de seguridad que pueden tomar el control en caso de fallo. aislamiento (la i en ACID - isolation ), entendido como la propiedad que define cuando y c\u00f3mo al realizar cambios en un nodo se propagan al resto de nodos. Si replicamos los datos podemos crear copias sincronizadas que separar procesos de la base de datos de producci\u00f3n, pudiendo ejecutar informes o copias de seguridad en nodos secundarios de modo que no tenga un impacto negativo en el nodo principal, as\u00ed como ofrecer un sistema sencillo para separar el entorno de producci\u00f3n del de preproducci\u00f3n. Replicaci\u00f3n vs particionado No hay que confundir la replicaci\u00f3n (copia de los datos en varias m\u00e1quinas) con la partici\u00f3n (cada m\u00e1quina tiene un subconjunto de los datos). El entorno m\u00e1s seguro y con mejor rendimiento es aquel que tiene los datos particionados y replicados (cada maquina que tiene un subconjunto de los datos est\u00e1 replicada en 2 o m\u00e1s). Implantando NoSQL \u00b6 Normalmente, las empresas empezar\u00e1n con una prueba de baja escalabilidad de una base de datos NoSQL, de modo que les permita comprender la tecnolog\u00eda asumiendo muy poco riesgo. La mayor\u00eda de las bases de datos NoSQL tambi\u00e9n son open-source, y por tanto se pueden probar sin ning\u00fan coste extra. Al tener unos ciclos de desarrollo m\u00e1s r\u00e1pidos, las empresas pueden innovar con mayor velocidad y mejorar la experiencia de sus cliente a un menor coste. Elegir la base de datos correcta para el proyecto es un tema importante. Se deben considerar las diferentes alternativas a las infraestructuras legacy teniendo en cuenta varios factores: la escalabilidad o el rendimiento m\u00e1s all\u00e1 de las capacidades del sistema existente identificar alternativas viables respecto al software propietario incrementar la velocidad y agilidad del proceso de desarrollo As\u00ed pues, al elegir un base de datos hemos de tener en cuenta las siguientes dimensiones: Modelo de Datos: A elegir entre un modelo documental, basado en columnas, de grafos o mediante clave-valor. Modelo de Consultas: Dependiendo de la aplicaci\u00f3n, puede ser aceptable un modelo de consultas que s\u00f3lo accede a los registros por su clave primaria. En cambio, otras aplicaciones pueden necesitar consultar por diferentes valores de cada registro. Adem\u00e1s, si la aplicaci\u00f3n necesita modificar los registros, la base de datos necesita consultar los datos por un \u00edndice secundario. Modelo de Consistencia: Los sistemas NoSQL normalmente mantienen m\u00faltiples copias de los datos para ofrecer disponibilidad y escalabilidad al sistema, lo que define la consistencia del mismo. Los sistemas NoSQL tienden a ser consistentes o eventualmente consistentes. APIs: No existe un est\u00e1ndar para interactuar con los sistemas NoSQL. Cada sistema presenta diferentes dise\u00f1os y capacidades para los equipos de desarrollo. La madurez de un API puede suponer una inversi\u00f3n en tiempo y dinero a la hora de desarrollar y mantener el sistema NoSQL. Soporte Comercial y de la Comunidad: Los usuarios deben considerar la salud de la compa\u00f1ia o de los proyectos al evaluar una base de datos. El producto debe evolucionar y se mantenga para introducir nuevas prestaciones y corregir fallos. Una base de datos con una comunidad fuerte de usuarios: permite encontrar y contratar desarrolladores con destrezas en el producto. facilita encontrar informaci\u00f3n, documentaci\u00f3n y ejemplos de c\u00f3digo. ayuda a las empresas a retener el talento. favorece que otras empresas de software integren sus productos y participen en el ecosistema de la base de datos. Casos de uso \u00b6 Una vez conocemos los diferentes sistemas y qu\u00e9 elementos puede hacer que nos decidamos por una soluci\u00f3n u otra, conviene repasar los casos de uso m\u00e1s comunes: Si vamos a crear una aplicaci\u00f3n web cuyo campos sean personalizables, usaremos una soluci\u00f3n documental. Como una capa de cach\u00e9, mediante un almac\u00e9n clave-valor. Para almacenar archivos binarios sin preocuparse de la gesti\u00f3n de permisos del sistema de archivos, y porder realizar consultas sobre sus metadatos, ya sea mediante una soluci\u00f3n documental o un almac\u00e9n clave-valor. Para almacenar un enorme volumen de datos, donde la consistencia no es lo m\u00e1s importante, pero si la disponibilidad y su capacidad de ser distribuida. Modelos de Datos \u00b6 La principal clasificaci\u00f3n de los sistemas de BBDD NoSQL se realiza respecto a los diferentes modelos de datos: Documental \u00b6 Mientras las bases de datos relacionales almacenan los datos en filas y columnas, las bases de datos documentales emplean documentos. Estos documentos utilizan una estructura JSON, ofreciendo un modo natural e intuitivo para modelar datos de manera similar a la orientaci\u00f3n a objetos, donde cada documento es un objeto. Representaci\u00f3n de un documento Los documentos se agrupan en colecciones o bases de datos, dependiendo del sistema, lo que permite agrupar documentos. Los documentos contienen uno o m\u00e1s campos, donde cada campo contiene un valor con un tipo, ya sea cadena, fecha, binario o array. En vez de extender los datos entre m\u00faltiples columnas y tablas, cada registro y sus datos asociados se almacenan de manera unida en un \u00fanico documento. Esto simplifica el acceso a los datos y reduce (y en ocasiones elimina) la necesidad de joins y transacciones complejas. Caracter\u00edsticas \u00b6 En una base de datos documental, la noci\u00f3n de esquema es din\u00e1mico: cada documento puede contener diferentes campos. Esta flexibilidad puede ser \u00fatil para modelar datos desestructurados y polim\u00f3rficos, lo que facilita la evoluci\u00f3n del desarrollo al permitir a\u00f1adir nuevos campos de manera din\u00e1mica. Por ejemplo, podemos tener dos documentos que pertenecen a la misma colecci\u00f3n, pero con atributos diferentes: ``` json { \"EmpleadoID\": \"BW1\", \"Nombre\" : \"Bruce\", \"Apellido\" : \"Wayne\", \"Edad\" : 35, \"Salario\" : 10000000 } { \"EmpleadoID\": \"JK1\", \"Nombre\" : \"Joker\", \"Edad\" : 34, \"Salary\" : 5000000, \"Direccion\" : { \"Lugar\" : \"Asilo Arkham\", \"Ciudad\" : \"Gotham\" }, \"Proyectos\" : [ \"desintoxicacion-virus\", \"top-secret-007\" ] } ``` Normalmente, cada documento contiene un elemento clave, sobre el cual se puede obtener un documento de manera un\u00edvoca. De todos modos, las bases de datos documentales ofrecen un completo mecanismo de consultas, posibilitando obtener informaci\u00f3n por cualquier campo del documento. Algunos productos ofrecen opciones de indexado para optimizar las consultas, como pueden ser \u00edndices compuestos, dispersos, con tiempo de vida (TTL), \u00fanicos, de texto o geoespaciales. Adem\u00e1s, estos sistemas ofrecen productos que permiten analizar los datos, mediante funciones de agregaci\u00f3n o implementaci\u00f3n de MapReduce. Respecto a la modificaciones, los documentos se pueden actualizar en una \u00fanica sentencia, sin necesidad de dar rodeos para elegir los datos a modificar. Casos de uso \u00b6 Las bases de datos documentales sirven para prop\u00f3sito general, v\u00e1lidos para un amplio abanico de aplicaciones gracias a la flexibilidad que ofrece el modelo de datos, lo que permite consultar cualquier campo y modelar de manera natural de manera similar a la programaci\u00f3n orientada a objetos. Entre los casos de \u00e9xito de estos sistemas cabe destacar: Sistemas de flujo de eventos: entre diferentes aplicaciones dentro de una empresa Gestores de Contenido, plataformas de Blogging: al almacenar los documentos mediante JSON, facilita la estructura de datos para guardar los comentarios, registros de usuarios, etc\u2026\u200b Anal\u00edticas Web, datos en Tiempo Real: al permitir modificar partes de un documento, e insertar nuevos atributos a un documento cuando se necesita una nueva m\u00e9trica Aplicaciones eCommerce: conforme las aplicaciones crecen, el esquema tambi\u00e9n lo hace Si nos centramos en aquellos casos donde no conviene este tipo de sistemas podemos destacar: Sistemas operaciones con transacciones complejas Sistemas con consultas agregadas que modifican su estructura. Si los criterios de las consultas no paran de cambiar, acabaremos normalizando los datos. Los productos m\u00e1s destacados son: MongoDB: http://www.mongodb.com CouchDB: http://couchdb.apache.org Clave-Valor \u00b6 Un almac\u00e9n clave-valor es una simple tabla hash donde todos los accesos a la base de datos se realizan a trav\u00e9s de la clave primaria. Desde una perspectiva de modelo de datos, los almacenes de clave-valor son los m\u00e1s b\u00e1sicos. Su funcionamiento es similar a tener una tabla relacional con dos columnas, por ejemplo id y nombre, siendo id la columna utilizada como clave y nombre como valor. Mientras que en una base de datos en el campo nombre s\u00f3lo podemos almacenar datos de tipo cadena, en un almac\u00e9n clave-valor, el valor puede ser de un dato simple o un objeto. Cuando una aplicaci\u00f3n accede mediante la clave y el valor, se almacenan el par de elementos. Si la clave ya existe, el valor se modifica. Representaci\u00f3n de un almac\u00e9n clave-valor El cliente puede tanto obtener el valor por la clave, asignar un valor a una clave o eliminar una clave del almac\u00e9n. El valor, sin embargo, es opaco al sistema, el cual no sabe que hay dentro de \u00e9l, ya que los datos s\u00f3lo se pueden consultar por la clave, lo cual puede ser un inconveniente. As\u00ed pues, la aplicaci\u00f3n es responsable de saber qu\u00e9 hay almacenado en cada valor. python Codigo de ejemplo de acceso s un bucket y b\u00fasqueda en Redis Riak utiliza el concepto de bucket (cubo) como una manera de agrupar claves, de manera similar a una tabla Interactuando con Riak medianta HTTP curl -v -X PUT http://localhost:8091/riak/heroes/ace -H \"Content-Type: application/json\" -d {\"nombre\" : \"Batman\", \"color\" : \"Negro\"} Algunos almacenes clave-valor, como puede ser Redis, permiten almacenar datos con cualquier estructura, como por ejemplos listas, conjuntos, hashes y pueden realizar operaciones como intersecci\u00f3n, uni\u00f3n, diferencia y rango. redis SET nombre \"Bruce Wayne\" //String HSET heroe nombre \"Batman\" // Hash \u2013 set HSET heroe color \"Negro\" SADD \"heroe:amigos\" \"Robin\" \"Alfred\" // Set \u2013 create/update Estas prestaciones hacen que Redis se extrapole a \u00e1mbitos ajenos a un almac\u00e9n clave-valor. Otra caracter\u00edstica que ofrecen algunos almacenes es que permiten crear un segundo nivel de consulta o incluso definir m\u00e1s de una clave para un mismo objeto. Como los almacenes clave-valor siempre utilizan accesos por clave primaria, de manera general tienen un gran rendimiento y son f\u00e1cilmente escalables. Si queremos que su rendimiento sea m\u00e1ximo, pueden configurarse para que mantegan la informaci\u00f3n en memoria y que se serialice de manera peri\u00f3dica, a costa de tener una consistencia eventual de los datos. Casos de uso \u00b6 Este modelo es muy \u00fatil para representar datos desestructurados o polim\u00f3rficos, ya que no fuerzan ning\u00fan esquema m\u00e1s all\u00e1 de los pares de clave-valor. Entre los casos de uso de estos almacenes podemos destacar el almacenaje de: Informaci\u00f3n sobre la sesi\u00f3n de navegaci\u00f3n (sessionid) Perfiles de usuario, preferencias Datos del carrito de la compra Cachear datos Todas estas operaciones van a asociada a operaciones de recuperaci\u00f3n, modificaci\u00f3n o inserci\u00f3n de los datos de una sola vez, de ah\u00ed su elecci\u00f3n. En cambio, no conviene utilizar estos almacenes cuando queremos realizar: Relaciones entre datos Transacciones entre varias operaciones Consultas por los datos del valor Operaciones con conjuntos de claves Los almacenes m\u00e1s empleados son: Riak: http://basho.com/riak/ Redis: http://redis.io Voldemort: https://github.com/voldemort/voldemort implementaci\u00f3n open-source de Amazon DynamoDB http://aws.amazon.com/dynamodb Basado en columnas \u00b6 Tambi\u00e9n conocidos como sistemas Big Data o tabulares. Su nombre viene tras la implementaci\u00f3n de Google de BigTable ( http://research.google.com/archive/bigtable.html ), el cual consiste en columnas separadas y sin esquema, a modo de mapa de dos niveles. Las bases de datos relacionales utilizan la fila como unidad de almacenamiento, lo que permite un buen rendimiento de escritura. Sin embargo, cuando las escrituras son ocasionales y es m\u00e1s comun tener que leer unas pocas columnas de muchas filas a la vez, es mejor utilizar como unidad de almacenamiento a grupos de columnas. Un modelo basado en columnas se representa como una estructura agregada de dos niveles. El primer nivel formado por un almac\u00e9n clave-valor, siendo la clave el identificador de la fila, y el valor un nuevo mapa con los datos agregados de la fila (familias de columnas). Los valores de este segundo nivel son las columnas. De este modo, podemos acceder a los datos de un fila, o a una determinada columna: Representaci\u00f3n de un almac\u00e9n basado en columnas Los almacenes basados en columnas utilizan un mapa ordenado multi-dimensional y distribuido para almacenar los datos. Est\u00e1n pensados para que cada fila tenga una gran n\u00famero de columnas (del orden del mill\u00f3n), almacenando las diferentes versiones que tenga una fila (pudiendo almacenar del orden de miles de millones de filas). Familias de columnas \u00b6 Una columna consiste en un pareja name-value, donde el nombre hace de clave. Adem\u00e1s, contiene un atributo timestamp para poder expirar datos y resolver conflictos de escritura. Un ejemplo de columna podr\u00eda ser: json { name: \"nombre\", value: \"Bruce\", timestamp: 12345667890 } Una fila es una colecci\u00f3n de columnas agrupadas a una clave. Si agrupamos filas similares tendremos una familia de columnas: json // familia de columnas { // fila \"tim-gordon\" : { nombre: \"Tim\", apellido: \"Gordon\", ultimaVisita: \"2015/12/12\" } // fila \"bruce-wayne\" : { nombre: \"Bruce\", apellido: \"Wayne\", lugar: \"Gotham\" } } Cada registro puede variar en el n\u00famero de columnas con el que se almacena, y las columnas se pueden anidar dentro de otras formando super-columnas, donde el valor es un nuevo mapa de columnas. json { name: \"libro:978-84-16152-08-7\", value: { autor: \"Grant Morrison\", titulo: \"Batman - Asilo Arkham\", isbn: \"978-84-16152-08-7\" } } Cuando se utilizan super columnas para crear familias de columnas tendremos una familia de super columnas. En resumen, las bases de datos basadas en columnas, almacenan los datos en familias de columnas como filas, las cuales tienen muchas columnas asociadas al identificador de una fila. Las familias de columnas son grupos de datos relacionados, a las cuales normalmente se accede de manera conjunta. Familias de columnas Operaciones \u00b6 A la hora de consultar los datos, \u00e9stos se pueden obtener por la clave primaria de la familia. As\u00ed pues, podemos obtener toda una familia, o la columna de una familia: python // Mediante Cassandra GET Clientes['bruce-wayne']; // familia GET Clientes['bruce-wayne']['lugar']; // columna Algunos productos ofrecen un soporte limitado para \u00edndices secundarios, pero con restricciones. Por ejemplo, Cassandra ofrece el lenguaje CQL similar a SQL pero sin joins, ni subconsultas donde las restricciones de where son sencillas: sql SELECT * FROM Clientes SELECT nombre,email FROM Clientes SELECT nombre,email FROM Clientes WHERE lugar='Gotham' Las actualizaciones se realizan en dos pasos: primero encontrar el registro y segundo modificarlo. En estos sistemas, una modificaci\u00f3n puede suponer una reescritura completa del registro independientemente que hayan cambiado unos pocos bytes del mismo. Casos de uso \u00b6 De manera similar a los almacenes clave-valor, el mercado de estos sistemas son las aplicaciones que s\u00f3lo necesitan consultar los datos por un \u00fanico valor. En cambio, estas aplicaciones centran sus objetivos en el rendimiento y la escalabilidad. Entre los casos de uso destacamos: Sistemas de flujo de eventos: para almacenar estados de las aplicaciones o errores de las mismas. Gestores de Contenido, plataformas de Blogging: mediante familias de columnas podemos almacenar las entradas y las etiquetas, categor\u00edas, enlaces, trackbacks en columnas. Los comentarios se pueden almacenar en la misma fila o en otra base de datos. Contadores: para poder almacenar las visitas de cada visitante a cada apartado de un site Si nos centramos en aquellos casos donde no conviene este tipo de sistemas podemos destacar: Sistemas operacionales con transacciones complejas Sistemas con consultas agregadas. Si los criterios de las consultas no paran de cambiar, acabaremos normalizando los datos. Prototipado inicial o sistemas donde el esquema no est\u00e9 fijado de antemano, ya que las consultas dependen del dise\u00f1o de las familias de columnas. Los productos m\u00e1s destacados son: HBase : http://hbase.apache.org , el cual se basa en Hadoop - http://hadoop.apache.org Cassandra : http://cassandra.apache.org Amazon SimpleDB: http://aws.amazon.com/simpledb Grafos \u00b6 Las bases de datos de grafos almacenan entidades y las relaciones entre estas entidades. Las entidades se conocen como nodos, los cuales tienen propiedades. Cada nodo es similar a una instancia de un objeto. Las relaciones, tambi\u00e9n conocidas como v\u00e9rtices, a su vez tienen propiedades, y su sentido es importante. Los nodos se organizan mediante relaciones que facilitan encontrar patrones de informaci\u00f3n existente entre los nodos. Este tipo de organizaci\u00f3n permite almacenar los datos una vez e interpretar los datos de diferentes maneras dependiendo de sus relaciones. Los nodos son entidades que tienen propiedades, tales como el nombre. Por ejemplo, en el gr\u00e1fico cada nodo tiene una propiedad nombre. Tambi\u00e9n podemos ver que las relaciones tienen tipos, como likes, author, etc\u2026\u200b Estas propiedades permiten organizar los nodos. Las relaciones pueden tener m\u00faltiples propiedades, y adem\u00e1s tienen direcci\u00f3n, con lo cual si queremos incluir bidireccionalidad tenemos que a\u00f1adir dos relaciones en sentidos opuestos. Creando un grafo mediante Neo4J: ``` java Node martin = graphDb.createNode(); martin.setProperty(\"name\", \"Martin\"); Node pramod = graphDb.createNode(); pramod.setProperty(\"name\", \"Pramod\"); martin.createRelationshipTo(pramod, FRIEND); pramod.createRelationshipTo(martin, FRIEND); ``` Los nodos permiten tener diferentes tipos de relaciones entre ellos y as\u00ed representar relaciones entre las entidades del dominio, y tener relaciones secundarias para caracter\u00edsticas como categor\u00eda, camino, \u00e1rboles de tiempo, listas enlazas para acceso ordenado, etc\u2026\u200b Al no existir un l\u00edmite en el n\u00famero ni en el tipo de relaciones que puede tener un nodo, todas se pueden representar en la misma base de datos. Traversing \u00b6 Una vez tenemos creado un grafo de nodos y relaciones, podemos consultar el grafo de muchas maneras; por ejemplo \"obtener todos los nodos que trabajan para Big Co y que les gusta NoSQL Distilled\". Realizar una consulta se conoce como hacer un traversing (recorrido) del mismo. Ejemplo de Traversing mediante Neo4J: java Node martin = nodeIndex.get(\"name\", \"Martin\").getSingle(); allRelationships = martin.getRelationships(Direction.INCOMING); Una ventaja a destacar de las bases de datos basadas en grafos es que podemos cambiar los requisitos de traversing sin tener que cambiar los nodos o sus relaciones. En las bases de datos de grafos, recorrer las relaciones es muy r\u00e1pido, ya que no se calculan en tiempo de consulta, sino que se persisten como una relaci\u00f3n, y por tanto no hay que hacer ning\u00fan c\u00e1lculo. En cambio, en una base de datos relacional, para crear una estructura de grafo se realiza para una relaci\u00f3n sencilla (\u00bfQuien es mi jefe?\"). Para poder a\u00f1adir otras relaciones necesitamos muchos cambios en el esquema y trasladar datos entre tablas. Adem\u00e1s, necesitamos de antemano saber que consultar queremos realizar para modelar las tablas y las relaciones acorde a las consultas. As\u00ed pues, estos sistemas ofrecen ricos modelos de consultas donde se pueden investigar las relaciones simples y complejas entre los nodos para obtener informaci\u00f3n directa e indirecta de los datos del sistemas. Los tipos de an\u00e1lisis que se realizan sobre estos sistema se ci\u00f1en a los tipos de relaci\u00f3n existente entre los datos. Casos de uso \u00b6 Mientras que el modelo de grafos no es muy intuitivo y tiene una importante curva de aprendizaje, se puede usar en un gran n\u00famero de aplicaciones. Su principal atractivo es que facilitan almacenar las relaciones entre entidades de una aplicaci\u00f3n, como por ejemplo de una red social, o las intersecciones existentes entre carreteras. Es decir, se emplean para almacenar datos que se representan como nodos interconectados. Por lo tanto, los casos de uso son: Datos conectados: redes sociales con diferentes tipos de conexiones entre los usuarios. Enrutamiento, entrega o servicios basados en la posici\u00f3n: si las relaciones almacenan la distancia entre los nodos, podemos realizar consultas sobre lugares cercanos, trayecto m\u00e1s corto, etc\u2026\u200b Motores de recomendaciones: de compras, de lugares visitados, etc\u2026\u200b En cambio, no se recomienda su uso cuando necesitemos modificar todos o un subconjunto de entidades, ya que modificar una propiedad en todos los nodos es una operaci\u00f3n compleja. Los productos m\u00e1s destacados son: Neo4j: http://neo4j.com FlockDB: https://github.com/twitter/flockdb HyperGraphDB: http://www.hypergraphdb.org/index Consistencia \u00b6 En un sistema consistente, las escrituras de una aplicaci\u00f3n son visibles en siguientes consultas. Con una consistencia eventual, las escrituras no son visibles inmediatamente. Por ejemplo, en un sistema de control de stock, si el sistema es consistente, cada consulta obtendr\u00e1 el estado real del inventario, mientras que si tiene consistencia eventual, puede que no sea el estado real en un momento concreto pero terminar\u00e1 si\u00e9ndolo en breve. Sistemas consistentes \u00b6 Cada aplicaci\u00f3n tiene diferentes requisitos para la consistencia de los datos. Para muchas aplicaciones, es imprescindible que los datos sean consistentes en todo momento. Como los equipos de desarrollo han estado trabajo con un modelo de datos relacional durante d\u00e9cadas, este enfoque parece natural. Sin embargo, en otras ocasiones, la consistencia eventual es un traspi\u00e9s aceptable si conlleva una mayor flexibilidad en la disponibilidad del sistema. Las bases de datos documentales y de grafos pueden ser consistentes o eventualmente consistentes. Por ejemplo, MongoDB ofrece un consistencia configurable. De manera predeterminada, los datos son consistentes, de modo que todas las escrituras y lecturas se realizan sobre la copia principal de los datos. Pero como opci\u00f3n, las consultas de lectura, se pueden realizar con las copias secundarias donde los datos tendr\u00e1n consistencia eventual. La elecci\u00f3n de la consistencia se realiza a nivel de consulta. Sistemas de consistencia eventual \u00b6 Con los sistemas eventualmente consistentes, hay un per\u00edodo de tiempo en el que todas las copias de los datos no est\u00e1n sincronizados. Esto puede ser aceptable para aplicaciones de s\u00f3lo-lectura y almacenes de datos que no cambian frecuentemente, como los archivos hist\u00f3ricos. Dentro del mismo saco podemos meter las aplicaciones con alta tasa de escritura donde las lecturas sean poco frecuentes, como un archivo de log. Un claro ejemplo de sistema eventualmente consistente es el servicio DNS, donde tras registrar un dominio, puede tardar varios d\u00edas en propagar los datos a trav\u00e9s de Internet, pero siempre est\u00e1n disponibles aunque contenga una versi\u00f3n antigua de los datos. Respecto a las bases de datos NoSQL, los almacenes de clave-valor y los basados en columnas son sistemas eventualmente consistentes. Estos tienen que soportar conflictos en las actualizaciones de registros individuales. Como las escrituras se pueden aplicar a cualquier copia de los datos, puede ocurrir, y no ser\u00eda muy extra\u00f1o, que hubiese un conflicto de escritura. Algunos sistemas como Riak utilizan vectores de reloj para determinar el orden de los eventos y asegurar que la operaci\u00f3n m\u00e1s reciente gana en caso de un conflicto. Otros sistemas como CouchDB, retienen todos los valores conflictivos y permiten al usuario resolver el conflicto. Otro enfoque seguido por Cassandra sencillamente asume que el valor m\u00e1s grande es el correcto. Por estos motivos, las escrituras tienden a comportarse bien en sistemas eventualmente consistentes, pero las actualizaciones pueden conllevar sacrificios que complican la aplicaci\u00f3n. Teorema de CAP \u00b6 Propuesto por Eric Brewer en el a\u00f1o 2000, prueba que podemos crear una base de datos distribuida que elija dos de las siguientes tres caracter\u00edsticas: C onsistencia: las escrituras son at\u00f3micas y todas las peticiones posteriores obtienen el nuevo valor, independientemente del lugar de la petici\u00f3n. Disponibilidad ( A vailable ): la base de datos devolver\u00e1 siempre un valor. En la pr\u00e1ctica significa que no hay downtime. Tolerancia a P articiones: el sistema funcionar\u00e1 incluso si la comunicaci\u00f3n con un servidor se interrumpe de manera temporal (para ello, ha de dividir los datos entre diferentes nodos). En otras palabras, podemos crear un sistema de base de datos que sea consistente y tolerante a particiones (CP), un sistema que sea disponible y tolerante a particiones (AP), o un sistema que sea consistente y disponible (CA). Pero no es posible crear una base de datos distribuida que sea consistente, disponible y tolerante a particiones al mismo tiempo. Teorema de CAP El teorema CAP es \u00fatil cuando consideramos el sistema de base de datos que necesitamos, ya que nos permite decidir cual de las tres caracter\u00edsticas vamos a descartar. La elecci\u00f3n realmente se centra entre la disponibilidad y la consistencia, ya que la tolerancia a particiones es una decisi\u00f3n de arquitectura (sea o no distribuida). Aunque el teorema dicte que si en un sistema distribuido elegimos disponibilidad no podemos tener consistencia, todav\u00eda podemos obtener consistencia eventual. Es decir, cada nodo siempre estar\u00e1 disponible para servir peticiones, aunque estos nodos no puedan asegurar que la informaci\u00f3n que contienen sea consistente (pero si bastante precisa), en alg\u00fan momento lo ser\u00e1. Algunas bases de datos tolerantes a particiones se pueden ajustar para ser m\u00e1s o menos consistentes o disponible a nivel de petici\u00f3n. Por ejemplo, Riak trabaja de esta manera, permitiendo a los clientes decidir en tiempo de petici\u00f3n que nivel de consistencia necesitan. Clasificaci\u00f3n seg\u00fan CAP \u00b6 El siguiente gr\u00e1fico muestra como dependiendo de estos atributos podemos clasificar los sistemas NoSQL: Clasificaci\u00f3n seg\u00fan CAP As\u00ed pues, las bases de datos NoSQL se clasifican en: CP : Consistente y tolerantes a particiones. Tanto MongoDB como HBase son CP, ya que dentro de una partici\u00f3n pueden no estar disponibles para responder una determinada consulta (por ejemplo, evitando lecturas en los nodos esclavo), aunque son tolerantes a fallos porque cualquier nodo secundario se puede convertir en principal y asumir el rol del nodo ca\u00eddo. AP : Disponibles y tolerantes a particiones. CouchDB permite replicar los datos entre sus nodos aunque no garantiza la consistencia en ninguno de los sus servidores. CA : Consistentes y disponible. Aqu\u00ed es donde situar\u00edamos a los SGDB relacionales. Por ejemplo, Redis, PostreSQL y Neo4J son CA, ya que no distribuyen los datos y por tanto la partici\u00f3n no es una restricci\u00f3n. Lo bueno es que la gran mayor\u00eda de sistemas permiten configurarse para cambiar su tipo CAP, lo que permite que MongoDB pase de CP a AP, o CouchDB de AP a CP. Referencias \u00b6 Actividades \u00b6 Cuestionario (RA5075.2 / CE5.2a / 2p) Alguna cuesti\u00f3n sobre ingenier\u00eda de datos. Catalogar diferentes supuestos entre los diferentes tipos de sistemas de almacenamiento, tanto relacionales como no relacionales. \u00bfQu\u00e9 significa el prefijo No del acr\u00f3nimo NoSQL? \u00bfUn sistema puede soportar al mismo tiempo replicaci\u00f3n y particionado? Para los siguientes supuestos, indica qu\u00e9 modelo de datos emplear\u00edas y justifica tu respuesta: Enciclopedia de personajes de c\u00f3mic Usuarios, perfiles, biblioteca de juegos, puntuaciones, etc\u2026\u200b de una plataforma de gaming Informaci\u00f3n acad\u00e9mica de un pa\u00eds (centros, alumnos, profesores, asignaturas, calificaciones, \u2026\u200b) Investiga en qu\u00e9 consiste la \"persistencia pol\u00edglota\". Clasifica las siguientes bases de datos en CP o AP: BigTable, BerkeleyDB, Cassandra, CouchDB, Dynamo, Hbase, Hypertable, KAI, MemcachedDB, MongoDB, Redis, Riak, Scalaris, SimpleDB, Terrastore, Tokyo, Cabinet y Voldemort. Investigaci\u00f3n (RA5075.3 / CE5.3a / 2p) Crear una presentaci\u00f3n de 5-6 diapositivas donde expliquen en qu\u00e9 consiste el sharding y como influye en la escalabilidad y la integridad de los datos.","title":"S18.- Ingenier\u00eda de datos / NoSQL"},{"location":"sa/01nosql.html#ingenieria-de-datos","text":"","title":"Ingenier\u00eda de Datos"},{"location":"sa/01nosql.html#no-solo-sql","text":"Si definimos NoSQL formalmente, podemos decir que se trata de un conjunto de tecnolog\u00edas que permiten el procesamiento r\u00e1pido y eficiente de conjuntos de datos dando la mayor importancia al rendimiento, la fiabilidad y la agilidad. Si nos basamos en el acr\u00f3nimo, el t\u00e9rmino se refiere a cualquier almac\u00e9n de datos que no sigue un modelo relacional, los datos no son relacionales y por tanto no utilizan SQL como lenguaje de consulta. As\u00ed pues, los sistemas NoSQL se centran en sistemas complementarios a los SGBD relacionales, que fijan sus prioridades en la escalabilidad y la disponibilidad en contra de la atomicidad y consistencia de los datos. NoSQL aparece como una necesidad debida al creciente volumen de datos sobre usuarios, objetos y productos que las empresas tienen que almacenar, as\u00ed como la frecuencia con la que se accede a los datos. Los SGDB relacionales existentes no fueron dise\u00f1ados teniendo en cuenta la escalabilidad ni la flexibilidad necesaria por las frecuentes modificaciones que necesitan las aplicaciones modernas; tampoco aprovechan que el almacenamiento a d\u00eda de hoy es muy barato, ni el nivel de procesamiento que alcanzan las m\u00e1quinas actuales. Los diferentes tipos de bases de datos NoSQL existentes se pueden agrupar en cuatro categor\u00edas: Clave-Valor : Los almacenes clave-valor son las bases de datos NoSQL m\u00e1s simples. Cada elemento de la base de datos se almacena con un nombre de atributo (o clave) junto a su valor. Los almacenes m\u00e1s conocidos son Redis, Riak y Voldemort. Algunos almacenes, como es el caso de Redis, permiten que cada valor tenga un tipo (por ejemplo, integer) lo cual a\u00f1ade funcionalidad extra. Documentales : Cada clave se asocia a una estructura compleja que se conoce como documento. Este puede contener diferentes pares clave-valor, o pares de clave-array o incluso documentos anidados, como en un documento JSON. Los ejemplos m\u00e1s conocidos son MongoDB y CouchDB. Grafos : Los almacenes de grafos se usan para almacenar informaci\u00f3n sobre redes, como pueden ser conexiones sociales. Los ejemplos m\u00e1s conocidos son Neo4J, FlockDB, InfiniteGraph y HyperGraphDB. Basados en columnas : Los almacenes basados en columnas como BigTable, Hadoop, Cassandra y HBase est\u00e1n optimizados para consultas sobre grandes conjuntos de datos, y almacenan los datos como columnas, en vez de como filas, de modo que cada fila puede contener un n\u00famero diferente de columnas. Sistemas NoSQL","title":"No S\u00f3lo SQL"},{"location":"sa/01nosql.html#esquema-dinamicos","text":"Las bases de datos relacionales requieren definir los esquemas antes de a\u00f1adir los datos. Una base de datos SQL necesita saber de antemano los datos que vamos a almacenar; por ejemplo, si nos centramos en los datos de un cliente, ser\u00edan el nombre, apellidos, n\u00famero de tel\u00e9fono, etc\u2026\u200b Esto casa bastante mal con los enfoques de desarrollo \u00e1gil, ya que cada vez que a\u00f1adimos nuevas funcionalidades, el esquema de la base de datos suele cambiar. De modo que si a mitad de desarrollo decidimos almacenar los productos favoritos de un cliente del cual guard\u00e1bamos su direcci\u00f3n y n\u00fameros de tel\u00e9fono, tendr\u00edamos que a\u00f1adir una nueva columna a la base de datos y migrar la base de datos entera a un nuevo esquema. Si la base de datos es grande, conlleva un proceso lento que implica parar el sistema durante un tiempo considerable. Si frecuentemente cambiamos los datos que la aplicaci\u00f3n almacena (al usar un desarrollo iterativo), tambi\u00e9n tendremos per\u00edodos frecuentes de inactividad del sistema. As\u00ed pues, no hay un modo efectivo mediante una base de datos relacional, de almacenar los datos que est\u00e1n desestructurados o que no se conocen de antemano. Las bases de datos NoSQL se construyen para permitir la inserci\u00f3n de datos sin un esquema predefinido. Esto facilita la modificaci\u00f3n de la aplicaci\u00f3n en tiempo real, sin preocuparse por interrupciones de servicio. De este modo se consigue un desarrollo m\u00e1s r\u00e1pido, integraci\u00f3n de c\u00f3digo m\u00e1s robusto y menos tiempo empleado en la administraci\u00f3n de la base de datos.","title":"Esquema din\u00e1micos"},{"location":"sa/01nosql.html#particionado","text":"Dado el modo en el que se estructuran las bases de datos relacionales, normalmente escalan verticalmente - un \u00fanico servidor que almacena toda la base de datos para asegurar la disponibilidad continua de los datos. Esto se traduce en costes que se incrementan r\u00e1pidamente, con un l\u00edmites definidos por el propio hardware, y en un peque\u00f1o n\u00famero de puntos cr\u00edticos de fallo dentro de la infraestructura de datos. La soluci\u00f3n es escalar horizontalmente, a\u00f1adiendo nuevos servidores en vez de concentrarse en incrementar la capacidad de un \u00fanico servidor. Este escalado horizontal se conoce como Sharding o Particionado. Particionado de los datos El particionado no es \u00fanico de las bases de datos NoSQL. Las bases de datos relacionales tambi\u00e9n lo soportan. Si en un sistema relacional queremos particionar los datos, podemos distinguir entre particionado: Horizontal : diferentes filas en diferentes particiones. Vertical : diferentes columnas en particiones distintas. En el caso de las bases de datos NoSQL, el particionado depende del modelo de la base de datos: Los almacenes clave-valor y las bases de datos documentales normalmente se particionan horizontalmente. Las bases de datos basados en columnas se pueden particionar horizontal o verticalmente. Escalar horizontalmente una base de datos relacional entre muchas instancias de servidores se puede conseguir pero normalmente conlleva el uso de SANs ( Storage Area Networks ) y otras triqui\u00f1uelas para hacer que el hardware act\u00fae como un \u00fanico servidor. Como los sistemas SQL no ofrecen esta prestaci\u00f3n de forma nativa, los equipos de desarrollo se las tienen que ingeniar para conseguir desplegar m\u00faltiples bases de datos relacionales en varias m\u00e1quinas. Para ello: Los datos se almacenan en cada instancia de base de datos de manera aut\u00f3noma El c\u00f3digo de aplicaci\u00f3n se desarrolla para distribuir los datos y las consultas y agregar los resultados de los datos a trav\u00e9s de todas las instancias de bases de datos Se debe desarrollar c\u00f3digo adicional para gestionar los fallos sobre los recursos, para realizar joins entre diferentes bases de datos, balancear los datos y/o replicarlos, etc\u2026\u200b Adem\u00e1s, muchos beneficios de las bases de datos como la integridad transaccional se ven comprometidos o incluso eliminados al emplear un escalado horizontal.","title":"Particionado"},{"location":"sa/01nosql.html#replicacion","text":"a replicaci\u00f3n mantiene copias id\u00e9nticas de los datos en m\u00faltiples servidores, lo que facilita que las aplicaciones siempre funcionen y los datos se mantengan seguros, incluso si alguno de los servidores sufre alg\u00fan problema. La mayor\u00eda de las bases de datos NoSQL tambi\u00e9n soportan la replicaci\u00f3n autom\u00e1tica, lo que implica una alta disponibilidad y recuperaci\u00f3n frente a desastres sin la necesidad de aplicaciones de terceros encargadas de ello. Desde el punto de vista del desarrollador, el entorno de almacenamiento es virtual y ajeno al c\u00f3digo de aplicaci\u00f3n. Replicaci\u00f3n de los datos La replicaci\u00f3n de los datos se utiliza para alcanzar: escalabilidad , incrementando el rendimiento al poder distribuir las consultas en diferentes nodos, y mejorar la rendundancia al permitir que cada nodo tenga una copia de los datos. disponibilidad , ofreciendo tolerancia a fallos de hardware o corrupci\u00f3n de la base de datos. Al replicar los datos vamos a poder tener una copia de la base de datos, dar soporte a un servidor de datos agregados, o tener nodos a modo de copias de seguridad que pueden tomar el control en caso de fallo. aislamiento (la i en ACID - isolation ), entendido como la propiedad que define cuando y c\u00f3mo al realizar cambios en un nodo se propagan al resto de nodos. Si replicamos los datos podemos crear copias sincronizadas que separar procesos de la base de datos de producci\u00f3n, pudiendo ejecutar informes o copias de seguridad en nodos secundarios de modo que no tenga un impacto negativo en el nodo principal, as\u00ed como ofrecer un sistema sencillo para separar el entorno de producci\u00f3n del de preproducci\u00f3n. Replicaci\u00f3n vs particionado No hay que confundir la replicaci\u00f3n (copia de los datos en varias m\u00e1quinas) con la partici\u00f3n (cada m\u00e1quina tiene un subconjunto de los datos). El entorno m\u00e1s seguro y con mejor rendimiento es aquel que tiene los datos particionados y replicados (cada maquina que tiene un subconjunto de los datos est\u00e1 replicada en 2 o m\u00e1s).","title":"Replicaci\u00f3n"},{"location":"sa/01nosql.html#implantando-nosql","text":"Normalmente, las empresas empezar\u00e1n con una prueba de baja escalabilidad de una base de datos NoSQL, de modo que les permita comprender la tecnolog\u00eda asumiendo muy poco riesgo. La mayor\u00eda de las bases de datos NoSQL tambi\u00e9n son open-source, y por tanto se pueden probar sin ning\u00fan coste extra. Al tener unos ciclos de desarrollo m\u00e1s r\u00e1pidos, las empresas pueden innovar con mayor velocidad y mejorar la experiencia de sus cliente a un menor coste. Elegir la base de datos correcta para el proyecto es un tema importante. Se deben considerar las diferentes alternativas a las infraestructuras legacy teniendo en cuenta varios factores: la escalabilidad o el rendimiento m\u00e1s all\u00e1 de las capacidades del sistema existente identificar alternativas viables respecto al software propietario incrementar la velocidad y agilidad del proceso de desarrollo As\u00ed pues, al elegir un base de datos hemos de tener en cuenta las siguientes dimensiones: Modelo de Datos: A elegir entre un modelo documental, basado en columnas, de grafos o mediante clave-valor. Modelo de Consultas: Dependiendo de la aplicaci\u00f3n, puede ser aceptable un modelo de consultas que s\u00f3lo accede a los registros por su clave primaria. En cambio, otras aplicaciones pueden necesitar consultar por diferentes valores de cada registro. Adem\u00e1s, si la aplicaci\u00f3n necesita modificar los registros, la base de datos necesita consultar los datos por un \u00edndice secundario. Modelo de Consistencia: Los sistemas NoSQL normalmente mantienen m\u00faltiples copias de los datos para ofrecer disponibilidad y escalabilidad al sistema, lo que define la consistencia del mismo. Los sistemas NoSQL tienden a ser consistentes o eventualmente consistentes. APIs: No existe un est\u00e1ndar para interactuar con los sistemas NoSQL. Cada sistema presenta diferentes dise\u00f1os y capacidades para los equipos de desarrollo. La madurez de un API puede suponer una inversi\u00f3n en tiempo y dinero a la hora de desarrollar y mantener el sistema NoSQL. Soporte Comercial y de la Comunidad: Los usuarios deben considerar la salud de la compa\u00f1ia o de los proyectos al evaluar una base de datos. El producto debe evolucionar y se mantenga para introducir nuevas prestaciones y corregir fallos. Una base de datos con una comunidad fuerte de usuarios: permite encontrar y contratar desarrolladores con destrezas en el producto. facilita encontrar informaci\u00f3n, documentaci\u00f3n y ejemplos de c\u00f3digo. ayuda a las empresas a retener el talento. favorece que otras empresas de software integren sus productos y participen en el ecosistema de la base de datos.","title":"Implantando NoSQL"},{"location":"sa/01nosql.html#modelos-de-datos","text":"La principal clasificaci\u00f3n de los sistemas de BBDD NoSQL se realiza respecto a los diferentes modelos de datos:","title":"Modelos de Datos"},{"location":"sa/01nosql.html#documental","text":"Mientras las bases de datos relacionales almacenan los datos en filas y columnas, las bases de datos documentales emplean documentos. Estos documentos utilizan una estructura JSON, ofreciendo un modo natural e intuitivo para modelar datos de manera similar a la orientaci\u00f3n a objetos, donde cada documento es un objeto. Representaci\u00f3n de un documento Los documentos se agrupan en colecciones o bases de datos, dependiendo del sistema, lo que permite agrupar documentos. Los documentos contienen uno o m\u00e1s campos, donde cada campo contiene un valor con un tipo, ya sea cadena, fecha, binario o array. En vez de extender los datos entre m\u00faltiples columnas y tablas, cada registro y sus datos asociados se almacenan de manera unida en un \u00fanico documento. Esto simplifica el acceso a los datos y reduce (y en ocasiones elimina) la necesidad de joins y transacciones complejas.","title":"Documental"},{"location":"sa/01nosql.html#clave-valor","text":"Un almac\u00e9n clave-valor es una simple tabla hash donde todos los accesos a la base de datos se realizan a trav\u00e9s de la clave primaria. Desde una perspectiva de modelo de datos, los almacenes de clave-valor son los m\u00e1s b\u00e1sicos. Su funcionamiento es similar a tener una tabla relacional con dos columnas, por ejemplo id y nombre, siendo id la columna utilizada como clave y nombre como valor. Mientras que en una base de datos en el campo nombre s\u00f3lo podemos almacenar datos de tipo cadena, en un almac\u00e9n clave-valor, el valor puede ser de un dato simple o un objeto. Cuando una aplicaci\u00f3n accede mediante la clave y el valor, se almacenan el par de elementos. Si la clave ya existe, el valor se modifica. Representaci\u00f3n de un almac\u00e9n clave-valor El cliente puede tanto obtener el valor por la clave, asignar un valor a una clave o eliminar una clave del almac\u00e9n. El valor, sin embargo, es opaco al sistema, el cual no sabe que hay dentro de \u00e9l, ya que los datos s\u00f3lo se pueden consultar por la clave, lo cual puede ser un inconveniente. As\u00ed pues, la aplicaci\u00f3n es responsable de saber qu\u00e9 hay almacenado en cada valor. python Codigo de ejemplo de acceso s un bucket y b\u00fasqueda en Redis Riak utiliza el concepto de bucket (cubo) como una manera de agrupar claves, de manera similar a una tabla Interactuando con Riak medianta HTTP curl -v -X PUT http://localhost:8091/riak/heroes/ace -H \"Content-Type: application/json\" -d {\"nombre\" : \"Batman\", \"color\" : \"Negro\"} Algunos almacenes clave-valor, como puede ser Redis, permiten almacenar datos con cualquier estructura, como por ejemplos listas, conjuntos, hashes y pueden realizar operaciones como intersecci\u00f3n, uni\u00f3n, diferencia y rango. redis SET nombre \"Bruce Wayne\" //String HSET heroe nombre \"Batman\" // Hash \u2013 set HSET heroe color \"Negro\" SADD \"heroe:amigos\" \"Robin\" \"Alfred\" // Set \u2013 create/update Estas prestaciones hacen que Redis se extrapole a \u00e1mbitos ajenos a un almac\u00e9n clave-valor. Otra caracter\u00edstica que ofrecen algunos almacenes es que permiten crear un segundo nivel de consulta o incluso definir m\u00e1s de una clave para un mismo objeto. Como los almacenes clave-valor siempre utilizan accesos por clave primaria, de manera general tienen un gran rendimiento y son f\u00e1cilmente escalables. Si queremos que su rendimiento sea m\u00e1ximo, pueden configurarse para que mantegan la informaci\u00f3n en memoria y que se serialice de manera peri\u00f3dica, a costa de tener una consistencia eventual de los datos.","title":"Clave-Valor"},{"location":"sa/01nosql.html#basado-en-columnas","text":"Tambi\u00e9n conocidos como sistemas Big Data o tabulares. Su nombre viene tras la implementaci\u00f3n de Google de BigTable ( http://research.google.com/archive/bigtable.html ), el cual consiste en columnas separadas y sin esquema, a modo de mapa de dos niveles. Las bases de datos relacionales utilizan la fila como unidad de almacenamiento, lo que permite un buen rendimiento de escritura. Sin embargo, cuando las escrituras son ocasionales y es m\u00e1s comun tener que leer unas pocas columnas de muchas filas a la vez, es mejor utilizar como unidad de almacenamiento a grupos de columnas. Un modelo basado en columnas se representa como una estructura agregada de dos niveles. El primer nivel formado por un almac\u00e9n clave-valor, siendo la clave el identificador de la fila, y el valor un nuevo mapa con los datos agregados de la fila (familias de columnas). Los valores de este segundo nivel son las columnas. De este modo, podemos acceder a los datos de un fila, o a una determinada columna: Representaci\u00f3n de un almac\u00e9n basado en columnas Los almacenes basados en columnas utilizan un mapa ordenado multi-dimensional y distribuido para almacenar los datos. Est\u00e1n pensados para que cada fila tenga una gran n\u00famero de columnas (del orden del mill\u00f3n), almacenando las diferentes versiones que tenga una fila (pudiendo almacenar del orden de miles de millones de filas).","title":"Basado en columnas"},{"location":"sa/01nosql.html#grafos","text":"Las bases de datos de grafos almacenan entidades y las relaciones entre estas entidades. Las entidades se conocen como nodos, los cuales tienen propiedades. Cada nodo es similar a una instancia de un objeto. Las relaciones, tambi\u00e9n conocidas como v\u00e9rtices, a su vez tienen propiedades, y su sentido es importante. Los nodos se organizan mediante relaciones que facilitan encontrar patrones de informaci\u00f3n existente entre los nodos. Este tipo de organizaci\u00f3n permite almacenar los datos una vez e interpretar los datos de diferentes maneras dependiendo de sus relaciones. Los nodos son entidades que tienen propiedades, tales como el nombre. Por ejemplo, en el gr\u00e1fico cada nodo tiene una propiedad nombre. Tambi\u00e9n podemos ver que las relaciones tienen tipos, como likes, author, etc\u2026\u200b Estas propiedades permiten organizar los nodos. Las relaciones pueden tener m\u00faltiples propiedades, y adem\u00e1s tienen direcci\u00f3n, con lo cual si queremos incluir bidireccionalidad tenemos que a\u00f1adir dos relaciones en sentidos opuestos. Creando un grafo mediante Neo4J: ``` java Node martin = graphDb.createNode(); martin.setProperty(\"name\", \"Martin\"); Node pramod = graphDb.createNode(); pramod.setProperty(\"name\", \"Pramod\"); martin.createRelationshipTo(pramod, FRIEND); pramod.createRelationshipTo(martin, FRIEND); ``` Los nodos permiten tener diferentes tipos de relaciones entre ellos y as\u00ed representar relaciones entre las entidades del dominio, y tener relaciones secundarias para caracter\u00edsticas como categor\u00eda, camino, \u00e1rboles de tiempo, listas enlazas para acceso ordenado, etc\u2026\u200b Al no existir un l\u00edmite en el n\u00famero ni en el tipo de relaciones que puede tener un nodo, todas se pueden representar en la misma base de datos.","title":"Grafos"},{"location":"sa/01nosql.html#consistencia","text":"En un sistema consistente, las escrituras de una aplicaci\u00f3n son visibles en siguientes consultas. Con una consistencia eventual, las escrituras no son visibles inmediatamente. Por ejemplo, en un sistema de control de stock, si el sistema es consistente, cada consulta obtendr\u00e1 el estado real del inventario, mientras que si tiene consistencia eventual, puede que no sea el estado real en un momento concreto pero terminar\u00e1 si\u00e9ndolo en breve.","title":"Consistencia"},{"location":"sa/01nosql.html#sistemas-consistentes","text":"Cada aplicaci\u00f3n tiene diferentes requisitos para la consistencia de los datos. Para muchas aplicaciones, es imprescindible que los datos sean consistentes en todo momento. Como los equipos de desarrollo han estado trabajo con un modelo de datos relacional durante d\u00e9cadas, este enfoque parece natural. Sin embargo, en otras ocasiones, la consistencia eventual es un traspi\u00e9s aceptable si conlleva una mayor flexibilidad en la disponibilidad del sistema. Las bases de datos documentales y de grafos pueden ser consistentes o eventualmente consistentes. Por ejemplo, MongoDB ofrece un consistencia configurable. De manera predeterminada, los datos son consistentes, de modo que todas las escrituras y lecturas se realizan sobre la copia principal de los datos. Pero como opci\u00f3n, las consultas de lectura, se pueden realizar con las copias secundarias donde los datos tendr\u00e1n consistencia eventual. La elecci\u00f3n de la consistencia se realiza a nivel de consulta.","title":"Sistemas consistentes"},{"location":"sa/01nosql.html#sistemas-de-consistencia-eventual","text":"Con los sistemas eventualmente consistentes, hay un per\u00edodo de tiempo en el que todas las copias de los datos no est\u00e1n sincronizados. Esto puede ser aceptable para aplicaciones de s\u00f3lo-lectura y almacenes de datos que no cambian frecuentemente, como los archivos hist\u00f3ricos. Dentro del mismo saco podemos meter las aplicaciones con alta tasa de escritura donde las lecturas sean poco frecuentes, como un archivo de log. Un claro ejemplo de sistema eventualmente consistente es el servicio DNS, donde tras registrar un dominio, puede tardar varios d\u00edas en propagar los datos a trav\u00e9s de Internet, pero siempre est\u00e1n disponibles aunque contenga una versi\u00f3n antigua de los datos. Respecto a las bases de datos NoSQL, los almacenes de clave-valor y los basados en columnas son sistemas eventualmente consistentes. Estos tienen que soportar conflictos en las actualizaciones de registros individuales. Como las escrituras se pueden aplicar a cualquier copia de los datos, puede ocurrir, y no ser\u00eda muy extra\u00f1o, que hubiese un conflicto de escritura. Algunos sistemas como Riak utilizan vectores de reloj para determinar el orden de los eventos y asegurar que la operaci\u00f3n m\u00e1s reciente gana en caso de un conflicto. Otros sistemas como CouchDB, retienen todos los valores conflictivos y permiten al usuario resolver el conflicto. Otro enfoque seguido por Cassandra sencillamente asume que el valor m\u00e1s grande es el correcto. Por estos motivos, las escrituras tienden a comportarse bien en sistemas eventualmente consistentes, pero las actualizaciones pueden conllevar sacrificios que complican la aplicaci\u00f3n.","title":"Sistemas de consistencia eventual"},{"location":"sa/01nosql.html#teorema-de-cap","text":"Propuesto por Eric Brewer en el a\u00f1o 2000, prueba que podemos crear una base de datos distribuida que elija dos de las siguientes tres caracter\u00edsticas: C onsistencia: las escrituras son at\u00f3micas y todas las peticiones posteriores obtienen el nuevo valor, independientemente del lugar de la petici\u00f3n. Disponibilidad ( A vailable ): la base de datos devolver\u00e1 siempre un valor. En la pr\u00e1ctica significa que no hay downtime. Tolerancia a P articiones: el sistema funcionar\u00e1 incluso si la comunicaci\u00f3n con un servidor se interrumpe de manera temporal (para ello, ha de dividir los datos entre diferentes nodos). En otras palabras, podemos crear un sistema de base de datos que sea consistente y tolerante a particiones (CP), un sistema que sea disponible y tolerante a particiones (AP), o un sistema que sea consistente y disponible (CA). Pero no es posible crear una base de datos distribuida que sea consistente, disponible y tolerante a particiones al mismo tiempo. Teorema de CAP El teorema CAP es \u00fatil cuando consideramos el sistema de base de datos que necesitamos, ya que nos permite decidir cual de las tres caracter\u00edsticas vamos a descartar. La elecci\u00f3n realmente se centra entre la disponibilidad y la consistencia, ya que la tolerancia a particiones es una decisi\u00f3n de arquitectura (sea o no distribuida). Aunque el teorema dicte que si en un sistema distribuido elegimos disponibilidad no podemos tener consistencia, todav\u00eda podemos obtener consistencia eventual. Es decir, cada nodo siempre estar\u00e1 disponible para servir peticiones, aunque estos nodos no puedan asegurar que la informaci\u00f3n que contienen sea consistente (pero si bastante precisa), en alg\u00fan momento lo ser\u00e1. Algunas bases de datos tolerantes a particiones se pueden ajustar para ser m\u00e1s o menos consistentes o disponible a nivel de petici\u00f3n. Por ejemplo, Riak trabaja de esta manera, permitiendo a los clientes decidir en tiempo de petici\u00f3n que nivel de consistencia necesitan.","title":"Teorema de CAP"},{"location":"sa/01nosql.html#clasificacion-segun-cap","text":"El siguiente gr\u00e1fico muestra como dependiendo de estos atributos podemos clasificar los sistemas NoSQL: Clasificaci\u00f3n seg\u00fan CAP As\u00ed pues, las bases de datos NoSQL se clasifican en: CP : Consistente y tolerantes a particiones. Tanto MongoDB como HBase son CP, ya que dentro de una partici\u00f3n pueden no estar disponibles para responder una determinada consulta (por ejemplo, evitando lecturas en los nodos esclavo), aunque son tolerantes a fallos porque cualquier nodo secundario se puede convertir en principal y asumir el rol del nodo ca\u00eddo. AP : Disponibles y tolerantes a particiones. CouchDB permite replicar los datos entre sus nodos aunque no garantiza la consistencia en ninguno de los sus servidores. CA : Consistentes y disponible. Aqu\u00ed es donde situar\u00edamos a los SGDB relacionales. Por ejemplo, Redis, PostreSQL y Neo4J son CA, ya que no distribuyen los datos y por tanto la partici\u00f3n no es una restricci\u00f3n. Lo bueno es que la gran mayor\u00eda de sistemas permiten configurarse para cambiar su tipo CAP, lo que permite que MongoDB pase de CP a AP, o CouchDB de AP a CP.","title":"Clasificaci\u00f3n seg\u00fan CAP"},{"location":"sa/01nosql.html#referencias","text":"","title":"Referencias"},{"location":"sa/01nosql.html#actividades","text":"Cuestionario (RA5075.2 / CE5.2a / 2p) Alguna cuesti\u00f3n sobre ingenier\u00eda de datos. Catalogar diferentes supuestos entre los diferentes tipos de sistemas de almacenamiento, tanto relacionales como no relacionales. \u00bfQu\u00e9 significa el prefijo No del acr\u00f3nimo NoSQL? \u00bfUn sistema puede soportar al mismo tiempo replicaci\u00f3n y particionado? Para los siguientes supuestos, indica qu\u00e9 modelo de datos emplear\u00edas y justifica tu respuesta: Enciclopedia de personajes de c\u00f3mic Usuarios, perfiles, biblioteca de juegos, puntuaciones, etc\u2026\u200b de una plataforma de gaming Informaci\u00f3n acad\u00e9mica de un pa\u00eds (centros, alumnos, profesores, asignaturas, calificaciones, \u2026\u200b) Investiga en qu\u00e9 consiste la \"persistencia pol\u00edglota\". Clasifica las siguientes bases de datos en CP o AP: BigTable, BerkeleyDB, Cassandra, CouchDB, Dynamo, Hbase, Hypertable, KAI, MemcachedDB, MongoDB, Redis, Riak, Scalaris, SimpleDB, Terrastore, Tokyo, Cabinet y Voldemort. Investigaci\u00f3n (RA5075.3 / CE5.3a / 2p) Crear una presentaci\u00f3n de 5-6 diapositivas donde expliquen en qu\u00e9 consiste el sharding y como influye en la escalabilidad y la integridad de los datos.","title":"Actividades"},{"location":"sa/02mongo.html","text":"MongoDB \u00b6 MongoDB ( http://www.mongodb.com ) es una de las bases de datos NoSQL m\u00e1s conocidas. Sigue un modelo de datos documental, donde los documentos se basan en JSON. MongoDB destaca porque: Soporta esquemas din\u00e1micos: diferentes documentos de una misma colecci\u00f3n pueden tener atributos diferentes. No soporta joins, ya que no escalan bien. No soporta transacciones. Lo que en un SGDB puede suponer m\u00faltiples operaciones, con MongoDB se puede hacer en una sola operaci\u00f3n al insertar/actualizar todo un documento de una sola vez. Productos comerciales Hablar de Atlas y de las versiones Enterprise y Community Conceptos \u00b6 Hay una serie de conceptos que conviene conocer antes de entrar en detalle: MongoDB tienen el mismo concepto de base de datos que un SGDB. Dentro de una instancia de MongoDB podemos tener 0 o m\u00e1s bases de datos, actuando cada una como un contenedor de alto nivel. Una base de datos tendr\u00e1 0 o m\u00e1s colecciones. Una colecci\u00f3n es muy similar a lo que entendemos como tabla dentro de un SGDB. MongoDB ofrece diferentes tipos de colecciones, desde las normales cuyo tama\u00f1o crece conforme lo hace el n\u00famero de documentos, como las colecciones capped , las cuales tienen un tama\u00f1o predefinido y que pueden contener una cierta cantidad de informaci\u00f3n que se sustituir\u00e1 por nueva cuando se llene. Las colecciones contienen 0 o m\u00e1s documentos , por lo que es similar a una fila o registro de un RDMS. Cada documento contiene 0 o m\u00e1s atributos, compuestos de parejas clave/valor . Cada uno de estos documentos no sigue ning\u00fan esquema, por lo que dos documentos de una misma colecci\u00f3n pueden contener todos los atributos diferentes entre s\u00ed. Elementos de MongoDB As\u00ed pues, tenemos que una base de datos va a contener varias colecciones, donde cada colecci\u00f3n contendr\u00e1 un conjunto de documentos: Modelo de MongoDB Adem\u00e1s, MongoDB soporta \u00edndices , igual que cualquier SGDB, para acelerar la b\u00fasqueda de datos. Al realizar cualquier consulta, se devuelve un cursor , con el cual podemos hacer cosas tales como contar, ordenar, limitar o saltar documentos. BSON \u00b6 Mediante JavaScript podemos crear objetos que se representan con JSON. Internamente, MongoDB almacena los documentos mediante BSON ( Binary JSON ). Podemos consultar la especificaci\u00f3n en http://BSONSpec.org Especificaci\u00f3n BSON BSON representa un superset de JSON ya que: Permite almacenar datos en binario Incluye un conjunto de tipos de datos no incluidos en JSON, como pueden ser ObjectId , Date o BinData . Podemos consultar todos los tipos que soporta un objeto BSON en http://docs.mongodb.org/manual/reference/bson-types/ Un ejemplo de un objeto BSON podr\u00eda ser: json var yo = { nombre: \"Aitor\", apellidos: \"Medrano\", fnac: new Date(\"Oct 3, 1977\"), hobbies: [\"programaci\u00f3n\", \"videojuegos\", \"baloncesto\"], casado: true, hijos: 2, fechaCreacion = new Timestamp() } Los documentos BSON tienen las siguientes restricciones: No pueden tener un tama\u00f1o superior a 16 MB. El atributo _id queda reservado para la clave primaria. Los nombres de los campos no pueden empezar por $ . Los nombres de los campos no pueden contener el . Adem\u00e1s MongoDB: No asegura que el orden de los campos se respete. Es sensible a los tipos de los datos Es sensible a las may\u00fasculas. Por lo que estos documentos son distintos: json {\"edad\": \"18\"} {\"edad\": 18} {\"Edad\": 18} Si queremos validar si un documento JSON es v\u00e1lido, podemos usar http://jsonlint.com/ . Hemos de tener en cuenta que s\u00f3lo valida JSON y no BSON, por tanto nos dar\u00e1 errores en los tipos de datos propios de BSON. FIXME: revisar la validaci\u00f3n de los esquemas Puesta en marcha \u00b6 Instalaci\u00f3n \u00b6 Desde https://www.mongodb.com/try/download/community podemos descargar la versi\u00f3n community acorde a nuestro sistema operativo. Independientemente de nuestro sistema operativo, por defecto, el demonio se lanza sobre el puerto 27017. Si accedemos a http://localhost:27017 podremos ver que nos indica c\u00f3mo estamos intentando acceder mediante HTTP a MongoDB mediante el puerto reservado al driver nativo. En vez de instalarlo como un servicio en nuestra m\u00e1quina, a d\u00eda de hoy, es mucho m\u00e1s comodo hacer uso de contenedores Docker o utilizar una soluci\u00f3n cloud . Docker \u00b6 docker run -p 127.0.0.1:27017:27017 --name iabd-mongo -d mongo Descargar datos desde https://atlas-education-staging.s3.amazonaws.com/sampledata.archive.gz copiar los datos dentro del contenedor docker cp sampledata.archive.gz iabd-mongo:/tmp Entramos en tmp y restauramos bash mongorestore --gzip --archive=sampledata.archive.gz Mongo Atlas \u00b6 Crear cuenta Crear una organizaci\u00f3n (s8a) Crear un proyecto (iabd) Crear cluster (Cluster0) Cambiar el nombre del cluster a ClusterIABD. La creaci\u00f3n del cluster puede tardar de 2 a 3 minutos. Configurar el acceso a la red (Network Access) para permitir todo el tr\u00e1fico de internet. (Allow access from anywhere) Crear un usuario: En nuestro caso, hemos creado el usuario iabd con la contrase\u00f1a iabdiabd , pudiendo leer y escribir de cualquier base de datos. Una vez creado, ya podemos cargar los datos, mediante la opci\u00f3n Load Sample Dataset . Cargar los dataset de ejemplo (pantallazo) A continuaci\u00f3n vamos a estudiar las diferentes herramientas que nos ofrece MongoDB para posteriormente todas las operaciones que podemos realizar. Herramientas \u00b6 Adem\u00e1s del demonio y del cliente, MongoDB ofrece un conjunto de herramientas para interactuar con las bases de datos, permitiendo crear y restaurar copias de seguridad. Si estamos interesados en introducir o exportar una colecci\u00f3n de datos mediante JSON, podemos emplear los comandos mongoimport y mongoexport: Importanto y exportando datos bash mongoimport -d nombreBaseDatos -c coleccion \u2013-file nombreFichero.json mongoexport -d nombreBaseDatos -c coleccion nombreFichero.json Estas herramientas interact\u00faan con datos JSON y no sobre toda la base de datos. Un caso particular y muy com\u00fan es importar datos que se encuentran en formato CSV/TSV. Para ello, emplearemos el par\u00e1metro --type csv: Importando CSV/TSV - poblacionEspanya2013.tsv bash mongoimport --type tsv -d test -c poblacion --headerline --drop poblacionEspanya2013.tsv M\u00e1s informaci\u00f3n sobre importar y exportar datos en http://docs.mongodb.org/manual/core/import-export/ Antes que hacer un export, es m\u00e1s conveniente realizar un backup en binario mediante mongodump, el cual genera ficheros BSON. Estos archivos posteriormente se restauran mediante mongorestore. Restaurando un copia de seguridad bash mongodump -d nombreBaseDatos nombreFichero.bson mongorestore -d nombreBaseDatos nombreFichero.bson M\u00e1s informaci\u00f3n sobre copias de seguridad en http://docs.mongodb.org/manual/core/backups/ Si necesitamos transformar un fichero BSON a JSON (de binario a texto), tenemos el comando bsondump: De BSON a JSON bash bsondump file.bson > file.json Otra herramienta es mongostat que permite visualizar el estado del servidor MongoDB, as\u00ed como algunas estad\u00edsticas sobre su rendimiento. Esta herramienta la estudiaremos en la \u00faltima sesi\u00f3n. Para poder trabajar con MongoDB desde cualquier aplicaci\u00f3n necesitamos un driver. MongoDB ofrece drivers oficiales para casi todos los lenguajes de programaci\u00f3n actuales. M\u00e1s informaci\u00f3n en http://docs.mongodb.org/ecosystem/drivers/ Finalmente, una herramienta de terceros bastante utilizada es RoboMongo ( http://robomongo.org ), el cual extiende el shell y permite un uso m\u00e1s amigable. Mongo Compass \u00b6 Instalar Compass mongodb+srv://iabd: @cluster0.4hm7u8y.mongodb.net/test En el curso nos vamos a centrar en el uso del shell y la conectividad de MongoDB mediante Python. Easily explore and manipulate your database with Compass, the GUI for MongoDB. Intuitive and flexible, Compass provides detailed schema visualizations, real-time performance metrics, sophisticated querying abilities, and much more. Please note that MongoDB Compass comes in three versions: a full version with all features, a read-only version without write or delete capabilities, and an isolated edition, whose sole network connection is to the MongoDB instance. For more information, see our documentation pages. Compass The full version of MongoDB Compass, with all features and capabilities. Readonly Edition This version is limited strictly to read operations, with all write and delete capabilities removed. Isolated Edition This version disables all network connections except the connection to the MongoDB instance. Hola MongoDB \u00b6 Tras lanzar el demonio mongod , llega el momento de acceder mediante el cliente mongo , el cual funciona igual que un shell, de modo que con la fecha hacia arriba visualizaremos el \u00faltimo comando. El cliente utiliza JavaScript como lenguaje de interacci\u00f3n con la base de datos. Al conectar con mongo si no le indicamos nada se conectar\u00e1 por defecto a la base de datos test . Si queremos conectarnos a una base de datos concreta, la pasaremos como par\u00e1metro: FIXME:Lanzando el cliente mongo Figure 12. Lanzando el cliente mongo En cualquier momento podemos cambiar la base de datos activa mediante use nombreBaseDatos . Si la base de datos no existiese, MongoDB crear\u00e1 dicha base de datos. Esto es una verdad a medias, ya que la base de datos realmente se crea al insertar datos dentro de alguna colecci\u00f3n. Otros comandos muy empleados son show dbs para mostrar las bases de datos existentes, y show collections para obtener las colecciones de la base de datos activa. As\u00ed pues, vamos a crear nuestra base de datos iabd: js use iabd Una vez creada, podemos crear nuestra primera colecci\u00f3n, que llamaremos people , e insertaremos un persona con nuestros datos personales mediante el m\u00e9todo insert , al que le pasamos un objeto JSON: js db.people.insert({ nombre: \"Aitor\", edad: 45, profesion: \"Profesor\" }) Una vez insertada, s\u00f3lo nos queda realizar una consulta para recuperar los datos y comprobar que todo funciona correctamente mediante el m\u00e9todo findOne: js db.people.findOne() Lo que nos dar\u00e1 como resultado un objeto JSON que contiene un atributo _id adem\u00e1s de los que le a\u00f1adimos al insertar la persona: js { \"_id\" : ObjectId(\"53274f9883a7adeb6a573e64\"), \"nombre\" : \"Aitor\", \"edad\" : 45, \"profesion\" : \"Profesor\" } Como podemos observar, todas las instrucciones van a seguir el patr\u00f3n de db.nombreColeccion.operacion() . Trabajando con el shell \u00b6 Antes de entrar en detalles en las instrucciones necesarias para realizar las operaciones CRUD, veamos algunos comandos que nos ser\u00e1n muy utiles al interactuar con el shell: Table 1. Comandos \u00fatiles dentro del cliente de MongoDB Comando Funci\u00f3n show dbs Muestra el nombre de las bases de datos show collections Muestra el nombre de las colecciones db Muestra el nombre de la base de datos que estamos utilizando db.dropDatabase() Elimina la base de datos actual db.help() Muestra los comandos disponibles db.version() Muestra la versi\u00f3n actual del servidor En el resto de la sesi\u00f3n vamos a hacer un uso intenso del shell de MongoDB. Por ejemplo, si nos basamos en el objeto definido en el apartado de BSON, podemos ejecutar las siguientes instrucciones: Ejemplos de interacci\u00f3n con el shell db.people.insert(yo) db.people.find() { \"_id\" : ObjectId(\"53274f9883a7adeb6a573e64\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2, \"fechaCreacion\" : Timestamp(1425633249, 1) } yo.email = \"aitormedrano@gmail.com\" aitormedrano@gmail.com db.people.save(yo) db.people.find() { \"_id\" : ObjectId(\"53274f9883a7adeb6a573e64\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2, \"fechaCreacion\" : Timestamp(1425633249, 1) } { \"_id\" : ObjectId(\"53274fca83a7adeb6a573e65\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2, \"fechaCreacion\" : Timestamp(1425633373, 1), \"email\" : \"aitormedrano@gmail.com\" } db.people.find().forEach(printjson) Si queremos insertar un documento en una colecci\u00f3n, hemos de utilizar el m\u00e9todo insert ( http://docs.mongodb.org/master/reference/method/db.collection.insert/ ) pas\u00e1ndole como par\u00e1metro el documento que queremos insertar. find permite recuperar documentos save es similar a insert, pero si existe un documento con el mismo ObjectId, realizar\u00e1 un update (realmente un upsert) Hay dos documentos porque al guardar el segundo se le ha asignado un nuevo ObjectId. Adem\u00e1s, los dos documentos no tienen el mismo n\u00famero de campos, y la fechaCreaci\u00f3n se ha actualizado con el timestamp actual. Otros ejemplos tanto de insert como de save con objetos directos, sin necesidad de usar variables, ser\u00edan: Inserci\u00f3n y Guardado db.people.insert({ nombre : \"Aitor\", edad : 37, profesion : \"Profesor\" }) db.people.save({ nombre : \"Aitor\", edad : 37, profesion : \"Profesor\" }) Autoevaluaci\u00f3n Al ejecutar las dos instrucciones anteriores sobre una colecci\u00f3n vac\u00eda \u00bfCuantos registros tendr\u00e1 la colecci\u00f3n? [1] Empleando JS \u00b6 a hemos comentado que el shell utiliza JavaScript como lenguaje de interacci\u00f3n, por lo que podemos almacenar los comandos en un script externo y ejecutarlo mediante load(): Carga de script load(\"scripts/misDatos.js\"); load(\"/data/db/scripts/misDatos.js\"); Si hacemos una referencia relativa, lo hace respecto a la ruta desde la cual se ejecuta el shell mongo Otra manera de lanzar un script es hacerlo desde la l\u00ednea de comandos, pas\u00e1ndole como segundo par\u00e1metro el script a ejecutar: Ejecuci\u00f3n de script mongo expertojava misDatos.js Si el c\u00f3digo a ejecutar no necesita almacenarse en un script externo, el propio shell permite introducir instrucciones en varias l\u00edneas: Uso de JavaScript en el shell Figure 2. Uso de JavaScript en el shell ObjectId \u00b6 En MongoDB, el atributo _id es \u00fanico dentro de la colecci\u00f3n, y hace la funci\u00f3n de clave primaria. Se le asocia un ObjectId ( http://docs.mongodb.org/manual/reference/object-id/ ), el cual es un tipo BSON de 12 bytes que se crea mediante: el timestamp actual (4 bytes) un identificador de la m\u00e1quina / hostname (3 bytes) donde se genera un identificador del proceso (2 bytes) donde se genera un n\u00famero aleatorio (3 bytes). Este objeto lo crea el driver y no MongoDB, por lo cual no deberemos considerar que siguen un orden concreto, ya que clientes diferentes pueden tener timestamps desincronizados. Lo que s\u00ed que podemos obtener a partir del ObjectId es la fecha de creaci\u00f3n del documento, mediante el m\u00e9todo getTimestamp() del atributo _id . Obteniendo la fecha de creaci\u00f3n de un documento ``` bash db.people.find()[0]._id ObjectId(\"53274f9883a7adeb6a573e64\") db.people.find()[0]._id.getTimestamp() ISODate(\"2014-03-17T19:40:08Z\") ``` Este identificador es global, \u00fanico e inmutable. Esto es, no habr\u00e1 dos repetidos y una vez un documento tiene un _id , \u00e9ste no se puede modificar. Si en la definici\u00f3n del objeto a insertar no ponemos el atributo identificador, MongoDB crear\u00e1 uno de manera autom\u00e1tica. Si lo ponemos nosotros de manera expl\u00edcita, MongoDB no a\u00f1adir\u00e1 ning\u00fan ObjectId . Eso s\u00ed, debemos asegurarnos que sea \u00fanico (podemos usar n\u00fameros, cadenas, etc\u2026\u200b). Por lo tanto, podemos asignar un identificador al insertar: js db.people.insert({_id:3, nombre:\"Marina\", edad:6 }) Tipos de datos Cuidado con los tipos, ya que no es lo mismo insertar un atributo con edad:6 (se considera el campo como entero) que con edad:\"6\" , ya que considera el campo como texto. O tambi\u00e9n, si queremos podemos hacer que el _id de un documento sea un documento en s\u00ed, y no un entero, para ello, al insertarlo, podemos asignarle un objeto JSON al atributo identificador: js db.people.insert({_id:{nombre:'Aitor', apellidos:'Medrano', twitter:'@aitormedrano'}, ciudad:'Elx'}) Recuperando datos \u00b6 Para recuperar los datos de una colecci\u00f3n o un documento en concreto usaremos el m\u00e9todo find() : ``` js db.people.find() { \"_id\" : ObjectId(\"53274f9883a7adeb6a573e64\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2 } { \"_id\" : ObjectId(\"53274fca83a7adeb6a573e65\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2, \"email\" : \"aitormedrano@gmail.com\" } { \"_id\" : 3, \"nombre\" : \"Marina\", \"edad\" : 6 } ``` El m\u00e9todo find() sobre una colecci\u00f3n devuelve un cursor a los datos obtenidos, el cual se queda abierto con el servidor y que se cierra autom\u00e1ticamente a los 10 minutos de inactividad o al finalizar su recorrido. Si hay muchos resultados, la consola nos mostrar\u00e1 un subconjunto de los datos (20). Si queremos seguir obtiendo resultados, solo tenemos que introducir it, para que contin\u00fae iterando el cursor. Si queremos que el resultado sea m\u00e1s legible, podemos recorrer la consulta y mostrar una vista tabulada mediante printjson: db.people.find().forEach(printjson) En cambio, si s\u00f3lo queremos recuperar un documento hemos de utilizar findOne(): Recuperando un \u00fanico documento db.people.findOne() { \"_id\" : ObjectId(\"53274f9883a7adeb6a573e64\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2 } Se puede observar que al recuperar un documento con findOne, se muestra una vista formateada. Si queremos que esta vista se aplique a un documento encontrado con find podemos utilizar el sufijo .pretty(). db.people.find().pretty() Preparando los ejemplos Para los siguientes ejemplos, vamos a utilizar una colecci\u00f3n de 800 calificaciones que han obtenido diferentes estudiantes en trabajos, ex\u00e1menes o cuestionarios. Para ello, importaremos la colecci\u00f3n grades.json mediante: Importanto grades.json mongoimport -d expertojava -c grades --file grades.json Un ejemplo de una calificaci\u00f3n ser\u00eda: db.grades.findOne() { \"_id\" : ObjectId(\"50906d7fa3c412bb040eb577\"), \"student_id\" : 0, \"type\" : \"exam\", \"score\" : 54.6535436362647 } El campo type puede tomar los siguientes valores: quiz, homework o exam Criterios en consultas \u00b6 Al hacer una consulta, si queremos obtener datos mediante m\u00e1s de un criterio, en el primer par\u00e1metro del find podemos pasar un objeto JSON con los campos a cumplir (condici\u00f3n Y). Consulta con dos condiciones db.grades.find({student_id:0, type:\"quiz\"}) Consejo de Rendimiento Las consultas disyuntivas, es decir, con varios criterios u operador $and, deben filtrar el conjunto m\u00e1s peque\u00f1o cuanto m\u00e1s pronto posible. Supongamos que vamos a consultar documentos que cumplen los criterios A, B y C. Digamos que el criterio A lo cumplen 40.000 documentos, el B lo hacen 9.000 y el C s\u00f3lo 200. Si filtramos A, luego B, y finalmente C, el conjunto que trabaja cada criterio es muy grande. Restringiendo consultas AND Figure 3. Restringiendo consultas AND de mayor a menor En cambio, si hacemos una consulta que primero empiece por el criterio m\u00e1s restrictivo, el resultado con lo que se intersecciona el siguiente criterio es menor, y por tanto, se realizar\u00e1 m\u00e1s r\u00e1pido. Restringiendo consultas AND Figure 4. Restringiendo consultas AND de menor a mayor MongoDB tambi\u00e9n ofrece operadores l\u00f3gicos para los campos num\u00e9ricos: Table 2. Operadores l\u00f3gicos Comparador Operador menor que (<) $lt menor o igual que (\u2264) $lte mayor que (>) $gt mayor o igual que (\u2265) $gte Estos operadores se pueden utilizar de forma simult\u00e1nea sobre un mismo campo o sobre diferentes campos, y se colocan como un nuevo documento en el valor del campo a filtrar, compuesto del operador y del valor a comparar: Ejemplos de consultas con operadores relacionales db.grades.find({ score:{$gt:95} }) db.grades.find({ score:{$gt:95, $lte:98}, type:\"exam\" }) db.grades.find({ type:\"exam\", score:{$gte:65} }) Para los campos de texto, adem\u00e1s de la comparaci\u00f3n directa, podemos usar el operador $ne para obtener los documentos cuyo campos no tienen un determinado valor. As\u00ed pues, podemos usarlo para averiguar todas las calificaciones que no sean cuestionarios (quiz): Consulta con not equal db.grades.find({type:{$ne:\"quiz\"}}) Mucho cuidado al usar polimorfismo y almacenar en un mismo campo un entero y una cadena, ya que al hacer comparaciones para recuperar datos, no vamos a poder mezclar cadenas con valores num\u00e9ricos. Se considera un antipatr\u00f3n el mezclar tipos de datos en un campo. Las comparaciones de cadenas se realizan siguiendo el orden UTF8, similar a ASCII, con lo cual no es lo mismo buscar un rango entre may\u00fasculas que min\u00fasculas. Con cierto parecido a la condici\u00f3n de valor no nulo de las BBDD relacionales y teniendo en cuenta que la libertad de esquema puede provocar que un documento tenga unos campos determinados y otro no lo tenga, podemos utilizar el operador $exists si queremos averiguar si un campo existe (y por tanto tiene alg\u00fan valor). Consulta con condici\u00f3n de existencia de un campo db.grades.find({\"score\":{$exists:true}}) Pese a que ciertos operadores contengan su correspondiente operador negado, MongoDB ofrece el operador $not. \u00c9ste puede utilizarse conjuntamente con otros operadores para negar el resultado de los documentos obtenidos. Por ejemplo, si queremos obtener todas las calificaciones que no sean m\u00faltiplo de 5, podr\u00edamos hacerlo as\u00ed: Ejemplo de consulta con negaci\u00f3n db.grades.find({score:{$not: {$mod: [5,0]}}}) Finalmente, si queremos realizar consultas sobre partes de un campo de texto, hemos de emplear expresiones regulares. Para ello, tenemos el operador $regexp o, de manera m\u00e1s sencilla, indicando como valor la expresi\u00f3n regular a cumplir: Por ejemplo, para buscar las personas cuyo nombre contenga la palabra Aitor: Ejemplo de consulta con expresi\u00f3n regular db.people.find({nombre:/Aitor/}) db.people.find({nombre:/aitor/i}) db.people.find({nombre: {$regex:/aitor/i}}) Ya vimos en el m\u00f3dulo de JavaScript la flexibilidad y potencia que ofrecen las expresiones regulares. Para profundizar en su uso mediante MongoDB pod\u00e9is obtener m\u00e1s informaci\u00f3n sobre el operador $regex en http://docs.mongodb.org/manual/reference/operator/query/regex/#op._S_regex Otros operadores Algunos operadores que conviene citar aunque su uso es m\u00e1s bien ocasional son: Si queremos recuperar documentos que dependan del tipo de campo que contiene, podemos preguntar con $type http://docs.mongodb.org/manual/reference/operator/query/type/ El operador $where permite introducir una expresi\u00f3n JavaScript http://docs.mongodb.org/manual/reference/operator/query/where/ Proyecci\u00f3n de campos \u00b6 Las consultas realizadas hasta ahora devuelven los documentos completos. Si queremos que devuelva un campo o varios campos en concreto, hemos de pasar un segundo par\u00e1metro de tipo JSON con aquellos campos que deseamos mostrar con el valor true o 1. Destacar que si no se indica nada, por defecto siempre mostrar\u00e1 el campo _id db.grades.findOne({student_id:3},{score:true}); { \"_id\" : ObjectId(\"50906d7fa3c412bb040eb583\"), \"score\" : 92.6244233936537 } Por lo tanto, si queremos que no se muestre el_id, lo podremos a false o 0: db.grades.findOne({student_id:3},{score:true, _id:false}); Condiciones sobre objetos anidados \u00b6 Si queremos acceder a campos de subdocumentos, siguiendo la sintaxis de JSON, se utiliza la notaci\u00f3n punto. Esta notaci\u00f3n permite acceder al campo de un documento anidado, da igual el nivel en el que est\u00e9 y su orden respecto al resto de campos. Por ejemplo, supongamos que tenemos un cat\u00e1logo de productos de una tienda electr\u00f3nica, el cual es similar al siguiente documento: { \"producto\" : \"Condensador de Fluzo\", \"precio\" : 100000000000, \"reviews\" : [ { \"usuario\" : \"emmett\", \"comentario\" : \"\u00a1Genial!\", \"calificacion\" : 5 },{ \"usuario\" : \"marty\" , \"comentario\" : \"\u00a1Justo lo que necesitaba!\", \"calificacion\" : 4 } ] } Para acceder al usuario de una revisi\u00f3n usar\u00edamos la propiedad reviews.usuario. Por ejemplo, para averiguar los productos que cuestan m\u00e1s de 10.000 y que tienen una calificaci\u00f3n igual a 5 o superior har\u00edamos: db.catalogo.find({\"precio\":{$gt:10000},\"reviews.calificacion\":{$gte:5}}) Condiciones compuestas con Y / O \u00b6 Para usar la conjunci\u00f3n o la disyunci\u00f3n, tenemos los operadores $and y $or. Son operadores prefijo, de modo que se ponen antes de las subconsultas que se van a evaluar. Estos operadores trabajan con arrays, donde cada uno de los elementos es un documento con la condici\u00f3n a evaluar, de modo que se realiza la uni\u00f3n entre estas condiciones, aplicando la l\u00f3gica asociada a AND y a OR. db.grades.find({ $or:[ {\"type\":\"exam\"}, {\"score\":{$gte:65}} ]}) db.grades.find({ $or:[ {\"score\":{$lt:50}}, {\"score\":{$gt:90}} ]}) Realmente el operador $and no se suele usar porque podemos anidar en la consulta 2 criterios, al poner uno dentro del otro. As\u00ed pues, estas dos consultas hacen lo mismo: Ejemplos consultas conjunciones con y sin $and db.grades.find({ type:\"exam\", score:{$gte:65} }) db.grades.find({ $and:[ {type:\"exam\"}, {score:{$gte:65}} ] }) Consejo de Rendimiento Las consultas conjuntivas, es decir, con varios criterios excluyentes u operador $or, deben filtrar el conjunto m\u00e1s grande cuanto m\u00e1s pronto posible. Supongamos que vamos a consultar los mismos documentos que cumplen los criterios A (40.000 documentos), B (9.000 documentos) y C (200 documentos). Si filtramos C, luego B, y finalmente A, el conjunto de documentos que tiene que comprobar MongoDB es muy grande. Restringiendo consultas OR Figure 5. Restringiendo consultas OR de menor a myor En cambio, si hacemos una consulta que primero empiece por el criterio menos restrictivo, el conjunto de documentos sobre el cual va a tener que comprobar siguientes criterios va a ser menor, y por tanto, se realizar\u00e1 m\u00e1s r\u00e1pido. Restringiendo consultas AND Figure 6. Restringiendo consultas OR de mayor a menor Tambi\u00e9n podemos utilizar el operado $nor, que no es m\u00e1s que la negaci\u00f3n de $or y que obtendr\u00e1 aquellos documentos que no cumplan ninguna de las condiciones. Autoevaluaci\u00f3n Que obtendr\u00edamos al ejecutar la siguiente consulta: [2] db.grades.find({ score:{$gte:65}, $nor:[ {type:\"quiz\"}, {type:\"homework\"} ] }) Finalmente, si queremos indicar mediante un array los diferentes valores que puede cumplir un campo, podemos utilizar el operador $in: db.grades.find({ type:{$in:[\"quiz\",\"exam\"]}}) Por supuesto, tambi\u00e9n existe su negaci\u00f3n mediante $nin. Consultas sobre arrays \u00b6 Si trabajamos con arrays, vamos a poder consultar el contenido de una posici\u00f3n del mismo tal como si fuera un campo normal, siempre que sea un campo de primer nivel, es decir, no sea un documento embebido dentro de un array. Si queremos filtrar teniendo en cuenta el n\u00famero de ocurrencias del array, podemos utilizar: $all para filtrar ocurrencias que tienen todos los valores del array, es decir, los valores pasados a la consulta ser\u00e1n un subconjunto del resultado. Puede que devuelva los mismos, o un array con m\u00e1s campos (el orden no importa) $in, igual que SQL, para obtener las ocurrencias que cumple con alguno de los valores pasados (similar a usar $or sobre un conjunto de valores de un mismo campo). Si queremos su negaci\u00f3n, usaremos $nin, para obtener los documentos que no cumplen ninguno de los valores. Por ejemplo, si queremos obtener las personas que dentro de sus amistades se encuentre Juan y David, y respecto a sus hobbies est\u00e9n el footing o el baloncesto, tendr\u00edamos: Ejemplo consulta con $all y $in db.people.find( {amistades: {$all: [\"Juan\", \"David\"]}, hobbies: {$in: [\"footing\", \"baloncesto\"]}} ) Si el array contiene documentos y queremos filtrar la consulta sobre los campos de los documentos del array, tenemos que utilizar $elemMatch. M\u00e1s informaci\u00f3n en http://docs.mongodb.org/manual/reference/operator/projection/elemMatch/ Si lo que nos interesa es la cantidad de elementos que contiene un array, emplearemos el operador $size. Por ejemplo, para obtener las personas que tienen 3 hobbies har\u00edamos: Ejemplo consulta con $size db.people.find( {hobbies : {$size : 3}} ) Finalmente, a la hora de proyectar los datos, si no estamos interesados en todos los valores de un campo que es un array, podemos restringir el resultado mediante el operador $slice: As\u00ed pues, si quisieramos obtener las personas que tienen mas de un hijo, y que de esas personas, en vez de mostrar todos sus hobbies, mostrase los dos primeros, har\u00edamos: Ejemplo con $slice db.people.find( {hijos: {$gt:1}}, {hobbies: {$slice:2}} ) M\u00e1s informaci\u00f3n en http://docs.mongodb.org/manual/reference/operator/projection/slice/ Conjunto de valores \u00b6 Igual que en SQL, a partir de un colecci\u00f3n, si queremos obtener todos los diferentes valores que existen en un campo, utilizaremos el m\u00e9todo distinct db.grades.distinct('type') [ \"exam\", \"quiz\", \"homework\" ] Si queremos filtrar los datos sobre los que se obtienen los valores, le pasaremos un segundo par\u00e1metro con el criterio a aplicar: db.grades.distinct('type', { score: { $gt: 99.9 } } ) [ \"exam\" ] 2.4.7. Cursores Al hacer una consulta en el shell, se devuelve un cursor. Este cursor lo podemos guardar en un variable, y partir de ah\u00ed trabajar con \u00e9l como har\u00edamos mediante Java. Si cur es la variable que referencia al cursor, podremos utilizar los siguientes m\u00e9todos: Table 3. M\u00e9todos de uso de cursores M\u00e9todo Uso Lugar de ejecuci\u00f3n cur.hasNext() true/false para saber si quedan elementos Cliente cur.next() Pasa al siguiente documento Cliente cur.limit(numElementos) Restringe el n\u00famero de resultados a numElementos Servidor cur.sort({campo:1}) Ordena los datos por campo 1 ascendente o -1 o descendente Servidor cur.skip(numElementos) Permite saltar numElementos con el cursor Servidor La consulta no se ejecuta hasta que el cursor comprueba o pasa al siguiente documento (next/hasNext), por ello que tanto limit como sort (ambos modifican el cursor) s\u00f3lo se pueden realizar antes de recorrer cualquier elemento del cursor. Como tras realizar una consulta con find, realmente se devuelve un cursor, un uso muy habitual es encadenar una operaci\u00f3n de find con sort y/o limit para ordenar el resultado por uno o m\u00e1s campos y posteriormente limitar el n\u00famero de documentos a devolver. As\u00ed pues, si quisi\u00e9ramos obtener la calificaci\u00f3n del trabajo con la nota m\u00e1s alta, podr\u00edamos hacerlo as\u00ed: db.grades.find({ type:'homework'}).sort({score:-1}).limit(1) Por ejemplo, si queremos paginar las notas de 10 en 10, a partir de la tercera p\u00e1gina, podr\u00edamos hacer algo as\u00ed: db.grades.find().sort({score:-1}).limit(10).skip(20); Autoevaluaci\u00f3n A partir de la colecci\u00f3n grades, escribe un consulta que obtenga los documentos de tipo \"exam\" ordenados descendentemente y que obtenga los documentos de 51 al 70. [3] Contando Documentos \u00b6 Para contar el n\u00famero de documentos, en vez de find usaremos el m\u00e9todo count. Por ejemplo: db.grades.count({type:\"exam\"}) db.grades.find({type:\"exam\"}).count() db.grades.count({type:\"essay\", score:{$gt:90}}) Tambi\u00e9n se puede utilizar count como m\u00e9todo de un cursor. Insertando y modificando \u00b6 Referencias \u00b6 Manual de MongoDB Cheatseat Actividades \u00b6 Primeros pasos. Conexi\u00f3n, Consultas sencillas (**) Operaciones CRUD (**)","title":"S24.- MongoDB"},{"location":"sa/02mongo.html#mongodb","text":"MongoDB ( http://www.mongodb.com ) es una de las bases de datos NoSQL m\u00e1s conocidas. Sigue un modelo de datos documental, donde los documentos se basan en JSON. MongoDB destaca porque: Soporta esquemas din\u00e1micos: diferentes documentos de una misma colecci\u00f3n pueden tener atributos diferentes. No soporta joins, ya que no escalan bien. No soporta transacciones. Lo que en un SGDB puede suponer m\u00faltiples operaciones, con MongoDB se puede hacer en una sola operaci\u00f3n al insertar/actualizar todo un documento de una sola vez. Productos comerciales Hablar de Atlas y de las versiones Enterprise y Community","title":"MongoDB"},{"location":"sa/02mongo.html#conceptos","text":"Hay una serie de conceptos que conviene conocer antes de entrar en detalle: MongoDB tienen el mismo concepto de base de datos que un SGDB. Dentro de una instancia de MongoDB podemos tener 0 o m\u00e1s bases de datos, actuando cada una como un contenedor de alto nivel. Una base de datos tendr\u00e1 0 o m\u00e1s colecciones. Una colecci\u00f3n es muy similar a lo que entendemos como tabla dentro de un SGDB. MongoDB ofrece diferentes tipos de colecciones, desde las normales cuyo tama\u00f1o crece conforme lo hace el n\u00famero de documentos, como las colecciones capped , las cuales tienen un tama\u00f1o predefinido y que pueden contener una cierta cantidad de informaci\u00f3n que se sustituir\u00e1 por nueva cuando se llene. Las colecciones contienen 0 o m\u00e1s documentos , por lo que es similar a una fila o registro de un RDMS. Cada documento contiene 0 o m\u00e1s atributos, compuestos de parejas clave/valor . Cada uno de estos documentos no sigue ning\u00fan esquema, por lo que dos documentos de una misma colecci\u00f3n pueden contener todos los atributos diferentes entre s\u00ed. Elementos de MongoDB As\u00ed pues, tenemos que una base de datos va a contener varias colecciones, donde cada colecci\u00f3n contendr\u00e1 un conjunto de documentos: Modelo de MongoDB Adem\u00e1s, MongoDB soporta \u00edndices , igual que cualquier SGDB, para acelerar la b\u00fasqueda de datos. Al realizar cualquier consulta, se devuelve un cursor , con el cual podemos hacer cosas tales como contar, ordenar, limitar o saltar documentos.","title":"Conceptos"},{"location":"sa/02mongo.html#bson","text":"Mediante JavaScript podemos crear objetos que se representan con JSON. Internamente, MongoDB almacena los documentos mediante BSON ( Binary JSON ). Podemos consultar la especificaci\u00f3n en http://BSONSpec.org Especificaci\u00f3n BSON BSON representa un superset de JSON ya que: Permite almacenar datos en binario Incluye un conjunto de tipos de datos no incluidos en JSON, como pueden ser ObjectId , Date o BinData . Podemos consultar todos los tipos que soporta un objeto BSON en http://docs.mongodb.org/manual/reference/bson-types/ Un ejemplo de un objeto BSON podr\u00eda ser: json var yo = { nombre: \"Aitor\", apellidos: \"Medrano\", fnac: new Date(\"Oct 3, 1977\"), hobbies: [\"programaci\u00f3n\", \"videojuegos\", \"baloncesto\"], casado: true, hijos: 2, fechaCreacion = new Timestamp() } Los documentos BSON tienen las siguientes restricciones: No pueden tener un tama\u00f1o superior a 16 MB. El atributo _id queda reservado para la clave primaria. Los nombres de los campos no pueden empezar por $ . Los nombres de los campos no pueden contener el . Adem\u00e1s MongoDB: No asegura que el orden de los campos se respete. Es sensible a los tipos de los datos Es sensible a las may\u00fasculas. Por lo que estos documentos son distintos: json {\"edad\": \"18\"} {\"edad\": 18} {\"Edad\": 18} Si queremos validar si un documento JSON es v\u00e1lido, podemos usar http://jsonlint.com/ . Hemos de tener en cuenta que s\u00f3lo valida JSON y no BSON, por tanto nos dar\u00e1 errores en los tipos de datos propios de BSON. FIXME: revisar la validaci\u00f3n de los esquemas","title":"BSON"},{"location":"sa/02mongo.html#puesta-en-marcha","text":"","title":"Puesta en marcha"},{"location":"sa/02mongo.html#instalacion","text":"Desde https://www.mongodb.com/try/download/community podemos descargar la versi\u00f3n community acorde a nuestro sistema operativo. Independientemente de nuestro sistema operativo, por defecto, el demonio se lanza sobre el puerto 27017. Si accedemos a http://localhost:27017 podremos ver que nos indica c\u00f3mo estamos intentando acceder mediante HTTP a MongoDB mediante el puerto reservado al driver nativo. En vez de instalarlo como un servicio en nuestra m\u00e1quina, a d\u00eda de hoy, es mucho m\u00e1s comodo hacer uso de contenedores Docker o utilizar una soluci\u00f3n cloud .","title":"Instalaci\u00f3n"},{"location":"sa/02mongo.html#docker","text":"docker run -p 127.0.0.1:27017:27017 --name iabd-mongo -d mongo Descargar datos desde https://atlas-education-staging.s3.amazonaws.com/sampledata.archive.gz copiar los datos dentro del contenedor docker cp sampledata.archive.gz iabd-mongo:/tmp Entramos en tmp y restauramos bash mongorestore --gzip --archive=sampledata.archive.gz","title":"Docker"},{"location":"sa/02mongo.html#mongo-atlas","text":"Crear cuenta Crear una organizaci\u00f3n (s8a) Crear un proyecto (iabd) Crear cluster (Cluster0) Cambiar el nombre del cluster a ClusterIABD. La creaci\u00f3n del cluster puede tardar de 2 a 3 minutos. Configurar el acceso a la red (Network Access) para permitir todo el tr\u00e1fico de internet. (Allow access from anywhere) Crear un usuario: En nuestro caso, hemos creado el usuario iabd con la contrase\u00f1a iabdiabd , pudiendo leer y escribir de cualquier base de datos. Una vez creado, ya podemos cargar los datos, mediante la opci\u00f3n Load Sample Dataset . Cargar los dataset de ejemplo (pantallazo) A continuaci\u00f3n vamos a estudiar las diferentes herramientas que nos ofrece MongoDB para posteriormente todas las operaciones que podemos realizar.","title":"Mongo Atlas"},{"location":"sa/02mongo.html#herramientas","text":"Adem\u00e1s del demonio y del cliente, MongoDB ofrece un conjunto de herramientas para interactuar con las bases de datos, permitiendo crear y restaurar copias de seguridad. Si estamos interesados en introducir o exportar una colecci\u00f3n de datos mediante JSON, podemos emplear los comandos mongoimport y mongoexport: Importanto y exportando datos bash mongoimport -d nombreBaseDatos -c coleccion \u2013-file nombreFichero.json mongoexport -d nombreBaseDatos -c coleccion nombreFichero.json Estas herramientas interact\u00faan con datos JSON y no sobre toda la base de datos. Un caso particular y muy com\u00fan es importar datos que se encuentran en formato CSV/TSV. Para ello, emplearemos el par\u00e1metro --type csv: Importando CSV/TSV - poblacionEspanya2013.tsv bash mongoimport --type tsv -d test -c poblacion --headerline --drop poblacionEspanya2013.tsv M\u00e1s informaci\u00f3n sobre importar y exportar datos en http://docs.mongodb.org/manual/core/import-export/ Antes que hacer un export, es m\u00e1s conveniente realizar un backup en binario mediante mongodump, el cual genera ficheros BSON. Estos archivos posteriormente se restauran mediante mongorestore. Restaurando un copia de seguridad bash mongodump -d nombreBaseDatos nombreFichero.bson mongorestore -d nombreBaseDatos nombreFichero.bson M\u00e1s informaci\u00f3n sobre copias de seguridad en http://docs.mongodb.org/manual/core/backups/ Si necesitamos transformar un fichero BSON a JSON (de binario a texto), tenemos el comando bsondump: De BSON a JSON bash bsondump file.bson > file.json Otra herramienta es mongostat que permite visualizar el estado del servidor MongoDB, as\u00ed como algunas estad\u00edsticas sobre su rendimiento. Esta herramienta la estudiaremos en la \u00faltima sesi\u00f3n. Para poder trabajar con MongoDB desde cualquier aplicaci\u00f3n necesitamos un driver. MongoDB ofrece drivers oficiales para casi todos los lenguajes de programaci\u00f3n actuales. M\u00e1s informaci\u00f3n en http://docs.mongodb.org/ecosystem/drivers/ Finalmente, una herramienta de terceros bastante utilizada es RoboMongo ( http://robomongo.org ), el cual extiende el shell y permite un uso m\u00e1s amigable.","title":"Herramientas"},{"location":"sa/02mongo.html#hola-mongodb","text":"Tras lanzar el demonio mongod , llega el momento de acceder mediante el cliente mongo , el cual funciona igual que un shell, de modo que con la fecha hacia arriba visualizaremos el \u00faltimo comando. El cliente utiliza JavaScript como lenguaje de interacci\u00f3n con la base de datos. Al conectar con mongo si no le indicamos nada se conectar\u00e1 por defecto a la base de datos test . Si queremos conectarnos a una base de datos concreta, la pasaremos como par\u00e1metro: FIXME:Lanzando el cliente mongo Figure 12. Lanzando el cliente mongo En cualquier momento podemos cambiar la base de datos activa mediante use nombreBaseDatos . Si la base de datos no existiese, MongoDB crear\u00e1 dicha base de datos. Esto es una verdad a medias, ya que la base de datos realmente se crea al insertar datos dentro de alguna colecci\u00f3n. Otros comandos muy empleados son show dbs para mostrar las bases de datos existentes, y show collections para obtener las colecciones de la base de datos activa. As\u00ed pues, vamos a crear nuestra base de datos iabd: js use iabd Una vez creada, podemos crear nuestra primera colecci\u00f3n, que llamaremos people , e insertaremos un persona con nuestros datos personales mediante el m\u00e9todo insert , al que le pasamos un objeto JSON: js db.people.insert({ nombre: \"Aitor\", edad: 45, profesion: \"Profesor\" }) Una vez insertada, s\u00f3lo nos queda realizar una consulta para recuperar los datos y comprobar que todo funciona correctamente mediante el m\u00e9todo findOne: js db.people.findOne() Lo que nos dar\u00e1 como resultado un objeto JSON que contiene un atributo _id adem\u00e1s de los que le a\u00f1adimos al insertar la persona: js { \"_id\" : ObjectId(\"53274f9883a7adeb6a573e64\"), \"nombre\" : \"Aitor\", \"edad\" : 45, \"profesion\" : \"Profesor\" } Como podemos observar, todas las instrucciones van a seguir el patr\u00f3n de db.nombreColeccion.operacion() .","title":"Hola MongoDB"},{"location":"sa/02mongo.html#trabajando-con-el-shell","text":"Antes de entrar en detalles en las instrucciones necesarias para realizar las operaciones CRUD, veamos algunos comandos que nos ser\u00e1n muy utiles al interactuar con el shell: Table 1. Comandos \u00fatiles dentro del cliente de MongoDB Comando Funci\u00f3n show dbs Muestra el nombre de las bases de datos show collections Muestra el nombre de las colecciones db Muestra el nombre de la base de datos que estamos utilizando db.dropDatabase() Elimina la base de datos actual db.help() Muestra los comandos disponibles db.version() Muestra la versi\u00f3n actual del servidor En el resto de la sesi\u00f3n vamos a hacer un uso intenso del shell de MongoDB. Por ejemplo, si nos basamos en el objeto definido en el apartado de BSON, podemos ejecutar las siguientes instrucciones: Ejemplos de interacci\u00f3n con el shell db.people.insert(yo) db.people.find() { \"_id\" : ObjectId(\"53274f9883a7adeb6a573e64\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2, \"fechaCreacion\" : Timestamp(1425633249, 1) } yo.email = \"aitormedrano@gmail.com\" aitormedrano@gmail.com db.people.save(yo) db.people.find() { \"_id\" : ObjectId(\"53274f9883a7adeb6a573e64\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2, \"fechaCreacion\" : Timestamp(1425633249, 1) } { \"_id\" : ObjectId(\"53274fca83a7adeb6a573e65\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2, \"fechaCreacion\" : Timestamp(1425633373, 1), \"email\" : \"aitormedrano@gmail.com\" } db.people.find().forEach(printjson) Si queremos insertar un documento en una colecci\u00f3n, hemos de utilizar el m\u00e9todo insert ( http://docs.mongodb.org/master/reference/method/db.collection.insert/ ) pas\u00e1ndole como par\u00e1metro el documento que queremos insertar. find permite recuperar documentos save es similar a insert, pero si existe un documento con el mismo ObjectId, realizar\u00e1 un update (realmente un upsert) Hay dos documentos porque al guardar el segundo se le ha asignado un nuevo ObjectId. Adem\u00e1s, los dos documentos no tienen el mismo n\u00famero de campos, y la fechaCreaci\u00f3n se ha actualizado con el timestamp actual. Otros ejemplos tanto de insert como de save con objetos directos, sin necesidad de usar variables, ser\u00edan: Inserci\u00f3n y Guardado db.people.insert({ nombre : \"Aitor\", edad : 37, profesion : \"Profesor\" }) db.people.save({ nombre : \"Aitor\", edad : 37, profesion : \"Profesor\" }) Autoevaluaci\u00f3n Al ejecutar las dos instrucciones anteriores sobre una colecci\u00f3n vac\u00eda \u00bfCuantos registros tendr\u00e1 la colecci\u00f3n? [1]","title":"Trabajando con el shell"},{"location":"sa/02mongo.html#empleando-js","text":"a hemos comentado que el shell utiliza JavaScript como lenguaje de interacci\u00f3n, por lo que podemos almacenar los comandos en un script externo y ejecutarlo mediante load(): Carga de script load(\"scripts/misDatos.js\"); load(\"/data/db/scripts/misDatos.js\"); Si hacemos una referencia relativa, lo hace respecto a la ruta desde la cual se ejecuta el shell mongo Otra manera de lanzar un script es hacerlo desde la l\u00ednea de comandos, pas\u00e1ndole como segundo par\u00e1metro el script a ejecutar: Ejecuci\u00f3n de script mongo expertojava misDatos.js Si el c\u00f3digo a ejecutar no necesita almacenarse en un script externo, el propio shell permite introducir instrucciones en varias l\u00edneas: Uso de JavaScript en el shell Figure 2. Uso de JavaScript en el shell","title":"Empleando JS"},{"location":"sa/02mongo.html#objectid","text":"En MongoDB, el atributo _id es \u00fanico dentro de la colecci\u00f3n, y hace la funci\u00f3n de clave primaria. Se le asocia un ObjectId ( http://docs.mongodb.org/manual/reference/object-id/ ), el cual es un tipo BSON de 12 bytes que se crea mediante: el timestamp actual (4 bytes) un identificador de la m\u00e1quina / hostname (3 bytes) donde se genera un identificador del proceso (2 bytes) donde se genera un n\u00famero aleatorio (3 bytes). Este objeto lo crea el driver y no MongoDB, por lo cual no deberemos considerar que siguen un orden concreto, ya que clientes diferentes pueden tener timestamps desincronizados. Lo que s\u00ed que podemos obtener a partir del ObjectId es la fecha de creaci\u00f3n del documento, mediante el m\u00e9todo getTimestamp() del atributo _id . Obteniendo la fecha de creaci\u00f3n de un documento ``` bash db.people.find()[0]._id ObjectId(\"53274f9883a7adeb6a573e64\") db.people.find()[0]._id.getTimestamp() ISODate(\"2014-03-17T19:40:08Z\") ``` Este identificador es global, \u00fanico e inmutable. Esto es, no habr\u00e1 dos repetidos y una vez un documento tiene un _id , \u00e9ste no se puede modificar. Si en la definici\u00f3n del objeto a insertar no ponemos el atributo identificador, MongoDB crear\u00e1 uno de manera autom\u00e1tica. Si lo ponemos nosotros de manera expl\u00edcita, MongoDB no a\u00f1adir\u00e1 ning\u00fan ObjectId . Eso s\u00ed, debemos asegurarnos que sea \u00fanico (podemos usar n\u00fameros, cadenas, etc\u2026\u200b). Por lo tanto, podemos asignar un identificador al insertar: js db.people.insert({_id:3, nombre:\"Marina\", edad:6 }) Tipos de datos Cuidado con los tipos, ya que no es lo mismo insertar un atributo con edad:6 (se considera el campo como entero) que con edad:\"6\" , ya que considera el campo como texto. O tambi\u00e9n, si queremos podemos hacer que el _id de un documento sea un documento en s\u00ed, y no un entero, para ello, al insertarlo, podemos asignarle un objeto JSON al atributo identificador: js db.people.insert({_id:{nombre:'Aitor', apellidos:'Medrano', twitter:'@aitormedrano'}, ciudad:'Elx'})","title":"ObjectId"},{"location":"sa/02mongo.html#recuperando-datos","text":"Para recuperar los datos de una colecci\u00f3n o un documento en concreto usaremos el m\u00e9todo find() : ``` js db.people.find() { \"_id\" : ObjectId(\"53274f9883a7adeb6a573e64\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2 } { \"_id\" : ObjectId(\"53274fca83a7adeb6a573e65\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2, \"email\" : \"aitormedrano@gmail.com\" } { \"_id\" : 3, \"nombre\" : \"Marina\", \"edad\" : 6 } ``` El m\u00e9todo find() sobre una colecci\u00f3n devuelve un cursor a los datos obtenidos, el cual se queda abierto con el servidor y que se cierra autom\u00e1ticamente a los 10 minutos de inactividad o al finalizar su recorrido. Si hay muchos resultados, la consola nos mostrar\u00e1 un subconjunto de los datos (20). Si queremos seguir obtiendo resultados, solo tenemos que introducir it, para que contin\u00fae iterando el cursor. Si queremos que el resultado sea m\u00e1s legible, podemos recorrer la consulta y mostrar una vista tabulada mediante printjson: db.people.find().forEach(printjson) En cambio, si s\u00f3lo queremos recuperar un documento hemos de utilizar findOne(): Recuperando un \u00fanico documento db.people.findOne() { \"_id\" : ObjectId(\"53274f9883a7adeb6a573e64\"), \"nombre\" : \"Aitor\", \"apellidos\" : \"Medrano\", \"fnac\" : ISODate(\"1977-10-02T23:00:00Z\"), \"hobbies\" : [ \"programaci\u00f3n\", \"videojuegos\", \"baloncesto\" ], \"casado\" : true, \"hijos\" : 2 } Se puede observar que al recuperar un documento con findOne, se muestra una vista formateada. Si queremos que esta vista se aplique a un documento encontrado con find podemos utilizar el sufijo .pretty(). db.people.find().pretty() Preparando los ejemplos Para los siguientes ejemplos, vamos a utilizar una colecci\u00f3n de 800 calificaciones que han obtenido diferentes estudiantes en trabajos, ex\u00e1menes o cuestionarios. Para ello, importaremos la colecci\u00f3n grades.json mediante: Importanto grades.json mongoimport -d expertojava -c grades --file grades.json Un ejemplo de una calificaci\u00f3n ser\u00eda: db.grades.findOne() { \"_id\" : ObjectId(\"50906d7fa3c412bb040eb577\"), \"student_id\" : 0, \"type\" : \"exam\", \"score\" : 54.6535436362647 } El campo type puede tomar los siguientes valores: quiz, homework o exam","title":"Recuperando datos"},{"location":"sa/02mongo.html#criterios-en-consultas","text":"Al hacer una consulta, si queremos obtener datos mediante m\u00e1s de un criterio, en el primer par\u00e1metro del find podemos pasar un objeto JSON con los campos a cumplir (condici\u00f3n Y). Consulta con dos condiciones db.grades.find({student_id:0, type:\"quiz\"}) Consejo de Rendimiento Las consultas disyuntivas, es decir, con varios criterios u operador $and, deben filtrar el conjunto m\u00e1s peque\u00f1o cuanto m\u00e1s pronto posible. Supongamos que vamos a consultar documentos que cumplen los criterios A, B y C. Digamos que el criterio A lo cumplen 40.000 documentos, el B lo hacen 9.000 y el C s\u00f3lo 200. Si filtramos A, luego B, y finalmente C, el conjunto que trabaja cada criterio es muy grande. Restringiendo consultas AND Figure 3. Restringiendo consultas AND de mayor a menor En cambio, si hacemos una consulta que primero empiece por el criterio m\u00e1s restrictivo, el resultado con lo que se intersecciona el siguiente criterio es menor, y por tanto, se realizar\u00e1 m\u00e1s r\u00e1pido. Restringiendo consultas AND Figure 4. Restringiendo consultas AND de menor a mayor MongoDB tambi\u00e9n ofrece operadores l\u00f3gicos para los campos num\u00e9ricos: Table 2. Operadores l\u00f3gicos Comparador Operador menor que (<) $lt menor o igual que (\u2264) $lte mayor que (>) $gt mayor o igual que (\u2265) $gte Estos operadores se pueden utilizar de forma simult\u00e1nea sobre un mismo campo o sobre diferentes campos, y se colocan como un nuevo documento en el valor del campo a filtrar, compuesto del operador y del valor a comparar: Ejemplos de consultas con operadores relacionales db.grades.find({ score:{$gt:95} }) db.grades.find({ score:{$gt:95, $lte:98}, type:\"exam\" }) db.grades.find({ type:\"exam\", score:{$gte:65} }) Para los campos de texto, adem\u00e1s de la comparaci\u00f3n directa, podemos usar el operador $ne para obtener los documentos cuyo campos no tienen un determinado valor. As\u00ed pues, podemos usarlo para averiguar todas las calificaciones que no sean cuestionarios (quiz): Consulta con not equal db.grades.find({type:{$ne:\"quiz\"}}) Mucho cuidado al usar polimorfismo y almacenar en un mismo campo un entero y una cadena, ya que al hacer comparaciones para recuperar datos, no vamos a poder mezclar cadenas con valores num\u00e9ricos. Se considera un antipatr\u00f3n el mezclar tipos de datos en un campo. Las comparaciones de cadenas se realizan siguiendo el orden UTF8, similar a ASCII, con lo cual no es lo mismo buscar un rango entre may\u00fasculas que min\u00fasculas. Con cierto parecido a la condici\u00f3n de valor no nulo de las BBDD relacionales y teniendo en cuenta que la libertad de esquema puede provocar que un documento tenga unos campos determinados y otro no lo tenga, podemos utilizar el operador $exists si queremos averiguar si un campo existe (y por tanto tiene alg\u00fan valor). Consulta con condici\u00f3n de existencia de un campo db.grades.find({\"score\":{$exists:true}}) Pese a que ciertos operadores contengan su correspondiente operador negado, MongoDB ofrece el operador $not. \u00c9ste puede utilizarse conjuntamente con otros operadores para negar el resultado de los documentos obtenidos. Por ejemplo, si queremos obtener todas las calificaciones que no sean m\u00faltiplo de 5, podr\u00edamos hacerlo as\u00ed: Ejemplo de consulta con negaci\u00f3n db.grades.find({score:{$not: {$mod: [5,0]}}}) Finalmente, si queremos realizar consultas sobre partes de un campo de texto, hemos de emplear expresiones regulares. Para ello, tenemos el operador $regexp o, de manera m\u00e1s sencilla, indicando como valor la expresi\u00f3n regular a cumplir: Por ejemplo, para buscar las personas cuyo nombre contenga la palabra Aitor: Ejemplo de consulta con expresi\u00f3n regular db.people.find({nombre:/Aitor/}) db.people.find({nombre:/aitor/i}) db.people.find({nombre: {$regex:/aitor/i}}) Ya vimos en el m\u00f3dulo de JavaScript la flexibilidad y potencia que ofrecen las expresiones regulares. Para profundizar en su uso mediante MongoDB pod\u00e9is obtener m\u00e1s informaci\u00f3n sobre el operador $regex en http://docs.mongodb.org/manual/reference/operator/query/regex/#op._S_regex Otros operadores Algunos operadores que conviene citar aunque su uso es m\u00e1s bien ocasional son: Si queremos recuperar documentos que dependan del tipo de campo que contiene, podemos preguntar con $type http://docs.mongodb.org/manual/reference/operator/query/type/ El operador $where permite introducir una expresi\u00f3n JavaScript http://docs.mongodb.org/manual/reference/operator/query/where/","title":"Criterios en consultas"},{"location":"sa/02mongo.html#proyeccion-de-campos","text":"Las consultas realizadas hasta ahora devuelven los documentos completos. Si queremos que devuelva un campo o varios campos en concreto, hemos de pasar un segundo par\u00e1metro de tipo JSON con aquellos campos que deseamos mostrar con el valor true o 1. Destacar que si no se indica nada, por defecto siempre mostrar\u00e1 el campo _id db.grades.findOne({student_id:3},{score:true}); { \"_id\" : ObjectId(\"50906d7fa3c412bb040eb583\"), \"score\" : 92.6244233936537 } Por lo tanto, si queremos que no se muestre el_id, lo podremos a false o 0: db.grades.findOne({student_id:3},{score:true, _id:false});","title":"Proyecci\u00f3n de campos"},{"location":"sa/02mongo.html#condiciones-sobre-objetos-anidados","text":"Si queremos acceder a campos de subdocumentos, siguiendo la sintaxis de JSON, se utiliza la notaci\u00f3n punto. Esta notaci\u00f3n permite acceder al campo de un documento anidado, da igual el nivel en el que est\u00e9 y su orden respecto al resto de campos. Por ejemplo, supongamos que tenemos un cat\u00e1logo de productos de una tienda electr\u00f3nica, el cual es similar al siguiente documento: { \"producto\" : \"Condensador de Fluzo\", \"precio\" : 100000000000, \"reviews\" : [ { \"usuario\" : \"emmett\", \"comentario\" : \"\u00a1Genial!\", \"calificacion\" : 5 },{ \"usuario\" : \"marty\" , \"comentario\" : \"\u00a1Justo lo que necesitaba!\", \"calificacion\" : 4 } ] } Para acceder al usuario de una revisi\u00f3n usar\u00edamos la propiedad reviews.usuario. Por ejemplo, para averiguar los productos que cuestan m\u00e1s de 10.000 y que tienen una calificaci\u00f3n igual a 5 o superior har\u00edamos: db.catalogo.find({\"precio\":{$gt:10000},\"reviews.calificacion\":{$gte:5}})","title":"Condiciones sobre objetos anidados"},{"location":"sa/02mongo.html#condiciones-compuestas-con-y-o","text":"Para usar la conjunci\u00f3n o la disyunci\u00f3n, tenemos los operadores $and y $or. Son operadores prefijo, de modo que se ponen antes de las subconsultas que se van a evaluar. Estos operadores trabajan con arrays, donde cada uno de los elementos es un documento con la condici\u00f3n a evaluar, de modo que se realiza la uni\u00f3n entre estas condiciones, aplicando la l\u00f3gica asociada a AND y a OR. db.grades.find({ $or:[ {\"type\":\"exam\"}, {\"score\":{$gte:65}} ]}) db.grades.find({ $or:[ {\"score\":{$lt:50}}, {\"score\":{$gt:90}} ]}) Realmente el operador $and no se suele usar porque podemos anidar en la consulta 2 criterios, al poner uno dentro del otro. As\u00ed pues, estas dos consultas hacen lo mismo: Ejemplos consultas conjunciones con y sin $and db.grades.find({ type:\"exam\", score:{$gte:65} }) db.grades.find({ $and:[ {type:\"exam\"}, {score:{$gte:65}} ] }) Consejo de Rendimiento Las consultas conjuntivas, es decir, con varios criterios excluyentes u operador $or, deben filtrar el conjunto m\u00e1s grande cuanto m\u00e1s pronto posible. Supongamos que vamos a consultar los mismos documentos que cumplen los criterios A (40.000 documentos), B (9.000 documentos) y C (200 documentos). Si filtramos C, luego B, y finalmente A, el conjunto de documentos que tiene que comprobar MongoDB es muy grande. Restringiendo consultas OR Figure 5. Restringiendo consultas OR de menor a myor En cambio, si hacemos una consulta que primero empiece por el criterio menos restrictivo, el conjunto de documentos sobre el cual va a tener que comprobar siguientes criterios va a ser menor, y por tanto, se realizar\u00e1 m\u00e1s r\u00e1pido. Restringiendo consultas AND Figure 6. Restringiendo consultas OR de mayor a menor Tambi\u00e9n podemos utilizar el operado $nor, que no es m\u00e1s que la negaci\u00f3n de $or y que obtendr\u00e1 aquellos documentos que no cumplan ninguna de las condiciones. Autoevaluaci\u00f3n Que obtendr\u00edamos al ejecutar la siguiente consulta: [2] db.grades.find({ score:{$gte:65}, $nor:[ {type:\"quiz\"}, {type:\"homework\"} ] }) Finalmente, si queremos indicar mediante un array los diferentes valores que puede cumplir un campo, podemos utilizar el operador $in: db.grades.find({ type:{$in:[\"quiz\",\"exam\"]}}) Por supuesto, tambi\u00e9n existe su negaci\u00f3n mediante $nin.","title":"Condiciones compuestas con Y / O"},{"location":"sa/02mongo.html#consultas-sobre-arrays","text":"Si trabajamos con arrays, vamos a poder consultar el contenido de una posici\u00f3n del mismo tal como si fuera un campo normal, siempre que sea un campo de primer nivel, es decir, no sea un documento embebido dentro de un array. Si queremos filtrar teniendo en cuenta el n\u00famero de ocurrencias del array, podemos utilizar: $all para filtrar ocurrencias que tienen todos los valores del array, es decir, los valores pasados a la consulta ser\u00e1n un subconjunto del resultado. Puede que devuelva los mismos, o un array con m\u00e1s campos (el orden no importa) $in, igual que SQL, para obtener las ocurrencias que cumple con alguno de los valores pasados (similar a usar $or sobre un conjunto de valores de un mismo campo). Si queremos su negaci\u00f3n, usaremos $nin, para obtener los documentos que no cumplen ninguno de los valores. Por ejemplo, si queremos obtener las personas que dentro de sus amistades se encuentre Juan y David, y respecto a sus hobbies est\u00e9n el footing o el baloncesto, tendr\u00edamos: Ejemplo consulta con $all y $in db.people.find( {amistades: {$all: [\"Juan\", \"David\"]}, hobbies: {$in: [\"footing\", \"baloncesto\"]}} ) Si el array contiene documentos y queremos filtrar la consulta sobre los campos de los documentos del array, tenemos que utilizar $elemMatch. M\u00e1s informaci\u00f3n en http://docs.mongodb.org/manual/reference/operator/projection/elemMatch/ Si lo que nos interesa es la cantidad de elementos que contiene un array, emplearemos el operador $size. Por ejemplo, para obtener las personas que tienen 3 hobbies har\u00edamos: Ejemplo consulta con $size db.people.find( {hobbies : {$size : 3}} ) Finalmente, a la hora de proyectar los datos, si no estamos interesados en todos los valores de un campo que es un array, podemos restringir el resultado mediante el operador $slice: As\u00ed pues, si quisieramos obtener las personas que tienen mas de un hijo, y que de esas personas, en vez de mostrar todos sus hobbies, mostrase los dos primeros, har\u00edamos: Ejemplo con $slice db.people.find( {hijos: {$gt:1}}, {hobbies: {$slice:2}} ) M\u00e1s informaci\u00f3n en http://docs.mongodb.org/manual/reference/operator/projection/slice/","title":"Consultas sobre arrays"},{"location":"sa/02mongo.html#conjunto-de-valores","text":"Igual que en SQL, a partir de un colecci\u00f3n, si queremos obtener todos los diferentes valores que existen en un campo, utilizaremos el m\u00e9todo distinct db.grades.distinct('type') [ \"exam\", \"quiz\", \"homework\" ] Si queremos filtrar los datos sobre los que se obtienen los valores, le pasaremos un segundo par\u00e1metro con el criterio a aplicar: db.grades.distinct('type', { score: { $gt: 99.9 } } ) [ \"exam\" ] 2.4.7. Cursores Al hacer una consulta en el shell, se devuelve un cursor. Este cursor lo podemos guardar en un variable, y partir de ah\u00ed trabajar con \u00e9l como har\u00edamos mediante Java. Si cur es la variable que referencia al cursor, podremos utilizar los siguientes m\u00e9todos: Table 3. M\u00e9todos de uso de cursores M\u00e9todo Uso Lugar de ejecuci\u00f3n cur.hasNext() true/false para saber si quedan elementos Cliente cur.next() Pasa al siguiente documento Cliente cur.limit(numElementos) Restringe el n\u00famero de resultados a numElementos Servidor cur.sort({campo:1}) Ordena los datos por campo 1 ascendente o -1 o descendente Servidor cur.skip(numElementos) Permite saltar numElementos con el cursor Servidor La consulta no se ejecuta hasta que el cursor comprueba o pasa al siguiente documento (next/hasNext), por ello que tanto limit como sort (ambos modifican el cursor) s\u00f3lo se pueden realizar antes de recorrer cualquier elemento del cursor. Como tras realizar una consulta con find, realmente se devuelve un cursor, un uso muy habitual es encadenar una operaci\u00f3n de find con sort y/o limit para ordenar el resultado por uno o m\u00e1s campos y posteriormente limitar el n\u00famero de documentos a devolver. As\u00ed pues, si quisi\u00e9ramos obtener la calificaci\u00f3n del trabajo con la nota m\u00e1s alta, podr\u00edamos hacerlo as\u00ed: db.grades.find({ type:'homework'}).sort({score:-1}).limit(1) Por ejemplo, si queremos paginar las notas de 10 en 10, a partir de la tercera p\u00e1gina, podr\u00edamos hacer algo as\u00ed: db.grades.find().sort({score:-1}).limit(10).skip(20); Autoevaluaci\u00f3n A partir de la colecci\u00f3n grades, escribe un consulta que obtenga los documentos de tipo \"exam\" ordenados descendentemente y que obtenga los documentos de 51 al 70. [3]","title":"Conjunto de valores"},{"location":"sa/02mongo.html#contando-documentos","text":"Para contar el n\u00famero de documentos, en vez de find usaremos el m\u00e9todo count. Por ejemplo: db.grades.count({type:\"exam\"}) db.grades.find({type:\"exam\"}).count() db.grades.count({type:\"essay\", score:{$gt:90}}) Tambi\u00e9n se puede utilizar count como m\u00e9todo de un cursor.","title":"Contando Documentos"},{"location":"sa/02mongo.html#insertando-y-modificando","text":"","title":"Insertando y modificando"},{"location":"sa/02mongo.html#referencias","text":"Manual de MongoDB Cheatseat","title":"Referencias"},{"location":"sa/02mongo.html#actividades","text":"Primeros pasos. Conexi\u00f3n, Consultas sencillas (**) Operaciones CRUD (**)","title":"Actividades"},{"location":"sa/03modelado.html","text":"Modelado NoSQL \u00b6 MongoDB es una base de datos documental, no relacional, donde el esquema no se debe basar en el uso de claves ajenas/joins, ya que no existen. A la hora de dise\u00f1ar un esquema, si nos encontramos que el esquema esta en 3FN o si cuando hacemos consultas (recordad que no hay joins) estamos teniendo que realizar varias consultas de manera programativa (primero acceder a una tabla, con ese _id ir a otra tabla, etc\u2026\u200b.) es que no estamos siguiendo el enfoque adecuado. MongoDB no soporta transacciones, ya que su enfoque distribuido dificultar\u00eda y penalizar\u00eda el rendimiento. En cambio, s\u00ed que asegura que las operaciones sean at\u00f3micas. Los posibles enfoques para solucionar la falta de transacciones son: Restructurar el c\u00f3digo para que toda la informaci\u00f3n est\u00e9 contenida en un \u00fanico documento. Implementar un sistema de bloqueo por software (sem\u00e1foro, etc\u2026\u200b). Tolerar un grado de inconsistencia en el sistema. Dependiendo del tipo de relaci\u00f3n entre dos documentos, normalizaremos los datos para minimizar la redundancia pero manteniendo en la medida de lo posible que mediante operaciones at\u00f3micas se mantenga la integridad de los datos. Para ello, bien crearemos referencias entre dos documentos o embeberemos un documento dentro de otro. Relacionando documentos \u00b6 Las aplicaciones que emplean MongoDB utilizan dos t\u00e9cnicas para relacionar documentos: Referencias Manuales Uso de DBRef Referencias manuales \u00b6 De manera similar a una base de datos relacional, se almacena el campo _id de un documento en otro documento a modo de clave ajena. De este modo, la aplicaci\u00f3n realiza una segunda consulta para obtener los datos relacionados. Estas referencias son sencillas y suficientes para la mayor\u00eda de casos de uso. Referencias manuales Por ejemplo, si nos basamos en el gr\u00e1fico anterior, podemos conseguir referenciar manualmente estos objetos del siguiente modo: ``` js var idUsuario = ObjectId(); db.usuario.insert({ _id: idUsuario, nombre: \"123xyz\" }); db.contacto.insert({ usuario_id: idUsuario, telefono: \"123 456 7890\", email: \"xyz@ejemplo.com\" }); ``` DBRef \u00b6 Son referencias de un documento a otro mediante el valor del campo _id , el nombre de la colecci\u00f3n y, opcionalmente, el nombre de la base de datos. Estos objetos siguen una convenci\u00f3n para representar un documento mediante la notaci\u00f3n { \"$ref\" : <nombreColeccion>, \"$id\" : <valorCampo_id>, \"$db\" : <nombreBaseDatos> } . Al incluir estos nombres, las DBRef permite referenciar documentos localizados en diferentes colecciones. As\u00ed pues, si reescribimos el c\u00f3digo anterior mediante DBRef tendr\u00edamos que el contacto queda de la siguiente manera: Ejemplo de DBRef - Usuario/Contacto js db.contacto.insert({ usuario_id: new DBRef(\"usuario\", idUsuario), telefono: \"123-456-7890\", email: \"xyz@example.com\" }); De manera similar a las referencias manuales, mediante consultas adicionales se obtendr\u00e1n los documentos referenciados. Muchos drivers (incluido el de Java, mediante la clase DBRef) contienen m\u00e9todos auxiliares que realizan las consultas con referencias DBRef autom\u00e1ticamennte. Desde la propia documentaci\u00f3n de MongoDB, recomiendan el uso de referencias manuales, a no ser de que dispongamos documentos de una colecci\u00f3n que referencian a documentos que se encuentran en varias colecciones diferentes. Datos embebidos \u00b6 En cambio, si dentro de un documento almacenamos los datos mediante sub-documentos, ya sea dentro de un atributo o un array, podremos obtener todos los datos mediante un \u00fanico acceso. Datos embebidos Generalmente, emplearemos datos embebidos cuando tengamos: relaciones \"contiene\" entre entidades, entre relaciones de documentos \"uno a uno\" o \"uno a pocos\". relaciones \"uno a muchos\" entre entidades. En estas relaciones los documentos hijo (o \"muchos\") siempre aparecen dentro del contexto del padre o del documento \"uno\". Los datos embebidos ofrecen mejor rendimiento al permitir obtener los datos mediante una \u00fanica operaci\u00f3n, as\u00ed como modificar datos relacionados en una sola operaci\u00f3n at\u00f3mica de escritura. Un aspecto a tener en cuenta es que un documento BSON puede contener un m\u00e1ximo de 16MB. Si quisi\u00e9ramos que un atributo contenga m\u00e1s informaci\u00f3n, tendr\u00edamos que utilizar el API de GridFS que veremos m\u00e1s adelante. Relaciones \u00b6 Vamos a estudiar en detalle cada uno de los tipos de relaciones, para intentar clarificar cuando es conveniente utilizar referencias o datos embebidos. 1:1 \u00b6 Cuando existe una relaci\u00f3n 1:1, como pueda ser entre Persona y Curriculum, o Persona y Direccion hay que embeber un documento dentro del otro, como parte de un atributo. Ejemplo relaci\u00f3n 1:1 - Persona/Direcci\u00f3n js { nombre: \"Aitor\", edad: 38, direccion: { calle: \"Mayor\", ciudad: \"Elx\" } } La principal ventaja de este planteamiento es que mediante una \u00fanica consulta podemos obtener tanto los detalles del usuario como su direcci\u00f3n. Un par de aspectos que nos pueden llevar a no embeberlos son: la frecuencia de acceso. Si a uno de ellos se accede raramente, puede que convenga tenerlos separados para liberar memoria. el tama\u00f1o de los elementos. Si hay uno que es mucho m\u00e1s grande que el otro, o uno lo modificamos muchas m\u00e1s veces que el otro, para que cada vez que hagamos un cambio en un documento no tengamos que modificar el otro ser\u00e1 mejor separarlos en documentos separados. Pero siempre teniendo en cuenta la atomicidad de los datos, ya que si necesitamos modificar los dos documentos al mismo tiempo, tendremos que embeber uno dentro del otro. 1:N \u00b6 Vamos a distinguir dos tipos: 1 a muchos , como puede ser entre Editorial y Libro. Para este tipo de relaci\u00f3n es mejor usar referencias entre los documentos: Ejemplo relaci\u00f3n 1:N - Editorial js { _id: 1, nombre: \"O'Reilly\", pais: \"EE.UU.\" } Ejemplo relaci\u00f3n 1:N - Libro js { _id: 1234, titulo: \"MongoDB: The Definitive Guide\", autor: [ \"Kristina Chodorow\", \"Mike Dirolf\" ], numPaginas: 216, editorial_id: 1, } { _id: 1235, titulo: \"50 Tips and Tricks for MongoDB Developer\", autor: \"Kristina Chodorow\", numPaginas: 68, editorial_id: 1, } 1 a pocos , como por ejemplo, dentro de un blog, la relaci\u00f3n entre Mensaje y Comentario. En este caso, la mejor soluci\u00f3n es crear un array dentro de la entidad 1 ( en nuestro caso, Mensaje). De este modo, el Mensaje contiene un array de Comentario: Ejemplo relaci\u00f3n 1:N - Mensaje/Comentario js { titulo: \"La broma asesina\", url: \"http://es.wikipedia.org/wiki/Batman:_The_Killing_Joke\", texto: \"La dualidad de Batman y Joker\", comentarios: [ { autor: \"Bruce Wayne\", fecha: ISODate(\"2015-04-01T09:31:32Z\"), comentario: \"A mi me encant\u00f3\" }, { autor: \"Bruno D\u00edaz\", fecha: ISODate(\"2015-04-03T10:07:28Z\"), comentario: \"El mejor\" } ] } Hay que tener siempre en mente la restricci\u00f3n de los 16 MB de BSON. Si vamos a embeber muchos documentos y estos son grandes, hay que vigilar no llegar a dicho tama\u00f1o. En ocasiones las relaciones 1 a muchos se traducen en documentos embebidos cuando la informaci\u00f3n que nos interesa es la que contiene en un momento determinado. Por ejemplo, dentro de Pedido, el precio de los productos debe embeberse, ya que si en un futuro se modifica el precio de un producto determinado debido a una oferta, el pedido realizado no debe modificar su precio total. Del mismo modo, al almacenar la direcci\u00f3n de una persona, tambi\u00e9n es conveniente embeberla. No queremos que la direcci\u00f3n de env\u00edo de un pedido se modique si un usuario modifica sus datos personales. N:M \u00b6 M\u00e1s que relaciones muchos a muchos, suelen ser relaciones pocos a pocos, como por ejemplo, Libro y Autor, o Profesor y Estudiante. Supongamos que tenemos libros de la siguiente manera y autores con la siguiente estructura: Ejemplo relaci\u00f3n N:N - Libro js { _id: 1, titulo: \"La historia interminable\", anyo: 1979 } Ejemplo relaci\u00f3n N:M - Autor js { _id: 1, nombre: \"Michael Ende\", pais: \"Alemania\" } Podemos resolver estas relaciones de tres maneras: Siguiendo un enfoque relacional, empleando un documento como la entidad que agrupa con referencias manuales a los dos documentos. Ejemplo relaci\u00f3n N:M - Autor/Libro js { autor_id: 1, libro_id: 1 } Este enfoque se desaconseja porque necesita tres consultas para obtener toda la informaci\u00f3n. Mediante 2 documentos, cada uno con un array que contenga los ids del otro documento (2 Way Embedding). Hay que tener cuidado porque podemos tener problemas de inconsistencia de datos si no actualizamos correctamente. Ejemplo relaci\u00f3n N:N - Libro referencia a Autor js { _id: 1, titulo: \"La historia interminable\", anyo: 1979, autores: [1] },{ _id: 2, titulo: \"Momo\", anyo: 1973, autores: [1] } Ejemplo relaci\u00f3n N:M - Autor referencia a Libro js { _id: 1, nombre: \"Michael Ende\", pais: \"Alemania\", libros: [1,2] } Embeber un documento dentro de otro (One Way Embedding). Por ejemplo: Ejemplo relaci\u00f3n N:M - Autor embebido en Libro js { _id: 1, titulo: \"La historia interminable\", anyo: 1979, autores: [{nombre:\"Michael Ende\", pais:\"Alemania\"}] },{ _id: 2, titulo: \"Momo\", anyo: 1973, autores: [{nombre:\"Michael Ende\", pais:\"Alemania\"}] } En principio este enfoque no se recomienda porque el documento puede crecer mucho y provocar anomal\u00edas de modificaciones donde la informaci\u00f3n no es consistente. Si se opta por esta soluci\u00f3n, hay que tener en cuenta que si un documento depende de otro para su creaci\u00f3n (por ejemplo, si metemos los profesores dentro de los estudiantes, no vamos a poder dar de alta a profesores sin haber dado de alta previamente a un alumno). A modo de resumen, en las relaciones N:M, hay que establecer el tama\u00f1o de N y M. Si N como m\u00e1ximo vale 3 y M 500000, entonces deber\u00edamos seguir un enfoque de embeber la N dentro de la M (One Way Embedding). En cambio, si N vale 3 y M vale 5, entonces podemos hacer que ambos embeban al otro documento (Two Way Embedding). M\u00e1s informaci\u00f3n en http://docs.mongodb.org/manual/applications/data-models-relationships/ Jer\u00e1rquicas \u00b6 Si tenemos que modelar alguna entidad que tenga hijos y nos importa las relaciones padre-hijos (categor\u00eda-subcategor\u00eda), podemos tanto embeber un array con los hijos de un documento (children), como embeber un array con los padres de un documento (ancestors) M\u00e1s informaci\u00f3n en http://docs.mongodb.org/manual/applications/data-models-tree-structures/ Patrones \u00b6 Duplicidad, caducidad e integridad \u00b6 Attribute Pattern \u00b6 Extended Reference Pattern \u00b6 In this case, the Extended Reference Pattern will easily take care of the additional queries our application is making. To implement the pattern we can modify the inventory item documents by adding frequently-accessed order data directly to them. This will result in lowering the number of related queries on the orders collection, since the relevant data about the orders will now be part of the inventory item documents. Subset Pattern \u00b6 Computed Pattern \u00b6 En vez de calcular un dato agregado en cada lectura, en una colecci\u00f3n aparte se guardan los datos calculados, de manera que cuando llega un nuevo registro, se recalcula este valor y se modifica el documento oportuno. Tiene sentido en aplicaciones donde hay muchas m\u00e1s lecturas que escrituras. The Computed Pattern allows your application to calculate values at write time. In this case, the sum of the number of views would be calculated in a rolling fashion by book genre. Bucket Pattern \u00b6 Agrupar los datos por fecha o categor\u00eda para reducir la cantidad de documentos o el tama\u00f1o de los mismos. The Bucket pattern allows us to record data in hour interval documents, which can then be stored in yearly collections. This makes it easy to store, analyze, and purge the data within the given time requirements. Schema Versioning Pattern \u00b6 A\u00f1ade un atributo schema_version para indicar que versi\u00f3n del esquema cumplen los datos. Permite evitar downtime al realizar la actualizaci\u00f3n del esquema This pattern allows for the application to quickly identify which document structure it is dealing with, the old one or the new. This helps to minimize downtime for the application user, while allowing the database to smoothly transition to the new schema. Tree Pattern \u00b6 Representaci\u00f3n de datos jer\u00e1rquicos. Referencias de hijos, padre, array de ancestors , materilized paths . Polymorphic Pattern \u00b6 The problem states that bodegas sell a variety of items from different categories, with different purposes and properties. In this case, the Polymorphic Pattern will be the best candidate to catalog this set of goods. Otros patrones asdf Referencias \u00b6 https://andreshevia.com/2020/10/18/diseno-de-modelos-de-datos-nosql/ https://www.mongodb.com/developer/products/mongodb/schema/tutorials/ https://www.mongodb.com/developer/products/mongodb/schema-design-anti-pattern-summary/ Actividades \u00b6 (1p) Estimaci\u00f3n de la carga de trabajo en un proceso de ingesta de datos. (Metodolog\u00eda curso MongoDB University) (2p) Ejercicios de modelado de relaciones 1:1, 1:N, N:M que impliquen documentos embebidos y/o relaciones (1p) Consultas agregadas sobre documentos con o sin referencias a otras colecciones.","title":"S26.- Modelado de datos NoSQL"},{"location":"sa/03modelado.html#modelado-nosql","text":"MongoDB es una base de datos documental, no relacional, donde el esquema no se debe basar en el uso de claves ajenas/joins, ya que no existen. A la hora de dise\u00f1ar un esquema, si nos encontramos que el esquema esta en 3FN o si cuando hacemos consultas (recordad que no hay joins) estamos teniendo que realizar varias consultas de manera programativa (primero acceder a una tabla, con ese _id ir a otra tabla, etc\u2026\u200b.) es que no estamos siguiendo el enfoque adecuado. MongoDB no soporta transacciones, ya que su enfoque distribuido dificultar\u00eda y penalizar\u00eda el rendimiento. En cambio, s\u00ed que asegura que las operaciones sean at\u00f3micas. Los posibles enfoques para solucionar la falta de transacciones son: Restructurar el c\u00f3digo para que toda la informaci\u00f3n est\u00e9 contenida en un \u00fanico documento. Implementar un sistema de bloqueo por software (sem\u00e1foro, etc\u2026\u200b). Tolerar un grado de inconsistencia en el sistema. Dependiendo del tipo de relaci\u00f3n entre dos documentos, normalizaremos los datos para minimizar la redundancia pero manteniendo en la medida de lo posible que mediante operaciones at\u00f3micas se mantenga la integridad de los datos. Para ello, bien crearemos referencias entre dos documentos o embeberemos un documento dentro de otro.","title":"Modelado NoSQL"},{"location":"sa/03modelado.html#relacionando-documentos","text":"Las aplicaciones que emplean MongoDB utilizan dos t\u00e9cnicas para relacionar documentos: Referencias Manuales Uso de DBRef","title":"Relacionando documentos"},{"location":"sa/03modelado.html#referencias-manuales","text":"De manera similar a una base de datos relacional, se almacena el campo _id de un documento en otro documento a modo de clave ajena. De este modo, la aplicaci\u00f3n realiza una segunda consulta para obtener los datos relacionados. Estas referencias son sencillas y suficientes para la mayor\u00eda de casos de uso. Referencias manuales Por ejemplo, si nos basamos en el gr\u00e1fico anterior, podemos conseguir referenciar manualmente estos objetos del siguiente modo: ``` js var idUsuario = ObjectId(); db.usuario.insert({ _id: idUsuario, nombre: \"123xyz\" }); db.contacto.insert({ usuario_id: idUsuario, telefono: \"123 456 7890\", email: \"xyz@ejemplo.com\" }); ```","title":"Referencias manuales"},{"location":"sa/03modelado.html#dbref","text":"Son referencias de un documento a otro mediante el valor del campo _id , el nombre de la colecci\u00f3n y, opcionalmente, el nombre de la base de datos. Estos objetos siguen una convenci\u00f3n para representar un documento mediante la notaci\u00f3n { \"$ref\" : <nombreColeccion>, \"$id\" : <valorCampo_id>, \"$db\" : <nombreBaseDatos> } . Al incluir estos nombres, las DBRef permite referenciar documentos localizados en diferentes colecciones. As\u00ed pues, si reescribimos el c\u00f3digo anterior mediante DBRef tendr\u00edamos que el contacto queda de la siguiente manera: Ejemplo de DBRef - Usuario/Contacto js db.contacto.insert({ usuario_id: new DBRef(\"usuario\", idUsuario), telefono: \"123-456-7890\", email: \"xyz@example.com\" }); De manera similar a las referencias manuales, mediante consultas adicionales se obtendr\u00e1n los documentos referenciados. Muchos drivers (incluido el de Java, mediante la clase DBRef) contienen m\u00e9todos auxiliares que realizan las consultas con referencias DBRef autom\u00e1ticamennte. Desde la propia documentaci\u00f3n de MongoDB, recomiendan el uso de referencias manuales, a no ser de que dispongamos documentos de una colecci\u00f3n que referencian a documentos que se encuentran en varias colecciones diferentes.","title":"DBRef"},{"location":"sa/03modelado.html#datos-embebidos","text":"En cambio, si dentro de un documento almacenamos los datos mediante sub-documentos, ya sea dentro de un atributo o un array, podremos obtener todos los datos mediante un \u00fanico acceso. Datos embebidos Generalmente, emplearemos datos embebidos cuando tengamos: relaciones \"contiene\" entre entidades, entre relaciones de documentos \"uno a uno\" o \"uno a pocos\". relaciones \"uno a muchos\" entre entidades. En estas relaciones los documentos hijo (o \"muchos\") siempre aparecen dentro del contexto del padre o del documento \"uno\". Los datos embebidos ofrecen mejor rendimiento al permitir obtener los datos mediante una \u00fanica operaci\u00f3n, as\u00ed como modificar datos relacionados en una sola operaci\u00f3n at\u00f3mica de escritura. Un aspecto a tener en cuenta es que un documento BSON puede contener un m\u00e1ximo de 16MB. Si quisi\u00e9ramos que un atributo contenga m\u00e1s informaci\u00f3n, tendr\u00edamos que utilizar el API de GridFS que veremos m\u00e1s adelante.","title":"Datos embebidos"},{"location":"sa/03modelado.html#relaciones","text":"Vamos a estudiar en detalle cada uno de los tipos de relaciones, para intentar clarificar cuando es conveniente utilizar referencias o datos embebidos.","title":"Relaciones"},{"location":"sa/03modelado.html#11","text":"Cuando existe una relaci\u00f3n 1:1, como pueda ser entre Persona y Curriculum, o Persona y Direccion hay que embeber un documento dentro del otro, como parte de un atributo. Ejemplo relaci\u00f3n 1:1 - Persona/Direcci\u00f3n js { nombre: \"Aitor\", edad: 38, direccion: { calle: \"Mayor\", ciudad: \"Elx\" } } La principal ventaja de este planteamiento es que mediante una \u00fanica consulta podemos obtener tanto los detalles del usuario como su direcci\u00f3n. Un par de aspectos que nos pueden llevar a no embeberlos son: la frecuencia de acceso. Si a uno de ellos se accede raramente, puede que convenga tenerlos separados para liberar memoria. el tama\u00f1o de los elementos. Si hay uno que es mucho m\u00e1s grande que el otro, o uno lo modificamos muchas m\u00e1s veces que el otro, para que cada vez que hagamos un cambio en un documento no tengamos que modificar el otro ser\u00e1 mejor separarlos en documentos separados. Pero siempre teniendo en cuenta la atomicidad de los datos, ya que si necesitamos modificar los dos documentos al mismo tiempo, tendremos que embeber uno dentro del otro.","title":"1:1"},{"location":"sa/03modelado.html#1n","text":"Vamos a distinguir dos tipos: 1 a muchos , como puede ser entre Editorial y Libro. Para este tipo de relaci\u00f3n es mejor usar referencias entre los documentos: Ejemplo relaci\u00f3n 1:N - Editorial js { _id: 1, nombre: \"O'Reilly\", pais: \"EE.UU.\" } Ejemplo relaci\u00f3n 1:N - Libro js { _id: 1234, titulo: \"MongoDB: The Definitive Guide\", autor: [ \"Kristina Chodorow\", \"Mike Dirolf\" ], numPaginas: 216, editorial_id: 1, } { _id: 1235, titulo: \"50 Tips and Tricks for MongoDB Developer\", autor: \"Kristina Chodorow\", numPaginas: 68, editorial_id: 1, } 1 a pocos , como por ejemplo, dentro de un blog, la relaci\u00f3n entre Mensaje y Comentario. En este caso, la mejor soluci\u00f3n es crear un array dentro de la entidad 1 ( en nuestro caso, Mensaje). De este modo, el Mensaje contiene un array de Comentario: Ejemplo relaci\u00f3n 1:N - Mensaje/Comentario js { titulo: \"La broma asesina\", url: \"http://es.wikipedia.org/wiki/Batman:_The_Killing_Joke\", texto: \"La dualidad de Batman y Joker\", comentarios: [ { autor: \"Bruce Wayne\", fecha: ISODate(\"2015-04-01T09:31:32Z\"), comentario: \"A mi me encant\u00f3\" }, { autor: \"Bruno D\u00edaz\", fecha: ISODate(\"2015-04-03T10:07:28Z\"), comentario: \"El mejor\" } ] } Hay que tener siempre en mente la restricci\u00f3n de los 16 MB de BSON. Si vamos a embeber muchos documentos y estos son grandes, hay que vigilar no llegar a dicho tama\u00f1o. En ocasiones las relaciones 1 a muchos se traducen en documentos embebidos cuando la informaci\u00f3n que nos interesa es la que contiene en un momento determinado. Por ejemplo, dentro de Pedido, el precio de los productos debe embeberse, ya que si en un futuro se modifica el precio de un producto determinado debido a una oferta, el pedido realizado no debe modificar su precio total. Del mismo modo, al almacenar la direcci\u00f3n de una persona, tambi\u00e9n es conveniente embeberla. No queremos que la direcci\u00f3n de env\u00edo de un pedido se modique si un usuario modifica sus datos personales.","title":"1:N"},{"location":"sa/03modelado.html#nm","text":"M\u00e1s que relaciones muchos a muchos, suelen ser relaciones pocos a pocos, como por ejemplo, Libro y Autor, o Profesor y Estudiante. Supongamos que tenemos libros de la siguiente manera y autores con la siguiente estructura: Ejemplo relaci\u00f3n N:N - Libro js { _id: 1, titulo: \"La historia interminable\", anyo: 1979 } Ejemplo relaci\u00f3n N:M - Autor js { _id: 1, nombre: \"Michael Ende\", pais: \"Alemania\" } Podemos resolver estas relaciones de tres maneras: Siguiendo un enfoque relacional, empleando un documento como la entidad que agrupa con referencias manuales a los dos documentos. Ejemplo relaci\u00f3n N:M - Autor/Libro js { autor_id: 1, libro_id: 1 } Este enfoque se desaconseja porque necesita tres consultas para obtener toda la informaci\u00f3n. Mediante 2 documentos, cada uno con un array que contenga los ids del otro documento (2 Way Embedding). Hay que tener cuidado porque podemos tener problemas de inconsistencia de datos si no actualizamos correctamente. Ejemplo relaci\u00f3n N:N - Libro referencia a Autor js { _id: 1, titulo: \"La historia interminable\", anyo: 1979, autores: [1] },{ _id: 2, titulo: \"Momo\", anyo: 1973, autores: [1] } Ejemplo relaci\u00f3n N:M - Autor referencia a Libro js { _id: 1, nombre: \"Michael Ende\", pais: \"Alemania\", libros: [1,2] } Embeber un documento dentro de otro (One Way Embedding). Por ejemplo: Ejemplo relaci\u00f3n N:M - Autor embebido en Libro js { _id: 1, titulo: \"La historia interminable\", anyo: 1979, autores: [{nombre:\"Michael Ende\", pais:\"Alemania\"}] },{ _id: 2, titulo: \"Momo\", anyo: 1973, autores: [{nombre:\"Michael Ende\", pais:\"Alemania\"}] } En principio este enfoque no se recomienda porque el documento puede crecer mucho y provocar anomal\u00edas de modificaciones donde la informaci\u00f3n no es consistente. Si se opta por esta soluci\u00f3n, hay que tener en cuenta que si un documento depende de otro para su creaci\u00f3n (por ejemplo, si metemos los profesores dentro de los estudiantes, no vamos a poder dar de alta a profesores sin haber dado de alta previamente a un alumno). A modo de resumen, en las relaciones N:M, hay que establecer el tama\u00f1o de N y M. Si N como m\u00e1ximo vale 3 y M 500000, entonces deber\u00edamos seguir un enfoque de embeber la N dentro de la M (One Way Embedding). En cambio, si N vale 3 y M vale 5, entonces podemos hacer que ambos embeban al otro documento (Two Way Embedding). M\u00e1s informaci\u00f3n en http://docs.mongodb.org/manual/applications/data-models-relationships/","title":"N:M"},{"location":"sa/03modelado.html#jerarquicas","text":"Si tenemos que modelar alguna entidad que tenga hijos y nos importa las relaciones padre-hijos (categor\u00eda-subcategor\u00eda), podemos tanto embeber un array con los hijos de un documento (children), como embeber un array con los padres de un documento (ancestors) M\u00e1s informaci\u00f3n en http://docs.mongodb.org/manual/applications/data-models-tree-structures/","title":"Jer\u00e1rquicas"},{"location":"sa/03modelado.html#patrones","text":"","title":"Patrones"},{"location":"sa/03modelado.html#duplicidad-caducidad-e-integridad","text":"","title":"Duplicidad, caducidad e integridad"},{"location":"sa/03modelado.html#attribute-pattern","text":"","title":"Attribute Pattern"},{"location":"sa/03modelado.html#extended-reference-pattern","text":"In this case, the Extended Reference Pattern will easily take care of the additional queries our application is making. To implement the pattern we can modify the inventory item documents by adding frequently-accessed order data directly to them. This will result in lowering the number of related queries on the orders collection, since the relevant data about the orders will now be part of the inventory item documents.","title":"Extended Reference Pattern"},{"location":"sa/03modelado.html#subset-pattern","text":"","title":"Subset Pattern"},{"location":"sa/03modelado.html#computed-pattern","text":"En vez de calcular un dato agregado en cada lectura, en una colecci\u00f3n aparte se guardan los datos calculados, de manera que cuando llega un nuevo registro, se recalcula este valor y se modifica el documento oportuno. Tiene sentido en aplicaciones donde hay muchas m\u00e1s lecturas que escrituras. The Computed Pattern allows your application to calculate values at write time. In this case, the sum of the number of views would be calculated in a rolling fashion by book genre.","title":"Computed Pattern"},{"location":"sa/03modelado.html#bucket-pattern","text":"Agrupar los datos por fecha o categor\u00eda para reducir la cantidad de documentos o el tama\u00f1o de los mismos. The Bucket pattern allows us to record data in hour interval documents, which can then be stored in yearly collections. This makes it easy to store, analyze, and purge the data within the given time requirements.","title":"Bucket Pattern"},{"location":"sa/03modelado.html#schema-versioning-pattern","text":"A\u00f1ade un atributo schema_version para indicar que versi\u00f3n del esquema cumplen los datos. Permite evitar downtime al realizar la actualizaci\u00f3n del esquema This pattern allows for the application to quickly identify which document structure it is dealing with, the old one or the new. This helps to minimize downtime for the application user, while allowing the database to smoothly transition to the new schema.","title":"Schema Versioning Pattern"},{"location":"sa/03modelado.html#tree-pattern","text":"Representaci\u00f3n de datos jer\u00e1rquicos. Referencias de hijos, padre, array de ancestors , materilized paths .","title":"Tree Pattern"},{"location":"sa/03modelado.html#polymorphic-pattern","text":"The problem states that bodegas sell a variety of items from different categories, with different purposes and properties. In this case, the Polymorphic Pattern will be the best candidate to catalog this set of goods. Otros patrones asdf","title":"Polymorphic Pattern"},{"location":"sa/03modelado.html#referencias","text":"https://andreshevia.com/2020/10/18/diseno-de-modelos-de-datos-nosql/ https://www.mongodb.com/developer/products/mongodb/schema/tutorials/ https://www.mongodb.com/developer/products/mongodb/schema-design-anti-pattern-summary/","title":"Referencias"},{"location":"sa/03modelado.html#actividades","text":"(1p) Estimaci\u00f3n de la carga de trabajo en un proceso de ingesta de datos. (Metodolog\u00eda curso MongoDB University) (2p) Ejercicios de modelado de relaciones 1:1, 1:N, N:M que impliquen documentos embebidos y/o relaciones (1p) Consultas agregadas sobre documentos con o sin referencias a otras colecciones.","title":"Actividades"},{"location":"sa/04formatos.html","text":"Formatos de datos. Escalabilidad en MongoDB \u00b6 Formatos \u00b6 Escalabilidad \u00b6 Referencias \u00b6 Actividades \u00b6","title":"S28.- Formatos de datos"},{"location":"sa/04formatos.html#formatos-de-datos-escalabilidad-en-mongodb","text":"","title":"Formatos de datos. Escalabilidad en MongoDB"},{"location":"sa/04formatos.html#formatos","text":"","title":"Formatos"},{"location":"sa/04formatos.html#escalabilidad","text":"","title":"Escalabilidad"},{"location":"sa/04formatos.html#referencias","text":"","title":"Referencias"},{"location":"sa/04formatos.html#actividades","text":"","title":"Actividades"},{"location":"sa/05pymongo.html","text":"PyMongo \u00b6 Para acceder a MongoDB desde Python nos vamos a centrar en la librer\u00eda PyMongo . Para instalar la librer\u00eda mediante pip usaremos el comando (recuerda hacerlo dentro de un entorno virtual): bash pip install pymongo Se recomienda consultar la documentaci\u00f3n o el API para cualquier duda o aclaraci\u00f3n. Versi\u00f3n En el momento de escribir los apuntes, estamos utilizando la versi\u00f3n 4.2.0 de PyMongo. MFlix \u00b6 https://s3.amazonaws.com/edu-downloads.10gen.com/M220P/2022/July/static/handouts/m220/mflix-python.zip Estructura del proyecto \u00b6 verything you will implement is located in the mflix/db.py file, which contains all database interfacing methods. The API will make calls to db.py to interact with MongoDB. The unit tests in tests will test these database access methods directly, without going through the API. The UI will run these methods in integration tests, and therefore requires the full application to be running. The API layer is fully implemented, as is the UI. If you need to run on a port other than 5000, you can edit the index.html file in the build directory to modify the value of window.host. Please do not modify the API layer in any way, movies.py and user.py under the mflix/api directory. Doing so will most likely result in the frontend application failing to validate some of the labs. Preparando el entorno \u00b6 Descargamos y descomprimimos el archivo Dentro de la carpeta, vamos a crear un entorno virtual con venv: bash virtualenv mflix_venv A continuaci\u00f3n, lo activamos: bash source mflix_venv/bin/activate E instalamos los requisitos: bash pip install -r requirements.txt Running the Application In the mflix-python directory you can find a file called dotini. Open this file and enter your Atlas SRV connection string as directed in the comment. This is the information the driver will use to connect. Make sure not to wrap your Atlas SRV connection between quotes: COPY MFLIX_DB_URI = mongodb+srv://... Rename this file to .ini with the following command: COPY mv dotini_unix .ini # on Unix ren dotini_win .ini # on Windows Note: Once you rename this file to .ini, it will no longer be visible in Finder or File Explorer. However, it will be visible from Command Prompt or Terminal, so if you need to edit it again, you can open it from there: COPY vi .ini # on Unix notepad .ini # on Windows Arrancando y Probando \u00b6 Para arrancar la aplicaci\u00f3n ejecutaremos el script run.py : bash python run.py Al ejecutar el script, arrancar\u00e1 la aplicaci\u00f3n y podremos acceder a ella a trav\u00e9s de http://127.0.0.1:5000/ . PANTALLAZO Si queremos ejecutar los test: Running the Unit Tests To run the unit tests for this course, you will use pytest and needs to be run from mflix-python directory. Each course lab contains a module of unit tests that you can call individually with a command like the following: COPY pytest -m LAB_UNIT_TEST_NAME Each ticket will contain the command to run that ticket's specific unit tests. For example to run the Connection Ticket test your shell command will be: COPY pytest -m connection MongoClient \u00b6 A partir de la URI de conexi\u00f3n a MongoDB, hemos de instanciar la clase MongoClient : python uri = \"mongodb+srv://usuario:contrasenya@host\" cliente = MongoCliente(uri) Podemos obtener informaci\u00f3n de la conexi\u00f3n mediante la propiedad state : python print(cliente.state) Por ejemplo, en nuestro caso, nos hemos conectado a MongoAtlas y de la salida del estado podemos ver los diferentes hosts que forman parte del conjunto de r\u00e9plicas: js Database(MongoClient(host=['ac-hrdpnx0-shard-00-02.4hm7u8y.mongodb.net:27017', 'ac-hrdpnx0-shard-00-01.4hm7u8y.mongodb.net:27017', 'ac-hrdpnx0-shard-00-00.4hm7u8y.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-pxc2m9-shard-0', ssl=True, connecttimeoutms=200, retrywrites=True), 'stats') Par\u00e1metros adicionales A la hora de crear el cliente, tambi\u00e9n podemos indicarle opciones de configuraci\u00f3n: cliente200Retry = MongoClient(uri, connectTimeoutMS=200, retryWrites=True) Tambi\u00e9n podemos obtener un listado de las bases de datos mediante list_database_names() : ``` python print(cliente.list_database_names()) ['sample_airbnb', 'sample_analytics', 'sample_geospatial', 'sample_guides', 'sample_mflix', 'sample_restaurants', 'sample_supplies', 'sample_training', 'sample_weatherdata', 'admin', 'local'] \u00b6 ``` Para conectarnos a una base de datos en concreto, \u00fanicamente accederemos a ella como una propiedad del cliente: python bd = cliente.sample_mflix bd = cliente[\"sample_mflix'] # tb podemos acceder como si fuera un diccionario Bases de datos y colecciones Lazy Es conveniente tener en cuenta que tantos las colecciones como las bases de datos se crean y carga de forma perezosa, esto es, hasta que no realizamos una operaci\u00f3n sobre ellas, no se accede realmente a ellas. As\u00ed pues, para crear realmente una colecci\u00f3n, hemos de insertar un documento en ella. Una vez tenemos la base de datos, el siguiente paso es obtener una colecci\u00f3n: python coleccion = bd.movies coleccion = bd[\"movies'] Si queremos obtener el nombre de todas las colecciones usaremos el m\u00e9todo list_collection_names() : ``` python print(bd.list_collection_names()) ['sessions', 'theaters', 'movies', 'comments', 'users'] \u00b6 ``` Primeras consultas \u00b6 Finalmente, sobre una colecci\u00f3n ya podemos realizar consultas y otras operaciones: ``` python coleccion.count_documents({}) 23530 \u00b6 coleccion.findOne() ``` Por ejemplo, podemos filtrar las pel\u00edculas de Salma Hayek: python movies.find( { \"cast\": \"Salma Hayek\" } ) ``` python return the count of movies with \"Salma Hayek\" in the \"cast\" \u00b6 movies.find( { \"cast\": \"Salma Hayek\" } ).count() ``` ``` python find all movies with Salma Hayek \u00b6 then pretty print \u00b6 cursor = movies.find( { \"cast\": \"Salma Hayek\" } ) from bson.json_util import dumps print(dumps(cursor, indent=2)) ``` ``` python find all movies with Salma Hayek, but only project the \"_id\" and \"title\" fields \u00b6 cursor = movies.find( { \"cast\": \"Salma Hayek\" }, { \"title\": 1 } ) print(dumps(cursor, indent=2)) ``` ``` python find all movies with Salma Hayek, but only project the \"title\" field \u00b6 cursor = movies.find( { \"cast\": \"Salma Hayek\" }, { \"title\": 1, \"_id\": 0 } ) print(dumps(cursor, indent=2)) ``` Referencias \u00b6 Actividades \u00b6","title":"S30.- MongoDB y Python"},{"location":"sa/05pymongo.html#pymongo","text":"Para acceder a MongoDB desde Python nos vamos a centrar en la librer\u00eda PyMongo . Para instalar la librer\u00eda mediante pip usaremos el comando (recuerda hacerlo dentro de un entorno virtual): bash pip install pymongo Se recomienda consultar la documentaci\u00f3n o el API para cualquier duda o aclaraci\u00f3n. Versi\u00f3n En el momento de escribir los apuntes, estamos utilizando la versi\u00f3n 4.2.0 de PyMongo.","title":"PyMongo"},{"location":"sa/05pymongo.html#mflix","text":"https://s3.amazonaws.com/edu-downloads.10gen.com/M220P/2022/July/static/handouts/m220/mflix-python.zip","title":"MFlix"},{"location":"sa/05pymongo.html#estructura-del-proyecto","text":"verything you will implement is located in the mflix/db.py file, which contains all database interfacing methods. The API will make calls to db.py to interact with MongoDB. The unit tests in tests will test these database access methods directly, without going through the API. The UI will run these methods in integration tests, and therefore requires the full application to be running. The API layer is fully implemented, as is the UI. If you need to run on a port other than 5000, you can edit the index.html file in the build directory to modify the value of window.host. Please do not modify the API layer in any way, movies.py and user.py under the mflix/api directory. Doing so will most likely result in the frontend application failing to validate some of the labs.","title":"Estructura del proyecto"},{"location":"sa/05pymongo.html#preparando-el-entorno","text":"Descargamos y descomprimimos el archivo Dentro de la carpeta, vamos a crear un entorno virtual con venv: bash virtualenv mflix_venv A continuaci\u00f3n, lo activamos: bash source mflix_venv/bin/activate E instalamos los requisitos: bash pip install -r requirements.txt Running the Application In the mflix-python directory you can find a file called dotini. Open this file and enter your Atlas SRV connection string as directed in the comment. This is the information the driver will use to connect. Make sure not to wrap your Atlas SRV connection between quotes: COPY MFLIX_DB_URI = mongodb+srv://... Rename this file to .ini with the following command: COPY mv dotini_unix .ini # on Unix ren dotini_win .ini # on Windows Note: Once you rename this file to .ini, it will no longer be visible in Finder or File Explorer. However, it will be visible from Command Prompt or Terminal, so if you need to edit it again, you can open it from there: COPY vi .ini # on Unix notepad .ini # on Windows","title":"Preparando el entorno"},{"location":"sa/05pymongo.html#arrancando-y-probando","text":"Para arrancar la aplicaci\u00f3n ejecutaremos el script run.py : bash python run.py Al ejecutar el script, arrancar\u00e1 la aplicaci\u00f3n y podremos acceder a ella a trav\u00e9s de http://127.0.0.1:5000/ . PANTALLAZO Si queremos ejecutar los test: Running the Unit Tests To run the unit tests for this course, you will use pytest and needs to be run from mflix-python directory. Each course lab contains a module of unit tests that you can call individually with a command like the following: COPY pytest -m LAB_UNIT_TEST_NAME Each ticket will contain the command to run that ticket's specific unit tests. For example to run the Connection Ticket test your shell command will be: COPY pytest -m connection","title":"Arrancando y Probando"},{"location":"sa/05pymongo.html#mongoclient","text":"A partir de la URI de conexi\u00f3n a MongoDB, hemos de instanciar la clase MongoClient : python uri = \"mongodb+srv://usuario:contrasenya@host\" cliente = MongoCliente(uri) Podemos obtener informaci\u00f3n de la conexi\u00f3n mediante la propiedad state : python print(cliente.state) Por ejemplo, en nuestro caso, nos hemos conectado a MongoAtlas y de la salida del estado podemos ver los diferentes hosts que forman parte del conjunto de r\u00e9plicas: js Database(MongoClient(host=['ac-hrdpnx0-shard-00-02.4hm7u8y.mongodb.net:27017', 'ac-hrdpnx0-shard-00-01.4hm7u8y.mongodb.net:27017', 'ac-hrdpnx0-shard-00-00.4hm7u8y.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-pxc2m9-shard-0', ssl=True, connecttimeoutms=200, retrywrites=True), 'stats') Par\u00e1metros adicionales A la hora de crear el cliente, tambi\u00e9n podemos indicarle opciones de configuraci\u00f3n: cliente200Retry = MongoClient(uri, connectTimeoutMS=200, retryWrites=True) Tambi\u00e9n podemos obtener un listado de las bases de datos mediante list_database_names() : ``` python print(cliente.list_database_names())","title":"MongoClient"},{"location":"sa/05pymongo.html#sample_airbnb-sample_analytics-sample_geospatial-sample_guides-sample_mflix-sample_restaurants-sample_supplies-sample_training-sample_weatherdata-admin-local","text":"``` Para conectarnos a una base de datos en concreto, \u00fanicamente accederemos a ella como una propiedad del cliente: python bd = cliente.sample_mflix bd = cliente[\"sample_mflix'] # tb podemos acceder como si fuera un diccionario Bases de datos y colecciones Lazy Es conveniente tener en cuenta que tantos las colecciones como las bases de datos se crean y carga de forma perezosa, esto es, hasta que no realizamos una operaci\u00f3n sobre ellas, no se accede realmente a ellas. As\u00ed pues, para crear realmente una colecci\u00f3n, hemos de insertar un documento en ella. Una vez tenemos la base de datos, el siguiente paso es obtener una colecci\u00f3n: python coleccion = bd.movies coleccion = bd[\"movies'] Si queremos obtener el nombre de todas las colecciones usaremos el m\u00e9todo list_collection_names() : ``` python print(bd.list_collection_names())","title":"['sample_airbnb', 'sample_analytics', 'sample_geospatial', 'sample_guides', 'sample_mflix', 'sample_restaurants', 'sample_supplies', 'sample_training', 'sample_weatherdata', 'admin', 'local']"},{"location":"sa/05pymongo.html#sessions-theaters-movies-comments-users","text":"```","title":"['sessions', 'theaters', 'movies', 'comments', 'users']"},{"location":"sa/05pymongo.html#primeras-consultas","text":"Finalmente, sobre una colecci\u00f3n ya podemos realizar consultas y otras operaciones: ``` python coleccion.count_documents({})","title":"Primeras consultas"},{"location":"sa/05pymongo.html#23530","text":"coleccion.findOne() ``` Por ejemplo, podemos filtrar las pel\u00edculas de Salma Hayek: python movies.find( { \"cast\": \"Salma Hayek\" } ) ``` python","title":"23530"},{"location":"sa/05pymongo.html#return-the-count-of-movies-with-salma-hayek-in-the-cast","text":"movies.find( { \"cast\": \"Salma Hayek\" } ).count() ``` ``` python","title":"return the count of movies with \"Salma Hayek\" in the \"cast\""},{"location":"sa/05pymongo.html#find-all-movies-with-salma-hayek","text":"","title":"find all movies with Salma Hayek"},{"location":"sa/05pymongo.html#then-pretty-print","text":"cursor = movies.find( { \"cast\": \"Salma Hayek\" } ) from bson.json_util import dumps print(dumps(cursor, indent=2)) ``` ``` python","title":"then pretty print"},{"location":"sa/05pymongo.html#find-all-movies-with-salma-hayek-but-only-project-the-_id-and-title-fields","text":"cursor = movies.find( { \"cast\": \"Salma Hayek\" }, { \"title\": 1 } ) print(dumps(cursor, indent=2)) ``` ``` python","title":"find all movies with Salma Hayek, but only project the \"_id\" and \"title\" fields"},{"location":"sa/05pymongo.html#find-all-movies-with-salma-hayek-but-only-project-the-title-field","text":"cursor = movies.find( { \"cast\": \"Salma Hayek\" }, { \"title\": 1, \"_id\": 0 } ) print(dumps(cursor, indent=2)) ```","title":"find all movies with Salma Hayek, but only project the \"title\" field"},{"location":"sa/05pymongo.html#referencias","text":"","title":"Referencias"},{"location":"sa/05pymongo.html#actividades","text":"","title":"Actividades"},{"location":"sa/planning.html","text":"Planning (10h) \u00b6 01 NoSQL (1h) \u00b6 02 MongoDB (1h + 1h) \u00b6 Conceptos Uso mediante Docker ... poner enlaces para instalar Mongo desde comandos Restore/dump Consultas sencillas (1h) CRUD 03 Modelado (1h) \u00b6 Modelado Relaciones Patrones Framework de agregaci\u00f3n (1h) \u00b6 04 Formatos (1h) \u00b6 csv json columnar avro parquet orc 05 Escalabilidad y Rendimiento (2h) \u00b6 MongoAtlas / Compass Cluster ReplicaSet Replicaci\u00f3n Sharding Rendimiento \u00cdndices 06 PyMongo (2h) \u00b6 Sesiones \u00b6 NoSQL + MongoDB I MongoDB II. Framework de agregaci\u00f3n Formatos de datos. Modelado NoSQL Escalabilidad y Rendimiento. Mongo y Python Pendiente \u00b6 Capped collections: colecciones limitadas","title":"Planning (10h)"},{"location":"sa/planning.html#planning-10h","text":"","title":"Planning (10h)"},{"location":"sa/planning.html#01-nosql-1h","text":"","title":"01 NoSQL (1h)"},{"location":"sa/planning.html#02-mongodb-1h-1h","text":"Conceptos Uso mediante Docker ... poner enlaces para instalar Mongo desde comandos Restore/dump Consultas sencillas (1h) CRUD","title":"02 MongoDB (1h + 1h)"},{"location":"sa/planning.html#03-modelado-1h","text":"Modelado Relaciones Patrones","title":"03 Modelado (1h)"},{"location":"sa/planning.html#framework-de-agregacion-1h","text":"","title":"Framework de agregaci\u00f3n (1h)"},{"location":"sa/planning.html#04-formatos-1h","text":"csv json columnar avro parquet orc","title":"04 Formatos (1h)"},{"location":"sa/planning.html#05-escalabilidad-y-rendimiento-2h","text":"MongoAtlas / Compass Cluster ReplicaSet Replicaci\u00f3n Sharding Rendimiento \u00cdndices","title":"05 Escalabilidad y Rendimiento (2h)"},{"location":"sa/planning.html#06-pymongo-2h","text":"","title":"06 PyMongo (2h)"},{"location":"sa/planning.html#sesiones","text":"NoSQL + MongoDB I MongoDB II. Framework de agregaci\u00f3n Formatos de datos. Modelado NoSQL Escalabilidad y Rendimiento. Mongo y Python","title":"Sesiones"},{"location":"sa/planning.html#pendiente","text":"Capped collections: colecciones limitadas","title":"Pendiente"}]}